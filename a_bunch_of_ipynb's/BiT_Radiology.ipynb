{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BiT-Radiology.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtWxqfwOpKaV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import tensorflow.keras.backend as K"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtOxhhXa57DH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df = pd.read_excel('/content/drive/My Drive/Files-Covid/train.xlsx')\n",
        "test_df = pd.read_excel('/content/drive/My Drive/Files-Covid/test.xlsx')\n",
        "valid_df = pd.read_excel('/content/drive/My Drive/Files-Covid/valid.xlsx')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2ENljhyCmBh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "fbdd8d50-39cc-4570-f009-15c16b1a9583"
      },
      "source": [
        "labels = ['Covid']\n",
        "\n",
        "def get_train_generator(df, image_dir, x_col, y_cols, shuffle=True, batch_size=8, seed=1, target_w = 200, target_h =200):\n",
        "    \"\"\"\n",
        "    Return generator for training set, normalizing using batch\n",
        "    statistics.\n",
        "\n",
        "    Args:\n",
        "      train_df (dataframe): dataframe specifying training data.\n",
        "      image_dir (str): directory where image files are held.\n",
        "      x_col (str): name of column in df that holds filenames.\n",
        "      y_cols (list): list of strings that hold y labels for images.\n",
        "      sample_size (int): size of sample to use for normalization statistics.\n",
        "      batch_size (int): images per batch to be fed into model during training.\n",
        "      seed (int): random seed.\n",
        "      target_w (int): final width of input images.\n",
        "      target_h (int): final height of input images.\n",
        "    \n",
        "    Returns:\n",
        "        train_generator (DataFrameIterator): iterator over training set\n",
        "    \"\"\"        \n",
        "    print(\"getting train generator...\") \n",
        "    # normalize images\n",
        "    image_generator = ImageDataGenerator(\n",
        "        samplewise_center=True,\n",
        "        samplewise_std_normalization= True)\n",
        "    \n",
        "    # flow from directory with specified batch size\n",
        "    # and target image size\n",
        "    generator = image_generator.flow_from_dataframe(\n",
        "            dataframe=df,\n",
        "            directory=image_dir,\n",
        "            x_col=x_col,\n",
        "            y_col=y_cols,\n",
        "            class_mode=\"raw\",\n",
        "            batch_size=batch_size,\n",
        "            shuffle=shuffle,\n",
        "            seed=seed,\n",
        "            target_size=(target_w,target_h))\n",
        "    \n",
        "    return generator\n",
        "\n",
        "def get_test_and_valid_generator(valid_df, test_df, train_df, image_dir, x_col, y_cols, sample_size=100, batch_size=8, seed=1, target_w = 200, target_h = 200):\n",
        "    \"\"\"\n",
        "    Return generator for validation set and test test set using \n",
        "    normalization statistics from training set.\n",
        "\n",
        "    Args:\n",
        "      valid_df (dataframe): dataframe specifying validation data.\n",
        "      test_df (dataframe): dataframe specifying test data.\n",
        "      train_df (dataframe): dataframe specifying training data.\n",
        "      image_dir (str): directory where image files are held.\n",
        "      x_col (str): name of column in df that holds filenames.\n",
        "      y_cols (list): list of strings that hold y labels for images.\n",
        "      sample_size (int): size of sample to use for normalization statistics.\n",
        "      batch_size (int): images per batch to be fed into model during training.\n",
        "      seed (int): random seed.\n",
        "      target_w (int): final width of input images.\n",
        "      target_h (int): final height of input images.\n",
        "    \n",
        "    Returns:\n",
        "        test_generator (DataFrameIterator) and valid_generator: iterators over test set and validation set respectively\n",
        "    \"\"\"\n",
        "    print(\"getting train and valid generators...\")\n",
        "    # get generator to sample dataset\n",
        "    raw_train_generator = ImageDataGenerator().flow_from_dataframe(\n",
        "        dataframe=train_df, \n",
        "        directory=IMG_DIR, \n",
        "        x_col=\"Source\", \n",
        "        y_col=labels, \n",
        "        class_mode=\"raw\", \n",
        "        batch_size=sample_size, \n",
        "        shuffle=True, \n",
        "        target_size=(target_w, target_h))\n",
        "    \n",
        "    # get data sample\n",
        "    batch = raw_train_generator.next()\n",
        "    data_sample = batch[0]\n",
        "\n",
        "    # use sample to fit mean and std for test set generator\n",
        "    image_generator = ImageDataGenerator(\n",
        "        featurewise_center=True,\n",
        "        featurewise_std_normalization= True)\n",
        "    \n",
        "    # fit generator to sample from training data\n",
        "    image_generator.fit(data_sample)\n",
        "\n",
        "    # get test generator\n",
        "    valid_generator = image_generator.flow_from_dataframe(\n",
        "            dataframe=valid_df,\n",
        "            directory=image_dir,\n",
        "            x_col=x_col,\n",
        "            y_col=y_cols,\n",
        "            class_mode=\"raw\",\n",
        "            batch_size=batch_size,\n",
        "            shuffle=False,\n",
        "            seed=seed,\n",
        "            target_size=(target_w,target_h))\n",
        "\n",
        "    test_generator = image_generator.flow_from_dataframe(\n",
        "            dataframe=test_df,\n",
        "            directory=image_dir,\n",
        "            x_col=x_col,\n",
        "            y_col=y_cols,\n",
        "            class_mode=\"raw\",\n",
        "            batch_size=batch_size,\n",
        "            shuffle=False,\n",
        "            seed=seed,\n",
        "            target_size=(target_w,target_h))\n",
        "    return valid_generator, test_generator\n",
        "    \n",
        "IMG_DIR = \"/content/drive/My Drive/Files-Covid/IMG_DIR/\"\n",
        "train_generator_192 = get_train_generator(train_df, IMG_DIR, \"Source\", labels,target_w = 192, target_h = 192)\n",
        "valid_generator_192, test_generator_192= get_test_and_valid_generator(valid_df, test_df, train_df, IMG_DIR, \"Source\", labels, target_w = 192, target_h = 192)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "getting train generator...\n",
            "Found 425 validated image filenames.\n",
            "getting train and valid generators...\n",
            "Found 425 validated image filenames.\n",
            "Found 118 validated image filenames.\n",
            "Found 203 validated image filenames.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cT7JG-gcH27F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_weighted_loss(pos_weights, neg_weights, epsilon=1e-7):\n",
        "    \"\"\"\n",
        "    Return weighted loss function given negative weights and positive weights.\n",
        "\n",
        "    Args:\n",
        "      pos_weights (np.array): array of positive weights for each class, size (num_classes)\n",
        "      neg_weights (np.array): array of negative weights for each class, size (num_classes)\n",
        "    \n",
        "    Returns:\n",
        "      weighted_loss (function): weighted loss function\n",
        "    \"\"\"\n",
        "    def weighted_loss(y_true, y_pred):\n",
        "        \"\"\"\n",
        "        Return weighted loss value. \n",
        "\n",
        "        Args:\n",
        "            y_true (Tensor): Tensor of true labels, size is (num_examples, num_classes)\n",
        "            y_pred (Tensor): Tensor of predicted labels, size is (num_examples, num_classes)\n",
        "        Returns:\n",
        "            loss (Tensor): overall scalar loss summed across all classes\n",
        "        \"\"\"\n",
        "        # initialize loss to zero\n",
        "        loss = 0.0\n",
        "        \n",
        "\n",
        "        for i in range(len(pos_weights)):\n",
        "            # for each class, add average weighted loss for that class \n",
        "            loss += -K.mean(pos_weights[i]*y_true[:,i]*K.log(y_pred[:,i]+epsilon) + neg_weights[i]*(1-y_true[:,i])*K.log(1-y_pred[:,i]+epsilon)) \n",
        "        return loss\n",
        "    return weighted_loss\n",
        "\n",
        "def compute_class_freqs(labels):\n",
        "    \"\"\"\n",
        "    Compute positive and negative frequences for each class.\n",
        "\n",
        "    Args:\n",
        "        labels (np.array): matrix of labels, size (num_examples, num_classes)\n",
        "    Returns:\n",
        "        positive_frequencies (np.array): array of positive frequences for each\n",
        "                                         class, size (num_classes)\n",
        "        negative_frequencies (np.array): array of negative frequences for each\n",
        "                                         class, size (num_classes)\n",
        "    \"\"\"\n",
        "    ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\n",
        "    \n",
        "    # total number of patients (rows)\n",
        "    N = labels.shape[0]\n",
        "    \n",
        "    positive_frequencies = np.sum(labels,axis=0)/N\n",
        "    negative_frequencies = np.ones_like(positive_frequencies) - positive_frequencies\n",
        "\n",
        "    ### END CODE HERE ###\n",
        "    return positive_frequencies, negative_frequencies\n",
        "\n",
        "freq_pos, freq_neg = compute_class_freqs(train_generator_192.labels)\n",
        "pos_weights = freq_neg\n",
        "neg_weights = freq_pos\n",
        "pos_contribution = freq_pos * pos_weights \n",
        "neg_contribution = freq_neg * neg_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-uhucWM30eck",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load model into KerasLayer\n",
        "model_url = \"https://tfhub.dev/google/bit/m-r50x1/1\"\n",
        "module = hub.KerasLayer(model_url)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EoccuhE10l0x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Add new head to the BiT model\n",
        "\n",
        "class MyBiTModel(tf.keras.Model):\n",
        "  \"\"\"BiT with a new head.\"\"\"\n",
        "\n",
        "  def __init__(self, num_classes, module):\n",
        "    super().__init__()\n",
        "\n",
        "    self.num_classes = num_classes\n",
        "    self.head = tf.keras.layers.Dense(num_classes, kernel_initializer='zeros',activation=tf.keras.activations.sigmoid, kernel_regularizer=tf.keras.regularizers.l2(0.1))\n",
        "    self.bit_model = module\n",
        "  \n",
        "  def call(self, images):\n",
        "    # No need to cut head off since we are using feature extractor model\n",
        "    bit_embedding = self.bit_model(images)\n",
        "    return self.head(bit_embedding)\n",
        "\n",
        "model = MyBiTModel(num_classes=1, module=module)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmY8R3GU5_1q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "STEPS_PER_EPOCH = 10\n",
        "BATCH_SIZE = 512\n",
        "# Define optimiser and loss\n",
        "SCHEDULE_LENGTH = 10000\n",
        "SCHEDULE_BOUNDARIES = [3000, 6000, 9000]\n",
        "lr = 0.003 * BATCH_SIZE / 512 \n",
        "SCHEDULE_LENGTH = SCHEDULE_LENGTH * 512 / BATCH_SIZE\n",
        "# Decay learning rate by a factor of 10 at SCHEDULE_BOUNDARIES.\n",
        "lr_schedule = tf.keras.optimizers.schedules.PiecewiseConstantDecay(boundaries=SCHEDULE_BOUNDARIES, \n",
        "                                                                   values=[lr, lr*0.1, lr*0.001, lr*0.0001])\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate=lr_schedule, momentum=0.9)\n",
        "\n",
        "loss_fn = get_weighted_loss(pos_weights,neg_weights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cK_9da0R80Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer=optimizer,\n",
        "              loss=loss_fn,\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j51bOd_qT0eJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5699f7bb-82cb-4f2f-cd3d-e7c589c0ae26"
      },
      "source": [
        "# Fine-tune model\n",
        "history = model.fit(\n",
        "    train_generator_192,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    steps_per_epoch=STEPS_PER_EPOCH,\n",
        "    epochs= int(SCHEDULE_LENGTH / STEPS_PER_EPOCH),  # TODO: replace with `epochs=10` here to shorten fine-tuning for tutorial if you wish\n",
        "    validation_data=test_generator_192,  # here we are only using .this data to evaluate our performance\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "10/10 [==============================] - 4s 357ms/step - loss: 0.5800 - accuracy: 0.6250 - val_loss: 0.4090 - val_accuracy: 0.7635\n",
            "Epoch 2/1000\n",
            "10/10 [==============================] - 2s 208ms/step - loss: 0.5516 - accuracy: 0.7375 - val_loss: 1.3056 - val_accuracy: 0.6847\n",
            "Epoch 3/1000\n",
            "10/10 [==============================] - 2s 243ms/step - loss: 1.1936 - accuracy: 0.6849 - val_loss: 0.5799 - val_accuracy: 0.7438\n",
            "Epoch 4/1000\n",
            "10/10 [==============================] - 2s 198ms/step - loss: 1.4089 - accuracy: 0.6986 - val_loss: 0.6058 - val_accuracy: 0.7586\n",
            "Epoch 5/1000\n",
            "10/10 [==============================] - 2s 225ms/step - loss: 0.7194 - accuracy: 0.8000 - val_loss: 0.9809 - val_accuracy: 0.6798\n",
            "Epoch 6/1000\n",
            "10/10 [==============================] - 2s 214ms/step - loss: 2.6588 - accuracy: 0.5625 - val_loss: 0.9705 - val_accuracy: 0.6946\n",
            "Epoch 7/1000\n",
            "10/10 [==============================] - 2s 213ms/step - loss: 0.9968 - accuracy: 0.7000 - val_loss: 1.2181 - val_accuracy: 0.7094\n",
            "Epoch 8/1000\n",
            "10/10 [==============================] - 2s 205ms/step - loss: 0.7422 - accuracy: 0.8125 - val_loss: 0.9300 - val_accuracy: 0.7094\n",
            "Epoch 9/1000\n",
            "10/10 [==============================] - 2s 202ms/step - loss: 0.6090 - accuracy: 0.8250 - val_loss: 1.6006 - val_accuracy: 0.7044\n",
            "Epoch 10/1000\n",
            "10/10 [==============================] - 2s 219ms/step - loss: 0.9581 - accuracy: 0.7625 - val_loss: 1.3474 - val_accuracy: 0.6158\n",
            "Epoch 11/1000\n",
            "10/10 [==============================] - 2s 206ms/step - loss: 0.5777 - accuracy: 0.8625 - val_loss: 1.1811 - val_accuracy: 0.6995\n",
            "Epoch 12/1000\n",
            "10/10 [==============================] - 2s 206ms/step - loss: 1.1776 - accuracy: 0.6750 - val_loss: 2.0568 - val_accuracy: 0.6552\n",
            "Epoch 13/1000\n",
            "10/10 [==============================] - 2s 207ms/step - loss: 1.0480 - accuracy: 0.7250 - val_loss: 1.2435 - val_accuracy: 0.6897\n",
            "Epoch 14/1000\n",
            "10/10 [==============================] - 2s 204ms/step - loss: 1.0109 - accuracy: 0.8000 - val_loss: 1.3004 - val_accuracy: 0.6650\n",
            "Epoch 15/1000\n",
            "10/10 [==============================] - 2s 219ms/step - loss: 1.8374 - accuracy: 0.6000 - val_loss: 1.9230 - val_accuracy: 0.5911\n",
            "Epoch 16/1000\n",
            "10/10 [==============================] - 2s 213ms/step - loss: 0.7953 - accuracy: 0.8375 - val_loss: 1.0961 - val_accuracy: 0.7389\n",
            "Epoch 17/1000\n",
            "10/10 [==============================] - 2s 223ms/step - loss: 0.7737 - accuracy: 0.8375 - val_loss: 1.8897 - val_accuracy: 0.6453\n",
            "Epoch 18/1000\n",
            "10/10 [==============================] - 2s 205ms/step - loss: 2.2515 - accuracy: 0.6750 - val_loss: 2.2411 - val_accuracy: 0.6108\n",
            "Epoch 19/1000\n",
            "10/10 [==============================] - 2s 204ms/step - loss: 1.7887 - accuracy: 0.7125 - val_loss: 1.3762 - val_accuracy: 0.7488\n",
            "Epoch 20/1000\n",
            "10/10 [==============================] - 2s 209ms/step - loss: 1.4198 - accuracy: 0.7750 - val_loss: 1.9163 - val_accuracy: 0.7685\n",
            "Epoch 21/1000\n",
            "10/10 [==============================] - 2s 209ms/step - loss: 2.2330 - accuracy: 0.6625 - val_loss: 2.8053 - val_accuracy: 0.6404\n",
            "Epoch 22/1000\n",
            "10/10 [==============================] - 2s 214ms/step - loss: 2.6285 - accuracy: 0.5479 - val_loss: 1.6608 - val_accuracy: 0.7586\n",
            "Epoch 23/1000\n",
            "10/10 [==============================] - 2s 215ms/step - loss: 1.7892 - accuracy: 0.7500 - val_loss: 1.9470 - val_accuracy: 0.7143\n",
            "Epoch 24/1000\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 1.1929 - accuracy: 0.8625 - val_loss: 1.6120 - val_accuracy: 0.7783\n",
            "Epoch 25/1000\n",
            "10/10 [==============================] - 2s 206ms/step - loss: 1.0187 - accuracy: 0.8000 - val_loss: 2.3360 - val_accuracy: 0.6946\n",
            "Epoch 26/1000\n",
            "10/10 [==============================] - 2s 197ms/step - loss: 1.2138 - accuracy: 0.7625 - val_loss: 1.4913 - val_accuracy: 0.7734\n",
            "Epoch 27/1000\n",
            "10/10 [==============================] - 2s 206ms/step - loss: 1.0761 - accuracy: 0.8625 - val_loss: 1.4617 - val_accuracy: 0.7586\n",
            "Epoch 28/1000\n",
            "10/10 [==============================] - 2s 215ms/step - loss: 0.7839 - accuracy: 0.9125 - val_loss: 1.8447 - val_accuracy: 0.7340\n",
            "Epoch 29/1000\n",
            "10/10 [==============================] - 2s 209ms/step - loss: 1.3522 - accuracy: 0.7875 - val_loss: 2.3119 - val_accuracy: 0.6847\n",
            "Epoch 30/1000\n",
            "10/10 [==============================] - 2s 208ms/step - loss: 1.0077 - accuracy: 0.8500 - val_loss: 2.5400 - val_accuracy: 0.6552\n",
            "Epoch 31/1000\n",
            "10/10 [==============================] - 2s 217ms/step - loss: 1.6869 - accuracy: 0.7625 - val_loss: 1.4638 - val_accuracy: 0.7586\n",
            "Epoch 32/1000\n",
            "10/10 [==============================] - 2s 210ms/step - loss: 0.9211 - accuracy: 0.8250 - val_loss: 1.3763 - val_accuracy: 0.7340\n",
            "Epoch 33/1000\n",
            "10/10 [==============================] - 2s 215ms/step - loss: 1.5836 - accuracy: 0.7125 - val_loss: 1.2363 - val_accuracy: 0.7783\n",
            "Epoch 34/1000\n",
            "10/10 [==============================] - 2s 204ms/step - loss: 1.4172 - accuracy: 0.7500 - val_loss: 1.3280 - val_accuracy: 0.7537\n",
            "Epoch 35/1000\n",
            "10/10 [==============================] - 2s 205ms/step - loss: 1.5021 - accuracy: 0.7500 - val_loss: 1.2799 - val_accuracy: 0.7389\n",
            "Epoch 36/1000\n",
            "10/10 [==============================] - 2s 203ms/step - loss: 2.7094 - accuracy: 0.6027 - val_loss: 1.5702 - val_accuracy: 0.7635\n",
            "Epoch 37/1000\n",
            "10/10 [==============================] - 2s 212ms/step - loss: 1.4629 - accuracy: 0.8000 - val_loss: 1.6919 - val_accuracy: 0.7833\n",
            "Epoch 38/1000\n",
            "10/10 [==============================] - 2s 208ms/step - loss: 1.6759 - accuracy: 0.7671 - val_loss: 1.9048 - val_accuracy: 0.7586\n",
            "Epoch 39/1000\n",
            "10/10 [==============================] - 2s 198ms/step - loss: 2.4435 - accuracy: 0.6500 - val_loss: 2.9901 - val_accuracy: 0.5665\n",
            "Epoch 40/1000\n",
            "10/10 [==============================] - 2s 214ms/step - loss: 1.6218 - accuracy: 0.7875 - val_loss: 1.7158 - val_accuracy: 0.7685\n",
            "Epoch 41/1000\n",
            "10/10 [==============================] - 2s 219ms/step - loss: 1.7582 - accuracy: 0.7125 - val_loss: 1.9759 - val_accuracy: 0.6847\n",
            "Epoch 42/1000\n",
            "10/10 [==============================] - 2s 203ms/step - loss: 0.9432 - accuracy: 0.8625 - val_loss: 1.4526 - val_accuracy: 0.7685\n",
            "Epoch 43/1000\n",
            "10/10 [==============================] - 2s 199ms/step - loss: 0.9178 - accuracy: 0.8630 - val_loss: 1.3625 - val_accuracy: 0.7685\n",
            "Epoch 44/1000\n",
            "10/10 [==============================] - 2s 207ms/step - loss: 1.1176 - accuracy: 0.8493 - val_loss: 3.9215 - val_accuracy: 0.5369\n",
            "Epoch 45/1000\n",
            "10/10 [==============================] - 2s 197ms/step - loss: 1.9996 - accuracy: 0.7250 - val_loss: 1.3630 - val_accuracy: 0.7340\n",
            "Epoch 46/1000\n",
            "10/10 [==============================] - 2s 205ms/step - loss: 1.2326 - accuracy: 0.7500 - val_loss: 2.2214 - val_accuracy: 0.6749\n",
            "Epoch 47/1000\n",
            "10/10 [==============================] - 2s 204ms/step - loss: 1.2904 - accuracy: 0.7875 - val_loss: 1.4875 - val_accuracy: 0.7734\n",
            "Epoch 48/1000\n",
            "10/10 [==============================] - 2s 210ms/step - loss: 1.1029 - accuracy: 0.8125 - val_loss: 1.3667 - val_accuracy: 0.7586\n",
            "Epoch 49/1000\n",
            "10/10 [==============================] - 2s 202ms/step - loss: 0.5355 - accuracy: 0.9250 - val_loss: 1.2885 - val_accuracy: 0.7340\n",
            "Epoch 50/1000\n",
            "10/10 [==============================] - 2s 205ms/step - loss: 0.8485 - accuracy: 0.8625 - val_loss: 1.4638 - val_accuracy: 0.7094\n",
            "Epoch 51/1000\n",
            "10/10 [==============================] - 2s 214ms/step - loss: 0.9594 - accuracy: 0.7250 - val_loss: 1.9176 - val_accuracy: 0.6749\n",
            "Epoch 52/1000\n",
            "10/10 [==============================] - 2s 215ms/step - loss: 1.3612 - accuracy: 0.7000 - val_loss: 1.1558 - val_accuracy: 0.8030\n",
            "Epoch 53/1000\n",
            "10/10 [==============================] - 2s 198ms/step - loss: 1.9971 - accuracy: 0.6625 - val_loss: 3.1058 - val_accuracy: 0.5714\n",
            "Epoch 54/1000\n",
            "10/10 [==============================] - 2s 210ms/step - loss: 2.0582 - accuracy: 0.6375 - val_loss: 3.1667 - val_accuracy: 0.5911\n",
            "Epoch 55/1000\n",
            "10/10 [==============================] - 2s 209ms/step - loss: 2.5176 - accuracy: 0.6750 - val_loss: 1.4183 - val_accuracy: 0.7783\n",
            "Epoch 56/1000\n",
            "10/10 [==============================] - 2s 210ms/step - loss: 1.3177 - accuracy: 0.8000 - val_loss: 1.4716 - val_accuracy: 0.7389\n",
            "Epoch 57/1000\n",
            "10/10 [==============================] - 2s 210ms/step - loss: 1.5324 - accuracy: 0.7875 - val_loss: 1.5416 - val_accuracy: 0.7783\n",
            "Epoch 58/1000\n",
            "10/10 [==============================] - 2s 204ms/step - loss: 0.8555 - accuracy: 0.8125 - val_loss: 1.8728 - val_accuracy: 0.6552\n",
            "Epoch 59/1000\n",
            "10/10 [==============================] - 2s 200ms/step - loss: 1.5929 - accuracy: 0.7125 - val_loss: 2.9472 - val_accuracy: 0.5517\n",
            "Epoch 60/1000\n",
            "10/10 [==============================] - 2s 204ms/step - loss: 1.5135 - accuracy: 0.7750 - val_loss: 2.5354 - val_accuracy: 0.6010\n",
            "Epoch 61/1000\n",
            "10/10 [==============================] - 2s 209ms/step - loss: 1.1273 - accuracy: 0.8000 - val_loss: 2.0420 - val_accuracy: 0.6700\n",
            "Epoch 62/1000\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 0.5436 - accuracy: 0.9125 - val_loss: 1.9484 - val_accuracy: 0.6601\n",
            "Epoch 63/1000\n",
            "10/10 [==============================] - 2s 205ms/step - loss: 1.3662 - accuracy: 0.7534 - val_loss: 3.1813 - val_accuracy: 0.5862\n",
            "Epoch 64/1000\n",
            "10/10 [==============================] - 2s 195ms/step - loss: 3.7623 - accuracy: 0.5625 - val_loss: 1.5267 - val_accuracy: 0.7537\n",
            "Epoch 65/1000\n",
            "10/10 [==============================] - 2s 202ms/step - loss: 1.5857 - accuracy: 0.7625 - val_loss: 2.6904 - val_accuracy: 0.6552\n",
            "Epoch 66/1000\n",
            "10/10 [==============================] - 2s 205ms/step - loss: 2.1850 - accuracy: 0.6750 - val_loss: 2.1625 - val_accuracy: 0.7241\n",
            "Epoch 67/1000\n",
            "10/10 [==============================] - 2s 209ms/step - loss: 3.8554 - accuracy: 0.5375 - val_loss: 2.2788 - val_accuracy: 0.7044\n",
            "Epoch 68/1000\n",
            "10/10 [==============================] - 2s 208ms/step - loss: 3.4856 - accuracy: 0.5750 - val_loss: 4.3216 - val_accuracy: 0.4828\n",
            "Epoch 69/1000\n",
            "10/10 [==============================] - 2s 198ms/step - loss: 5.2351 - accuracy: 0.3562 - val_loss: 4.3229 - val_accuracy: 0.4828\n",
            "Epoch 70/1000\n",
            "10/10 [==============================] - 2s 209ms/step - loss: 4.8975 - accuracy: 0.4000 - val_loss: 4.2776 - val_accuracy: 0.4828\n",
            "Epoch 71/1000\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 4.3732 - accuracy: 0.4658 - val_loss: 4.2194 - val_accuracy: 0.4828\n",
            "Epoch 72/1000\n",
            "10/10 [==============================] - 2s 198ms/step - loss: 5.1442 - accuracy: 0.3500 - val_loss: 4.1614 - val_accuracy: 0.4828\n",
            "Epoch 73/1000\n",
            "10/10 [==============================] - 2s 207ms/step - loss: 4.5508 - accuracy: 0.4250 - val_loss: 4.1081 - val_accuracy: 0.4828\n",
            "Epoch 74/1000\n",
            "10/10 [==============================] - 2s 200ms/step - loss: 5.3060 - accuracy: 0.3125 - val_loss: 4.0603 - val_accuracy: 0.4828\n",
            "Epoch 75/1000\n",
            "10/10 [==============================] - 2s 206ms/step - loss: 4.6337 - accuracy: 0.4000 - val_loss: 4.0179 - val_accuracy: 0.4828\n",
            "Epoch 76/1000\n",
            "10/10 [==============================] - 2s 214ms/step - loss: 4.3250 - accuracy: 0.4375 - val_loss: 3.9806 - val_accuracy: 0.4828\n",
            "Epoch 77/1000\n",
            "10/10 [==============================] - 2s 205ms/step - loss: 4.2897 - accuracy: 0.4375 - val_loss: 3.9476 - val_accuracy: 0.4828\n",
            "Epoch 78/1000\n",
            "10/10 [==============================] - 2s 205ms/step - loss: 4.5272 - accuracy: 0.4000 - val_loss: 3.9187 - val_accuracy: 0.4828\n",
            "Epoch 79/1000\n",
            "10/10 [==============================] - 2s 205ms/step - loss: 4.7685 - accuracy: 0.3625 - val_loss: 3.8931 - val_accuracy: 0.4828\n",
            "Epoch 80/1000\n",
            "10/10 [==============================] - 2s 216ms/step - loss: 4.1175 - accuracy: 0.4500 - val_loss: 3.8707 - val_accuracy: 0.4828\n",
            "Epoch 81/1000\n",
            "10/10 [==============================] - 2s 204ms/step - loss: 3.8850 - accuracy: 0.4795 - val_loss: 3.8509 - val_accuracy: 0.4828\n",
            "Epoch 82/1000\n",
            "10/10 [==============================] - 2s 203ms/step - loss: 3.9881 - accuracy: 0.4625 - val_loss: 3.8335 - val_accuracy: 0.4828\n",
            "Epoch 83/1000\n",
            "10/10 [==============================] - 2s 224ms/step - loss: 3.8821 - accuracy: 0.4750 - val_loss: 3.8182 - val_accuracy: 0.4828\n",
            "Epoch 84/1000\n",
            "10/10 [==============================] - 2s 210ms/step - loss: 3.9572 - accuracy: 0.4625 - val_loss: 3.8047 - val_accuracy: 0.4828\n",
            "Epoch 85/1000\n",
            "10/10 [==============================] - 2s 210ms/step - loss: 3.9215 - accuracy: 0.4658 - val_loss: 3.7929 - val_accuracy: 0.4828\n",
            "Epoch 86/1000\n",
            "10/10 [==============================] - 2s 215ms/step - loss: 3.5750 - accuracy: 0.5125 - val_loss: 3.7825 - val_accuracy: 0.4828\n",
            "Epoch 87/1000\n",
            "10/10 [==============================] - 2s 204ms/step - loss: 3.2069 - accuracy: 0.5625 - val_loss: 3.7733 - val_accuracy: 0.4828\n",
            "Epoch 88/1000\n",
            "10/10 [==============================] - 2s 208ms/step - loss: 4.5787 - accuracy: 0.3699 - val_loss: 3.7652 - val_accuracy: 0.4828\n",
            "Epoch 89/1000\n",
            "10/10 [==============================] - 2s 209ms/step - loss: 2.8324 - accuracy: 0.6125 - val_loss: 3.7581 - val_accuracy: 0.4828\n",
            "Epoch 90/1000\n",
            "10/10 [==============================] - 2s 197ms/step - loss: 3.8108 - accuracy: 0.4750 - val_loss: 3.7518 - val_accuracy: 0.4828\n",
            "Epoch 91/1000\n",
            "10/10 [==============================] - 2s 196ms/step - loss: 3.8712 - accuracy: 0.4658 - val_loss: 3.7448 - val_accuracy: 0.4828\n",
            "Epoch 92/1000\n",
            "10/10 [==============================] - 2s 204ms/step - loss: 4.2475 - accuracy: 0.4125 - val_loss: 3.7384 - val_accuracy: 0.4828\n",
            "Epoch 93/1000\n",
            "10/10 [==============================] - 2s 211ms/step - loss: 2.4630 - accuracy: 0.5375 - val_loss: 1.5086 - val_accuracy: 0.5961\n",
            "Epoch 94/1000\n",
            "10/10 [==============================] - 2s 208ms/step - loss: 1.3405 - accuracy: 0.6750 - val_loss: 1.3034 - val_accuracy: 0.6946\n",
            "Epoch 95/1000\n",
            "10/10 [==============================] - 2s 203ms/step - loss: 0.4033 - accuracy: 0.8375 - val_loss: 0.7220 - val_accuracy: 0.7488\n",
            "Epoch 96/1000\n",
            "10/10 [==============================] - 2s 208ms/step - loss: 1.1138 - accuracy: 0.7125 - val_loss: 0.7314 - val_accuracy: 0.7291\n",
            "Epoch 97/1000\n",
            "10/10 [==============================] - 2s 214ms/step - loss: 1.1239 - accuracy: 0.7250 - val_loss: 1.6109 - val_accuracy: 0.6601\n",
            "Epoch 98/1000\n",
            "10/10 [==============================] - 2s 210ms/step - loss: 1.0214 - accuracy: 0.7375 - val_loss: 1.1377 - val_accuracy: 0.6995\n",
            "Epoch 99/1000\n",
            "10/10 [==============================] - 2s 208ms/step - loss: 1.5556 - accuracy: 0.7250 - val_loss: 1.2413 - val_accuracy: 0.7488\n",
            "Epoch 100/1000\n",
            "10/10 [==============================] - 2s 199ms/step - loss: 4.0971 - accuracy: 0.4250 - val_loss: 3.9709 - val_accuracy: 0.4828\n",
            "Epoch 101/1000\n",
            "10/10 [==============================] - 2s 206ms/step - loss: 4.1310 - accuracy: 0.4625 - val_loss: 3.9943 - val_accuracy: 0.4828\n",
            "Epoch 102/1000\n",
            "10/10 [==============================] - 2s 210ms/step - loss: 4.3146 - accuracy: 0.4375 - val_loss: 3.9816 - val_accuracy: 0.4828\n",
            "Epoch 103/1000\n",
            "10/10 [==============================] - 2s 202ms/step - loss: 4.8324 - accuracy: 0.3625 - val_loss: 3.9565 - val_accuracy: 0.4828\n",
            "Epoch 104/1000\n",
            "10/10 [==============================] - 2s 212ms/step - loss: 3.8207 - accuracy: 0.5000 - val_loss: 3.9293 - val_accuracy: 0.4828\n",
            "Epoch 105/1000\n",
            "10/10 [==============================] - 2s 198ms/step - loss: 4.0627 - accuracy: 0.4625 - val_loss: 3.9035 - val_accuracy: 0.4828\n",
            "Epoch 106/1000\n",
            "10/10 [==============================] - 2s 219ms/step - loss: 3.7693 - accuracy: 0.5000 - val_loss: 3.8802 - val_accuracy: 0.4828\n",
            "Epoch 107/1000\n",
            "10/10 [==============================] - 2s 195ms/step - loss: 4.4635 - accuracy: 0.4000 - val_loss: 3.8594 - val_accuracy: 0.4828\n",
            "Epoch 108/1000\n",
            "10/10 [==============================] - 2s 195ms/step - loss: 4.2647 - accuracy: 0.4250 - val_loss: 3.8410 - val_accuracy: 0.4828\n",
            "Epoch 109/1000\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 3.7996 - accuracy: 0.4875 - val_loss: 3.8248 - val_accuracy: 0.4828\n",
            "Epoch 110/1000\n",
            "10/10 [==============================] - 2s 215ms/step - loss: 3.8413 - accuracy: 0.4795 - val_loss: 3.8106 - val_accuracy: 0.4828\n",
            "Epoch 111/1000\n",
            "10/10 [==============================] - 2s 196ms/step - loss: 3.9499 - accuracy: 0.4625 - val_loss: 3.7980 - val_accuracy: 0.4828\n",
            "Epoch 112/1000\n",
            "10/10 [==============================] - 2s 200ms/step - loss: 4.3859 - accuracy: 0.4000 - val_loss: 3.7870 - val_accuracy: 0.4828\n",
            "Epoch 113/1000\n",
            "10/10 [==============================] - 2s 196ms/step - loss: 4.1963 - accuracy: 0.4250 - val_loss: 3.7772 - val_accuracy: 0.4828\n",
            "Epoch 114/1000\n",
            "10/10 [==============================] - 2s 219ms/step - loss: 4.2726 - accuracy: 0.4125 - val_loss: 3.7679 - val_accuracy: 0.4828\n",
            "Epoch 115/1000\n",
            "10/10 [==============================] - 2s 203ms/step - loss: 4.3874 - accuracy: 0.3750 - val_loss: 2.7015 - val_accuracy: 0.4877\n",
            "Epoch 116/1000\n",
            "10/10 [==============================] - 2s 215ms/step - loss: 1.9453 - accuracy: 0.6000 - val_loss: 1.8289 - val_accuracy: 0.6404\n",
            "Epoch 117/1000\n",
            "10/10 [==============================] - 2s 212ms/step - loss: 0.7531 - accuracy: 0.7625 - val_loss: 1.2077 - val_accuracy: 0.7143\n",
            "Epoch 118/1000\n",
            "10/10 [==============================] - 2s 215ms/step - loss: 3.3787 - accuracy: 0.6000 - val_loss: 4.3208 - val_accuracy: 0.5172\n",
            "Epoch 119/1000\n",
            "10/10 [==============================] - 2s 207ms/step - loss: 4.1562 - accuracy: 0.5375 - val_loss: 4.1271 - val_accuracy: 0.5320\n",
            "Epoch 120/1000\n",
            "10/10 [==============================] - 2s 206ms/step - loss: 3.7284 - accuracy: 0.5068 - val_loss: 3.9659 - val_accuracy: 0.4828\n",
            "Epoch 121/1000\n",
            "10/10 [==============================] - 2s 208ms/step - loss: 4.0836 - accuracy: 0.4750 - val_loss: 4.0823 - val_accuracy: 0.4828\n",
            "Epoch 122/1000\n",
            "10/10 [==============================] - 2s 197ms/step - loss: 4.6900 - accuracy: 0.4000 - val_loss: 4.1028 - val_accuracy: 0.4828\n",
            "Epoch 123/1000\n",
            "10/10 [==============================] - 2s 207ms/step - loss: 4.5978 - accuracy: 0.4125 - val_loss: 4.0800 - val_accuracy: 0.4828\n",
            "Epoch 124/1000\n",
            "10/10 [==============================] - 2s 208ms/step - loss: 4.3885 - accuracy: 0.4375 - val_loss: 4.0441 - val_accuracy: 0.4828\n",
            "Epoch 125/1000\n",
            "10/10 [==============================] - 2s 210ms/step - loss: 4.3514 - accuracy: 0.4375 - val_loss: 4.0067 - val_accuracy: 0.4828\n",
            "Epoch 126/1000\n",
            "10/10 [==============================] - 2s 208ms/step - loss: 3.9567 - accuracy: 0.4875 - val_loss: 3.9717 - val_accuracy: 0.4828\n",
            "Epoch 127/1000\n",
            "10/10 [==============================] - 2s 205ms/step - loss: 3.9232 - accuracy: 0.4875 - val_loss: 3.9402 - val_accuracy: 0.4828\n",
            "Epoch 128/1000\n",
            "10/10 [==============================] - 2s 219ms/step - loss: 3.4604 - accuracy: 0.5479 - val_loss: 3.9122 - val_accuracy: 0.4828\n",
            "Epoch 129/1000\n",
            "10/10 [==============================] - 2s 215ms/step - loss: 4.2251 - accuracy: 0.4375 - val_loss: 3.8875 - val_accuracy: 0.4828\n",
            "Epoch 130/1000\n",
            "10/10 [==============================] - 2s 206ms/step - loss: 3.5749 - accuracy: 0.5250 - val_loss: 3.8658 - val_accuracy: 0.4828\n",
            "Epoch 131/1000\n",
            "10/10 [==============================] - 2s 218ms/step - loss: 4.0021 - accuracy: 0.4625 - val_loss: 3.8466 - val_accuracy: 0.4828\n",
            "Epoch 132/1000\n",
            "10/10 [==============================] - 2s 212ms/step - loss: 4.0735 - accuracy: 0.4500 - val_loss: 3.8297 - val_accuracy: 0.4828\n",
            "Epoch 133/1000\n",
            "10/10 [==============================] - 2s 212ms/step - loss: 4.5054 - accuracy: 0.3875 - val_loss: 3.8149 - val_accuracy: 0.4828\n",
            "Epoch 134/1000\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 4.0436 - accuracy: 0.4500 - val_loss: 3.8018 - val_accuracy: 0.4828\n",
            "Epoch 135/1000\n",
            "10/10 [==============================] - 2s 202ms/step - loss: 3.5255 - accuracy: 0.5205 - val_loss: 3.7903 - val_accuracy: 0.4828\n",
            "Epoch 136/1000\n",
            "10/10 [==============================] - 2s 210ms/step - loss: 4.4681 - accuracy: 0.3875 - val_loss: 3.7802 - val_accuracy: 0.4828\n",
            "Epoch 137/1000\n",
            "10/10 [==============================] - 2s 198ms/step - loss: 3.4069 - accuracy: 0.5342 - val_loss: 3.7713 - val_accuracy: 0.4828\n",
            "Epoch 138/1000\n",
            "10/10 [==============================] - 2s 211ms/step - loss: 4.4501 - accuracy: 0.3875 - val_loss: 3.7634 - val_accuracy: 0.4828\n",
            "Epoch 139/1000\n",
            "10/10 [==============================] - 2s 220ms/step - loss: 3.5472 - accuracy: 0.5125 - val_loss: 3.7565 - val_accuracy: 0.4828\n",
            "Epoch 140/1000\n",
            "10/10 [==============================] - 2s 210ms/step - loss: 3.7197 - accuracy: 0.4875 - val_loss: 3.7504 - val_accuracy: 0.4828\n",
            "Epoch 141/1000\n",
            "10/10 [==============================] - 2s 205ms/step - loss: 3.7140 - accuracy: 0.4875 - val_loss: 3.7451 - val_accuracy: 0.4828\n",
            "Epoch 142/1000\n",
            "10/10 [==============================] - 2s 209ms/step - loss: 4.0672 - accuracy: 0.4375 - val_loss: 3.7404 - val_accuracy: 0.4828\n",
            "Epoch 143/1000\n",
            "10/10 [==============================] - 2s 207ms/step - loss: 4.3314 - accuracy: 0.4000 - val_loss: 3.7363 - val_accuracy: 0.4828\n",
            "Epoch 144/1000\n",
            "10/10 [==============================] - 2s 200ms/step - loss: 3.6110 - accuracy: 0.5000 - val_loss: 3.7326 - val_accuracy: 0.4828\n",
            "Epoch 145/1000\n",
            "10/10 [==============================] - 2s 206ms/step - loss: 3.1328 - accuracy: 0.5616 - val_loss: 0.9799 - val_accuracy: 0.6552\n",
            "Epoch 146/1000\n",
            "10/10 [==============================] - 2s 202ms/step - loss: 3.5075 - accuracy: 0.5625 - val_loss: 4.4040 - val_accuracy: 0.5172\n",
            "Epoch 147/1000\n",
            "10/10 [==============================] - 2s 203ms/step - loss: 4.5887 - accuracy: 0.5000 - val_loss: 4.4623 - val_accuracy: 0.5172\n",
            "Epoch 148/1000\n",
            "10/10 [==============================] - 2s 198ms/step - loss: 4.4003 - accuracy: 0.5250 - val_loss: 4.4716 - val_accuracy: 0.5172\n",
            "Epoch 149/1000\n",
            "10/10 [==============================] - 2s 199ms/step - loss: 4.0658 - accuracy: 0.5625 - val_loss: 4.4605 - val_accuracy: 0.5172\n",
            "Epoch 150/1000\n",
            "10/10 [==============================] - 2s 214ms/step - loss: 4.6675 - accuracy: 0.4932 - val_loss: 4.4434 - val_accuracy: 0.5172\n",
            "Epoch 151/1000\n",
            "10/10 [==============================] - 2s 206ms/step - loss: 4.0337 - accuracy: 0.5625 - val_loss: 4.4257 - val_accuracy: 0.5172\n",
            "Epoch 152/1000\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 4.2384 - accuracy: 0.5375 - val_loss: 4.4093 - val_accuracy: 0.5172\n",
            "Epoch 153/1000\n",
            "10/10 [==============================] - 2s 224ms/step - loss: 4.2510 - accuracy: 0.5342 - val_loss: 4.3944 - val_accuracy: 0.5172\n",
            "Epoch 154/1000\n",
            "10/10 [==============================] - 2s 204ms/step - loss: 3.6540 - accuracy: 0.6000 - val_loss: 4.3813 - val_accuracy: 0.5172\n",
            "Epoch 155/1000\n",
            "10/10 [==============================] - 2s 198ms/step - loss: 3.9743 - accuracy: 0.5625 - val_loss: 4.3697 - val_accuracy: 0.5172\n",
            "Epoch 156/1000\n",
            "10/10 [==============================] - 2s 198ms/step - loss: 4.8507 - accuracy: 0.4625 - val_loss: 4.3594 - val_accuracy: 0.5172\n",
            "Epoch 157/1000\n",
            "10/10 [==============================] - 2s 210ms/step - loss: 3.9536 - accuracy: 0.5625 - val_loss: 4.3504 - val_accuracy: 0.5172\n",
            "Epoch 158/1000\n",
            "10/10 [==============================] - 2s 196ms/step - loss: 3.8342 - accuracy: 0.5750 - val_loss: 4.3425 - val_accuracy: 0.5172\n",
            "Epoch 159/1000\n",
            "10/10 [==============================] - 2s 212ms/step - loss: 4.1595 - accuracy: 0.5375 - val_loss: 4.3355 - val_accuracy: 0.5172\n",
            "Epoch 160/1000\n",
            "10/10 [==============================] - 2s 210ms/step - loss: 4.4857 - accuracy: 0.5000 - val_loss: 4.3293 - val_accuracy: 0.5172\n",
            "Epoch 161/1000\n",
            "10/10 [==============================] - 2s 196ms/step - loss: 3.8143 - accuracy: 0.5750 - val_loss: 4.3239 - val_accuracy: 0.5172\n",
            "Epoch 162/1000\n",
            "10/10 [==============================] - 2s 202ms/step - loss: 4.3638 - accuracy: 0.5125 - val_loss: 4.3192 - val_accuracy: 0.5172\n",
            "Epoch 163/1000\n",
            "10/10 [==============================] - 2s 202ms/step - loss: 3.9156 - accuracy: 0.5625 - val_loss: 4.3150 - val_accuracy: 0.5172\n",
            "Epoch 164/1000\n",
            "10/10 [==============================] - 2s 208ms/step - loss: 4.3553 - accuracy: 0.5125 - val_loss: 4.3113 - val_accuracy: 0.5172\n",
            "Epoch 165/1000\n",
            "10/10 [==============================] - 2s 213ms/step - loss: 3.6863 - accuracy: 0.5875 - val_loss: 4.3080 - val_accuracy: 0.5172\n",
            "Epoch 166/1000\n",
            "10/10 [==============================] - 2s 211ms/step - loss: 3.9051 - accuracy: 0.5625 - val_loss: 4.3052 - val_accuracy: 0.5172\n",
            "Epoch 167/1000\n",
            "10/10 [==============================] - 2s 199ms/step - loss: 3.9100 - accuracy: 0.5616 - val_loss: 4.3027 - val_accuracy: 0.5172\n",
            "Epoch 168/1000\n",
            "10/10 [==============================] - 2s 205ms/step - loss: 4.2328 - accuracy: 0.5250 - val_loss: 4.3004 - val_accuracy: 0.5172\n",
            "Epoch 169/1000\n",
            "10/10 [==============================] - 2s 209ms/step - loss: 4.5635 - accuracy: 0.4875 - val_loss: 4.2985 - val_accuracy: 0.5172\n",
            "Epoch 170/1000\n",
            "10/10 [==============================] - 2s 203ms/step - loss: 4.2288 - accuracy: 0.5250 - val_loss: 4.2968 - val_accuracy: 0.5172\n",
            "Epoch 171/1000\n",
            "10/10 [==============================] - 2s 208ms/step - loss: 3.6726 - accuracy: 0.5875 - val_loss: 4.2952 - val_accuracy: 0.5172\n",
            "Epoch 172/1000\n",
            "10/10 [==============================] - 2s 209ms/step - loss: 4.1148 - accuracy: 0.5375 - val_loss: 4.2938 - val_accuracy: 0.5172\n",
            "Epoch 173/1000\n",
            "10/10 [==============================] - 2s 210ms/step - loss: 3.2915 - accuracy: 0.6301 - val_loss: 4.2924 - val_accuracy: 0.5172\n",
            "Epoch 174/1000\n",
            "10/10 [==============================] - 2s 206ms/step - loss: 3.4466 - accuracy: 0.6125 - val_loss: 4.2900 - val_accuracy: 0.5172\n",
            "Epoch 175/1000\n",
            "10/10 [==============================] - 2s 216ms/step - loss: 4.3633 - accuracy: 0.5000 - val_loss: 0.4718 - val_accuracy: 0.6995\n",
            "Epoch 176/1000\n",
            "10/10 [==============================] - 2s 194ms/step - loss: 0.8333 - accuracy: 0.7534 - val_loss: 0.7824 - val_accuracy: 0.6207\n",
            "Epoch 177/1000\n",
            "10/10 [==============================] - 2s 200ms/step - loss: 1.3086 - accuracy: 0.6375 - val_loss: 2.8031 - val_accuracy: 0.5320\n",
            "Epoch 178/1000\n",
            "10/10 [==============================] - 2s 207ms/step - loss: 2.8182 - accuracy: 0.5125 - val_loss: 2.1376 - val_accuracy: 0.6552\n",
            "Epoch 179/1000\n",
            "10/10 [==============================] - 2s 207ms/step - loss: 2.4015 - accuracy: 0.6301 - val_loss: 3.6932 - val_accuracy: 0.4828\n",
            "Epoch 180/1000\n",
            "10/10 [==============================] - 2s 208ms/step - loss: 4.4082 - accuracy: 0.4250 - val_loss: 4.1328 - val_accuracy: 0.4828\n",
            "Epoch 181/1000\n",
            "10/10 [==============================] - 2s 210ms/step - loss: 4.5225 - accuracy: 0.4375 - val_loss: 4.2490 - val_accuracy: 0.4828\n",
            "Epoch 182/1000\n",
            "10/10 [==============================] - 2s 220ms/step - loss: 4.4012 - accuracy: 0.4625 - val_loss: 4.2519 - val_accuracy: 0.4828\n",
            "Epoch 183/1000\n",
            "10/10 [==============================] - 2s 215ms/step - loss: 5.0076 - accuracy: 0.3750 - val_loss: 4.2115 - val_accuracy: 0.4828\n",
            "Epoch 184/1000\n",
            "10/10 [==============================] - 2s 208ms/step - loss: 4.9606 - accuracy: 0.3750 - val_loss: 4.1598 - val_accuracy: 0.4828\n",
            "Epoch 185/1000\n",
            "10/10 [==============================] - 2s 223ms/step - loss: 3.9234 - accuracy: 0.5125 - val_loss: 4.1085 - val_accuracy: 0.4828\n",
            "Epoch 186/1000\n",
            "10/10 [==============================] - 2s 200ms/step - loss: 4.3216 - accuracy: 0.4500 - val_loss: 4.0613 - val_accuracy: 0.4828\n",
            "Epoch 187/1000\n",
            "10/10 [==============================] - 2s 208ms/step - loss: 3.9184 - accuracy: 0.5000 - val_loss: 4.0191 - val_accuracy: 0.4828\n",
            "Epoch 188/1000\n",
            "10/10 [==============================] - 2s 202ms/step - loss: 3.7888 - accuracy: 0.5125 - val_loss: 3.9816 - val_accuracy: 0.4828\n",
            "Epoch 189/1000\n",
            "10/10 [==============================] - 2s 205ms/step - loss: 4.1116 - accuracy: 0.4625 - val_loss: 3.9486 - val_accuracy: 0.4828\n",
            "Epoch 190/1000\n",
            "10/10 [==============================] - 2s 203ms/step - loss: 4.0558 - accuracy: 0.4658 - val_loss: 3.9195 - val_accuracy: 0.4828\n",
            "Epoch 191/1000\n",
            "10/10 [==============================] - 2s 203ms/step - loss: 4.5007 - accuracy: 0.4000 - val_loss: 3.8939 - val_accuracy: 0.4828\n",
            "Epoch 192/1000\n",
            "10/10 [==============================] - 2s 206ms/step - loss: 3.4168 - accuracy: 0.5479 - val_loss: 3.8714 - val_accuracy: 0.4828\n",
            "Epoch 193/1000\n",
            "10/10 [==============================] - 2s 208ms/step - loss: 4.0813 - accuracy: 0.4521 - val_loss: 3.8515 - val_accuracy: 0.4828\n",
            "Epoch 194/1000\n",
            "10/10 [==============================] - 2s 203ms/step - loss: 4.2573 - accuracy: 0.4250 - val_loss: 3.8340 - val_accuracy: 0.4828\n",
            "Epoch 195/1000\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 4.4399 - accuracy: 0.3973 - val_loss: 3.8187 - val_accuracy: 0.4828\n",
            "Epoch 196/1000\n",
            "10/10 [==============================] - 2s 212ms/step - loss: 4.4054 - accuracy: 0.4000 - val_loss: 3.8052 - val_accuracy: 0.4828\n",
            "Epoch 197/1000\n",
            "10/10 [==============================] - 2s 218ms/step - loss: 4.3030 - accuracy: 0.4125 - val_loss: 3.7932 - val_accuracy: 0.4828\n",
            "Epoch 198/1000\n",
            "10/10 [==============================] - 2s 204ms/step - loss: 4.7396 - accuracy: 0.3500 - val_loss: 3.7828 - val_accuracy: 0.4828\n",
            "Epoch 199/1000\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 4.1923 - accuracy: 0.4250 - val_loss: 3.7735 - val_accuracy: 0.4828\n",
            "Epoch 200/1000\n",
            "10/10 [==============================] - 2s 216ms/step - loss: 3.5567 - accuracy: 0.5125 - val_loss: 3.7654 - val_accuracy: 0.4828\n",
            "Epoch 201/1000\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 3.9818 - accuracy: 0.4521 - val_loss: 3.7583 - val_accuracy: 0.4828\n",
            "Epoch 202/1000\n",
            "10/10 [==============================] - 2s 199ms/step - loss: 4.0734 - accuracy: 0.4384 - val_loss: 3.7520 - val_accuracy: 0.4828\n",
            "Epoch 203/1000\n",
            "10/10 [==============================] - 2s 213ms/step - loss: 3.7155 - accuracy: 0.4875 - val_loss: 3.7465 - val_accuracy: 0.4828\n",
            "Epoch 204/1000\n",
            "10/10 [==============================] - 2s 210ms/step - loss: 4.1581 - accuracy: 0.4250 - val_loss: 3.7416 - val_accuracy: 0.4828\n",
            "Epoch 205/1000\n",
            "10/10 [==============================] - 2s 200ms/step - loss: 4.0579 - accuracy: 0.4384 - val_loss: 3.7373 - val_accuracy: 0.4828\n",
            "Epoch 206/1000\n",
            "10/10 [==============================] - 2s 204ms/step - loss: 3.7016 - accuracy: 0.4875 - val_loss: 3.7335 - val_accuracy: 0.4828\n",
            "Epoch 207/1000\n",
            "10/10 [==============================] - 2s 198ms/step - loss: 4.0563 - accuracy: 0.4375 - val_loss: 3.7302 - val_accuracy: 0.4828\n",
            "Epoch 208/1000\n",
            "10/10 [==============================] - 2s 209ms/step - loss: 3.7845 - accuracy: 0.4750 - val_loss: 3.7273 - val_accuracy: 0.4828\n",
            "Epoch 209/1000\n",
            "10/10 [==============================] - 2s 210ms/step - loss: 3.3339 - accuracy: 0.5375 - val_loss: 3.7247 - val_accuracy: 0.4828\n",
            "Epoch 210/1000\n",
            "10/10 [==============================] - 2s 202ms/step - loss: 4.2381 - accuracy: 0.4110 - val_loss: 3.7225 - val_accuracy: 0.4828\n",
            "Epoch 211/1000\n",
            "10/10 [==============================] - 2s 202ms/step - loss: 3.3294 - accuracy: 0.5375 - val_loss: 3.7205 - val_accuracy: 0.4828\n",
            "Epoch 212/1000\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 4.3126 - accuracy: 0.4000 - val_loss: 3.7187 - val_accuracy: 0.4828\n",
            "Epoch 213/1000\n",
            "10/10 [==============================] - 2s 213ms/step - loss: 3.3491 - accuracy: 0.5342 - val_loss: 3.7172 - val_accuracy: 0.4828\n",
            "Epoch 214/1000\n",
            "10/10 [==============================] - 2s 197ms/step - loss: 3.9513 - accuracy: 0.4500 - val_loss: 3.7158 - val_accuracy: 0.4828\n",
            "Epoch 215/1000\n",
            "10/10 [==============================] - 2s 213ms/step - loss: 4.0395 - accuracy: 0.4375 - val_loss: 3.7146 - val_accuracy: 0.4828\n",
            "Epoch 216/1000\n",
            "10/10 [==============================] - 2s 195ms/step - loss: 4.2286 - accuracy: 0.4110 - val_loss: 3.7136 - val_accuracy: 0.4828\n",
            "Epoch 217/1000\n",
            "10/10 [==============================] - 2s 210ms/step - loss: 3.5896 - accuracy: 0.5000 - val_loss: 3.7127 - val_accuracy: 0.4828\n",
            "Epoch 218/1000\n",
            "10/10 [==============================] - 2s 205ms/step - loss: 3.7679 - accuracy: 0.4750 - val_loss: 3.7103 - val_accuracy: 0.4828\n",
            "Epoch 219/1000\n",
            "10/10 [==============================] - 2s 205ms/step - loss: 4.0318 - accuracy: 0.4375 - val_loss: 3.5649 - val_accuracy: 0.4828\n",
            "Epoch 220/1000\n",
            "10/10 [==============================] - 2s 206ms/step - loss: 3.6674 - accuracy: 0.5375 - val_loss: 4.3139 - val_accuracy: 0.5172\n",
            "Epoch 221/1000\n",
            "10/10 [==============================] - 2s 206ms/step - loss: 4.3683 - accuracy: 0.5125 - val_loss: 4.3372 - val_accuracy: 0.5172\n",
            "Epoch 222/1000\n",
            "10/10 [==============================] - 2s 210ms/step - loss: 4.0499 - accuracy: 0.5500 - val_loss: 4.3426 - val_accuracy: 0.5172\n",
            "Epoch 223/1000\n",
            "10/10 [==============================] - 2s 208ms/step - loss: 4.8276 - accuracy: 0.4625 - val_loss: 4.3400 - val_accuracy: 0.5172\n",
            "Epoch 224/1000\n",
            "10/10 [==============================] - 2s 205ms/step - loss: 3.9361 - accuracy: 0.5625 - val_loss: 4.3349 - val_accuracy: 0.5172\n",
            "Epoch 225/1000\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 4.4854 - accuracy: 0.5000 - val_loss: 4.3294 - val_accuracy: 0.5172\n",
            "Epoch 226/1000\n",
            "10/10 [==============================] - 2s 205ms/step - loss: 3.9329 - accuracy: 0.5616 - val_loss: 4.3242 - val_accuracy: 0.5172\n",
            "Epoch 227/1000\n",
            "10/10 [==============================] - 2s 202ms/step - loss: 3.6985 - accuracy: 0.5875 - val_loss: 4.3194 - val_accuracy: 0.5172\n",
            "Epoch 228/1000\n",
            "10/10 [==============================] - 2s 212ms/step - loss: 3.6940 - accuracy: 0.5875 - val_loss: 4.3152 - val_accuracy: 0.5172\n",
            "Epoch 229/1000\n",
            "10/10 [==============================] - 2s 221ms/step - loss: 4.5775 - accuracy: 0.4875 - val_loss: 4.3115 - val_accuracy: 0.5172\n",
            "Epoch 230/1000\n",
            "10/10 [==============================] - 2s 209ms/step - loss: 3.0650 - accuracy: 0.6575 - val_loss: 4.3082 - val_accuracy: 0.5172\n",
            "Epoch 231/1000\n",
            "10/10 [==============================] - 2s 215ms/step - loss: 5.5692 - accuracy: 0.3750 - val_loss: 4.3054 - val_accuracy: 0.5172\n",
            "Epoch 232/1000\n",
            "10/10 [==============================] - 2s 200ms/step - loss: 3.5456 - accuracy: 0.6027 - val_loss: 4.3028 - val_accuracy: 0.5172\n",
            "Epoch 233/1000\n",
            "10/10 [==============================] - 2s 198ms/step - loss: 3.7892 - accuracy: 0.5750 - val_loss: 4.3006 - val_accuracy: 0.5172\n",
            "Epoch 234/1000\n",
            "10/10 [==============================] - 2s 203ms/step - loss: 3.7840 - accuracy: 0.5753 - val_loss: 4.2986 - val_accuracy: 0.5172\n",
            "Epoch 235/1000\n",
            "10/10 [==============================] - 2s 209ms/step - loss: 4.1180 - accuracy: 0.5375 - val_loss: 4.2969 - val_accuracy: 0.5172\n",
            "Epoch 236/1000\n",
            "10/10 [==============================] - 2s 210ms/step - loss: 4.1164 - accuracy: 0.5375 - val_loss: 4.2954 - val_accuracy: 0.5172\n",
            "Epoch 237/1000\n",
            "10/10 [==============================] - 2s 197ms/step - loss: 4.5086 - accuracy: 0.4932 - val_loss: 4.2940 - val_accuracy: 0.5172\n",
            "Epoch 238/1000\n",
            "10/10 [==============================] - 2s 207ms/step - loss: 4.6683 - accuracy: 0.4750 - val_loss: 4.2928 - val_accuracy: 0.5172\n",
            "Epoch 239/1000\n",
            "10/10 [==============================] - 2s 207ms/step - loss: 3.2251 - accuracy: 0.6375 - val_loss: 4.2917 - val_accuracy: 0.5172\n",
            "Epoch 240/1000\n",
            "10/10 [==============================] - 2s 198ms/step - loss: 2.8032 - accuracy: 0.6849 - val_loss: 4.2905 - val_accuracy: 0.5172\n",
            "Epoch 241/1000\n",
            "10/10 [==============================] - 2s 214ms/step - loss: 3.7742 - accuracy: 0.5753 - val_loss: 4.2878 - val_accuracy: 0.5172\n",
            "Epoch 242/1000\n",
            "10/10 [==============================] - 2s 202ms/step - loss: 3.5466 - accuracy: 0.5375 - val_loss: 2.8075 - val_accuracy: 0.4828\n",
            "Epoch 243/1000\n",
            "10/10 [==============================] - 2s 198ms/step - loss: 1.3350 - accuracy: 0.6250 - val_loss: 1.2174 - val_accuracy: 0.7291\n",
            "Epoch 244/1000\n",
            "10/10 [==============================] - 2s 199ms/step - loss: 1.0624 - accuracy: 0.6750 - val_loss: 2.2844 - val_accuracy: 0.5369\n",
            "Epoch 245/1000\n",
            "10/10 [==============================] - 2s 211ms/step - loss: 1.2531 - accuracy: 0.7250 - val_loss: 1.6331 - val_accuracy: 0.6946\n",
            "Epoch 246/1000\n",
            "10/10 [==============================] - 2s 202ms/step - loss: 0.8477 - accuracy: 0.8125 - val_loss: 3.2059 - val_accuracy: 0.5665\n",
            "Epoch 247/1000\n",
            "10/10 [==============================] - 2s 215ms/step - loss: 1.6158 - accuracy: 0.6875 - val_loss: 2.8856 - val_accuracy: 0.5813\n",
            "Epoch 248/1000\n",
            "10/10 [==============================] - 2s 194ms/step - loss: 2.7579 - accuracy: 0.5753 - val_loss: 3.9505 - val_accuracy: 0.4828\n",
            "Epoch 249/1000\n",
            "10/10 [==============================] - 2s 205ms/step - loss: 4.5743 - accuracy: 0.4000 - val_loss: 4.0058 - val_accuracy: 0.4828\n",
            "Epoch 250/1000\n",
            "10/10 [==============================] - 2s 208ms/step - loss: 3.7959 - accuracy: 0.5125 - val_loss: 4.0062 - val_accuracy: 0.4828\n",
            "Epoch 251/1000\n",
            "10/10 [==============================] - 2s 199ms/step - loss: 4.8588 - accuracy: 0.3625 - val_loss: 3.9839 - val_accuracy: 0.4828\n",
            "Epoch 252/1000\n",
            "10/10 [==============================] - 2s 204ms/step - loss: 4.3850 - accuracy: 0.4250 - val_loss: 3.9554 - val_accuracy: 0.4828\n",
            "Epoch 253/1000\n",
            "10/10 [==============================] - 2s 194ms/step - loss: 4.5355 - accuracy: 0.4000 - val_loss: 3.9272 - val_accuracy: 0.4828\n",
            "Epoch 254/1000\n",
            "10/10 [==============================] - 2s 207ms/step - loss: 3.8405 - accuracy: 0.4932 - val_loss: 3.9013 - val_accuracy: 0.4828\n",
            "Epoch 255/1000\n",
            "10/10 [==============================] - 2s 199ms/step - loss: 4.2149 - accuracy: 0.4375 - val_loss: 3.8780 - val_accuracy: 0.4828\n",
            "Epoch 256/1000\n",
            "10/10 [==============================] - 2s 207ms/step - loss: 4.5511 - accuracy: 0.3875 - val_loss: 3.8575 - val_accuracy: 0.4828\n",
            "Epoch 257/1000\n",
            "10/10 [==============================] - 2s 198ms/step - loss: 4.6581 - accuracy: 0.3699 - val_loss: 3.8393 - val_accuracy: 0.4828\n",
            "Epoch 258/1000\n",
            "10/10 [==============================] - 2s 209ms/step - loss: 4.6414 - accuracy: 0.3699 - val_loss: 3.8233 - val_accuracy: 0.4828\n",
            "Epoch 259/1000\n",
            "10/10 [==============================] - 2s 196ms/step - loss: 3.6038 - accuracy: 0.5125 - val_loss: 3.8092 - val_accuracy: 0.4828\n",
            "Epoch 260/1000\n",
            "10/10 [==============================] - 2s 212ms/step - loss: 3.6800 - accuracy: 0.5000 - val_loss: 3.7968 - val_accuracy: 0.4828\n",
            "Epoch 261/1000\n",
            "10/10 [==============================] - 2s 197ms/step - loss: 4.0122 - accuracy: 0.4521 - val_loss: 3.7859 - val_accuracy: 0.4828\n",
            "Epoch 262/1000\n",
            "10/10 [==============================] - 2s 206ms/step - loss: 3.7072 - accuracy: 0.4932 - val_loss: 3.7763 - val_accuracy: 0.4828\n",
            "Epoch 263/1000\n",
            "10/10 [==============================] - 2s 206ms/step - loss: 4.0071 - accuracy: 0.4500 - val_loss: 3.7679 - val_accuracy: 0.4828\n",
            "Epoch 264/1000\n",
            "10/10 [==============================] - 2s 218ms/step - loss: 3.4618 - accuracy: 0.5250 - val_loss: 3.7604 - val_accuracy: 0.4828\n",
            "Epoch 265/1000\n",
            "10/10 [==============================] - 2s 212ms/step - loss: 3.9026 - accuracy: 0.4625 - val_loss: 3.7539 - val_accuracy: 0.4828\n",
            "Epoch 266/1000\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 4.5601 - accuracy: 0.3699 - val_loss: 3.7481 - val_accuracy: 0.4828\n",
            "Epoch 267/1000\n",
            "10/10 [==============================] - 2s 199ms/step - loss: 3.8910 - accuracy: 0.4625 - val_loss: 3.7431 - val_accuracy: 0.4828\n",
            "Epoch 268/1000\n",
            "10/10 [==============================] - 2s 212ms/step - loss: 3.7966 - accuracy: 0.4750 - val_loss: 3.7386 - val_accuracy: 0.4828\n",
            "Epoch 269/1000\n",
            "10/10 [==============================] - 2s 205ms/step - loss: 3.3446 - accuracy: 0.5375 - val_loss: 3.7347 - val_accuracy: 0.4828\n",
            "Epoch 270/1000\n",
            "10/10 [==============================] - 2s 205ms/step - loss: 4.5052 - accuracy: 0.3750 - val_loss: 3.7312 - val_accuracy: 0.4828\n",
            "Epoch 271/1000\n",
            "10/10 [==============================] - 2s 205ms/step - loss: 3.7854 - accuracy: 0.4750 - val_loss: 3.7282 - val_accuracy: 0.4828\n",
            "Epoch 272/1000\n",
            "10/10 [==============================] - 2s 200ms/step - loss: 4.1408 - accuracy: 0.4250 - val_loss: 3.7255 - val_accuracy: 0.4828\n",
            "Epoch 273/1000\n",
            "10/10 [==============================] - 2s 203ms/step - loss: 3.9444 - accuracy: 0.4521 - val_loss: 3.7232 - val_accuracy: 0.4828\n",
            "Epoch 274/1000\n",
            "10/10 [==============================] - 2s 206ms/step - loss: 4.0347 - accuracy: 0.4375 - val_loss: 3.5601 - val_accuracy: 0.4828\n",
            "Epoch 275/1000\n",
            "10/10 [==============================] - 2s 216ms/step - loss: 2.1592 - accuracy: 0.5125 - val_loss: 1.0659 - val_accuracy: 0.7094\n",
            "Epoch 276/1000\n",
            "10/10 [==============================] - 2s 195ms/step - loss: 0.9956 - accuracy: 0.7250 - val_loss: 1.2920 - val_accuracy: 0.7143\n",
            "Epoch 277/1000\n",
            "10/10 [==============================] - 2s 205ms/step - loss: 0.7400 - accuracy: 0.8125 - val_loss: 1.3478 - val_accuracy: 0.6650\n",
            "Epoch 278/1000\n",
            "10/10 [==============================] - 2s 206ms/step - loss: 2.4154 - accuracy: 0.5753 - val_loss: 3.6334 - val_accuracy: 0.5123\n",
            "Epoch 279/1000\n",
            "10/10 [==============================] - 2s 209ms/step - loss: 1.9961 - accuracy: 0.6875 - val_loss: 1.8600 - val_accuracy: 0.6158\n",
            "Epoch 280/1000\n",
            "10/10 [==============================] - 2s 205ms/step - loss: 1.5131 - accuracy: 0.7375 - val_loss: 1.7813 - val_accuracy: 0.6749\n",
            "Epoch 281/1000\n",
            "10/10 [==============================] - 2s 208ms/step - loss: 1.3109 - accuracy: 0.7750 - val_loss: 1.9622 - val_accuracy: 0.6847\n",
            "Epoch 282/1000\n",
            "10/10 [==============================] - 2s 207ms/step - loss: 1.0209 - accuracy: 0.8500 - val_loss: 1.3554 - val_accuracy: 0.7537\n",
            "Epoch 283/1000\n",
            "10/10 [==============================] - 2s 216ms/step - loss: 1.1177 - accuracy: 0.7945 - val_loss: 1.5069 - val_accuracy: 0.7389\n",
            "Epoch 284/1000\n",
            "10/10 [==============================] - 2s 202ms/step - loss: 1.0501 - accuracy: 0.7875 - val_loss: 1.3930 - val_accuracy: 0.7192\n",
            "Epoch 285/1000\n",
            "10/10 [==============================] - 2s 209ms/step - loss: 0.9847 - accuracy: 0.8000 - val_loss: 2.0860 - val_accuracy: 0.6749\n",
            "Epoch 286/1000\n",
            "10/10 [==============================] - 2s 202ms/step - loss: 1.2951 - accuracy: 0.7375 - val_loss: 3.3467 - val_accuracy: 0.5714\n",
            "Epoch 287/1000\n",
            "10/10 [==============================] - 2s 198ms/step - loss: 1.4997 - accuracy: 0.7750 - val_loss: 2.1703 - val_accuracy: 0.6700\n",
            "Epoch 288/1000\n",
            "10/10 [==============================] - 2s 213ms/step - loss: 1.5738 - accuracy: 0.7000 - val_loss: 1.6912 - val_accuracy: 0.7241\n",
            "Epoch 289/1000\n",
            "10/10 [==============================] - 2s 203ms/step - loss: 2.5999 - accuracy: 0.6301 - val_loss: 4.0445 - val_accuracy: 0.4828\n",
            "Epoch 290/1000\n",
            "10/10 [==============================] - 2s 204ms/step - loss: 4.8868 - accuracy: 0.3699 - val_loss: 4.1105 - val_accuracy: 0.4828\n",
            "Epoch 291/1000\n",
            "10/10 [==============================] - 2s 203ms/step - loss: 4.3493 - accuracy: 0.4500 - val_loss: 4.1109 - val_accuracy: 0.4828\n",
            "Epoch 292/1000\n",
            "10/10 [==============================] - 2s 204ms/step - loss: 4.4231 - accuracy: 0.4375 - val_loss: 4.0810 - val_accuracy: 0.4828\n",
            "Epoch 293/1000\n",
            "10/10 [==============================] - 2s 206ms/step - loss: 4.2092 - accuracy: 0.4625 - val_loss: 4.0428 - val_accuracy: 0.4828\n",
            "Epoch 294/1000\n",
            "10/10 [==============================] - 2s 206ms/step - loss: 4.6184 - accuracy: 0.4000 - val_loss: 4.0048 - val_accuracy: 0.4828\n",
            "Epoch 295/1000\n",
            "10/10 [==============================] - 2s 218ms/step - loss: 4.4025 - accuracy: 0.4250 - val_loss: 3.9698 - val_accuracy: 0.4828\n",
            "Epoch 296/1000\n",
            "10/10 [==============================] - 2s 197ms/step - loss: 4.6378 - accuracy: 0.3875 - val_loss: 3.9384 - val_accuracy: 0.4828\n",
            "Epoch 297/1000\n",
            "10/10 [==============================] - 2s 204ms/step - loss: 3.6230 - accuracy: 0.5250 - val_loss: 3.9106 - val_accuracy: 0.4828\n",
            "Epoch 298/1000\n",
            "10/10 [==============================] - 2s 207ms/step - loss: 3.5967 - accuracy: 0.5250 - val_loss: 3.8861 - val_accuracy: 0.4828\n",
            "Epoch 299/1000\n",
            "10/10 [==============================] - 2s 203ms/step - loss: 4.2928 - accuracy: 0.4247 - val_loss: 3.8645 - val_accuracy: 0.4828\n",
            "Epoch 300/1000\n",
            "10/10 [==============================] - 2s 198ms/step - loss: 4.0904 - accuracy: 0.4500 - val_loss: 3.8455 - val_accuracy: 0.4828\n",
            "Epoch 301/1000\n",
            "10/10 [==============================] - 2s 203ms/step - loss: 4.3426 - accuracy: 0.4125 - val_loss: 3.8336 - val_accuracy: 0.4828\n",
            "Epoch 302/1000\n",
            "10/10 [==============================] - 2s 200ms/step - loss: 3.6583 - accuracy: 0.5068 - val_loss: 3.8286 - val_accuracy: 0.4828\n",
            "Epoch 303/1000\n",
            "10/10 [==============================] - 2s 210ms/step - loss: 4.3307 - accuracy: 0.4125 - val_loss: 3.8259 - val_accuracy: 0.4828\n",
            "Epoch 304/1000\n",
            "10/10 [==============================] - 2s 220ms/step - loss: 4.4180 - accuracy: 0.4000 - val_loss: 3.8241 - val_accuracy: 0.4828\n",
            "Epoch 305/1000\n",
            "10/10 [==============================] - 2s 199ms/step - loss: 3.7489 - accuracy: 0.4932 - val_loss: 3.8225 - val_accuracy: 0.4828\n",
            "Epoch 306/1000\n",
            "10/10 [==============================] - 2s 204ms/step - loss: 3.5192 - accuracy: 0.5250 - val_loss: 3.8211 - val_accuracy: 0.4828\n",
            "Epoch 307/1000\n",
            "10/10 [==============================] - 2s 204ms/step - loss: 4.1447 - accuracy: 0.4375 - val_loss: 3.8197 - val_accuracy: 0.4828\n",
            "Epoch 308/1000\n",
            "10/10 [==============================] - 2s 198ms/step - loss: 3.8746 - accuracy: 0.4750 - val_loss: 3.8183 - val_accuracy: 0.4828\n",
            "Epoch 309/1000\n",
            "10/10 [==============================] - 2s 206ms/step - loss: 4.6793 - accuracy: 0.3625 - val_loss: 3.8169 - val_accuracy: 0.4828\n",
            "Epoch 310/1000\n",
            "10/10 [==============================] - 2s 208ms/step - loss: 4.1406 - accuracy: 0.4375 - val_loss: 3.8156 - val_accuracy: 0.4828\n",
            "Epoch 311/1000\n",
            "10/10 [==============================] - 2s 213ms/step - loss: 4.3294 - accuracy: 0.4110 - val_loss: 3.8143 - val_accuracy: 0.4828\n",
            "Epoch 312/1000\n",
            "10/10 [==============================] - 2s 207ms/step - loss: 4.3171 - accuracy: 0.4125 - val_loss: 3.8130 - val_accuracy: 0.4828\n",
            "Epoch 313/1000\n",
            "10/10 [==============================] - 2s 214ms/step - loss: 3.1515 - accuracy: 0.5750 - val_loss: 3.8117 - val_accuracy: 0.4828\n",
            "Epoch 314/1000\n",
            "10/10 [==============================] - 2s 211ms/step - loss: 4.2250 - accuracy: 0.4250 - val_loss: 3.8104 - val_accuracy: 0.4828\n",
            "Epoch 315/1000\n",
            "10/10 [==============================] - 2s 213ms/step - loss: 4.0446 - accuracy: 0.4500 - val_loss: 3.8092 - val_accuracy: 0.4828\n",
            "Epoch 316/1000\n",
            "10/10 [==============================] - 2s 206ms/step - loss: 4.2224 - accuracy: 0.4250 - val_loss: 3.8079 - val_accuracy: 0.4828\n",
            "Epoch 317/1000\n",
            "10/10 [==============================] - 2s 204ms/step - loss: 3.5943 - accuracy: 0.5125 - val_loss: 3.8067 - val_accuracy: 0.4828\n",
            "Epoch 318/1000\n",
            "10/10 [==============================] - 2s 205ms/step - loss: 4.1304 - accuracy: 0.4375 - val_loss: 3.8055 - val_accuracy: 0.4828\n",
            "Epoch 319/1000\n",
            "10/10 [==============================] - 2s 204ms/step - loss: 4.0397 - accuracy: 0.4500 - val_loss: 3.8043 - val_accuracy: 0.4828\n",
            "Epoch 320/1000\n",
            "10/10 [==============================] - 2s 217ms/step - loss: 4.3072 - accuracy: 0.4125 - val_loss: 3.8031 - val_accuracy: 0.4828\n",
            "Epoch 321/1000\n",
            "10/10 [==============================] - 2s 207ms/step - loss: 3.7281 - accuracy: 0.4932 - val_loss: 3.8020 - val_accuracy: 0.4828\n",
            "Epoch 322/1000\n",
            "10/10 [==============================] - 2s 205ms/step - loss: 4.3944 - accuracy: 0.4000 - val_loss: 3.8008 - val_accuracy: 0.4828\n",
            "Epoch 323/1000\n",
            "10/10 [==============================] - 2s 208ms/step - loss: 3.9454 - accuracy: 0.4625 - val_loss: 3.7997 - val_accuracy: 0.4828\n",
            "Epoch 324/1000\n",
            "10/10 [==============================] - 2s 210ms/step - loss: 4.5712 - accuracy: 0.3750 - val_loss: 3.7985 - val_accuracy: 0.4828\n",
            "Epoch 325/1000\n",
            "10/10 [==============================] - 2s 196ms/step - loss: 3.9432 - accuracy: 0.4625 - val_loss: 3.7974 - val_accuracy: 0.4828\n",
            "Epoch 326/1000\n",
            "10/10 [==============================] - 2s 198ms/step - loss: 4.4794 - accuracy: 0.3875 - val_loss: 3.7963 - val_accuracy: 0.4828\n",
            "Epoch 327/1000\n",
            "10/10 [==============================] - 2s 209ms/step - loss: 4.2992 - accuracy: 0.4125 - val_loss: 3.7952 - val_accuracy: 0.4828\n",
            "Epoch 328/1000\n",
            "10/10 [==============================] - 2s 219ms/step - loss: 4.2086 - accuracy: 0.4250 - val_loss: 3.7942 - val_accuracy: 0.4828\n",
            "Epoch 329/1000\n",
            "10/10 [==============================] - 2s 212ms/step - loss: 4.1180 - accuracy: 0.4375 - val_loss: 3.7931 - val_accuracy: 0.4828\n",
            "Epoch 330/1000\n",
            "10/10 [==============================] - 2s 207ms/step - loss: 3.5796 - accuracy: 0.5125 - val_loss: 3.7921 - val_accuracy: 0.4828\n",
            "Epoch 331/1000\n",
            "10/10 [==============================] - 2s 204ms/step - loss: 4.0116 - accuracy: 0.4521 - val_loss: 3.7910 - val_accuracy: 0.4828\n",
            "Epoch 332/1000\n",
            "10/10 [==============================] - 2s 215ms/step - loss: 3.1297 - accuracy: 0.5750 - val_loss: 3.7900 - val_accuracy: 0.4828\n",
            "Epoch 333/1000\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 3.3974 - accuracy: 0.5375 - val_loss: 3.7890 - val_accuracy: 0.4828\n",
            "Epoch 334/1000\n",
            "10/10 [==============================] - 2s 206ms/step - loss: 4.4711 - accuracy: 0.3875 - val_loss: 3.7880 - val_accuracy: 0.4828\n",
            "Epoch 335/1000\n",
            "10/10 [==============================] - 2s 208ms/step - loss: 3.5745 - accuracy: 0.5125 - val_loss: 3.7870 - val_accuracy: 0.4828\n",
            "Epoch 336/1000\n",
            "10/10 [==============================] - 2s 207ms/step - loss: 4.5586 - accuracy: 0.3750 - val_loss: 3.7860 - val_accuracy: 0.4828\n",
            "Epoch 337/1000\n",
            "10/10 [==============================] - 2s 198ms/step - loss: 4.4681 - accuracy: 0.3875 - val_loss: 3.7851 - val_accuracy: 0.4828\n",
            "Epoch 338/1000\n",
            "10/10 [==============================] - 2s 199ms/step - loss: 4.5567 - accuracy: 0.3750 - val_loss: 3.7841 - val_accuracy: 0.4828\n",
            "Epoch 339/1000\n",
            "10/10 [==============================] - 2s 208ms/step - loss: 3.5706 - accuracy: 0.5125 - val_loss: 3.7832 - val_accuracy: 0.4828\n",
            "Epoch 340/1000\n",
            "10/10 [==============================] - 2s 210ms/step - loss: 3.4801 - accuracy: 0.5250 - val_loss: 3.7823 - val_accuracy: 0.4828\n",
            "Epoch 341/1000\n",
            "10/10 [==============================] - 2s 203ms/step - loss: 3.6583 - accuracy: 0.5000 - val_loss: 3.7814 - val_accuracy: 0.4828\n",
            "Epoch 342/1000\n",
            "10/10 [==============================] - 2s 200ms/step - loss: 4.1948 - accuracy: 0.4250 - val_loss: 3.7804 - val_accuracy: 0.4828\n",
            "Epoch 343/1000\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 3.9252 - accuracy: 0.4625 - val_loss: 3.7796 - val_accuracy: 0.4828\n",
            "Epoch 344/1000\n",
            "10/10 [==============================] - 2s 214ms/step - loss: 3.7452 - accuracy: 0.4875 - val_loss: 3.7787 - val_accuracy: 0.4828\n",
            "Epoch 345/1000\n",
            "10/10 [==============================] - 2s 204ms/step - loss: 4.7295 - accuracy: 0.3500 - val_loss: 3.7778 - val_accuracy: 0.4828\n",
            "Epoch 346/1000\n",
            "10/10 [==============================] - 2s 209ms/step - loss: 3.9226 - accuracy: 0.4625 - val_loss: 3.7769 - val_accuracy: 0.4828\n",
            "Epoch 347/1000\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 3.8002 - accuracy: 0.4795 - val_loss: 3.7761 - val_accuracy: 0.4828\n",
            "Epoch 348/1000\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 3.4731 - accuracy: 0.5250 - val_loss: 3.7752 - val_accuracy: 0.4828\n",
            "Epoch 349/1000\n",
            "10/10 [==============================] - 2s 205ms/step - loss: 3.9200 - accuracy: 0.4625 - val_loss: 3.7744 - val_accuracy: 0.4828\n",
            "Epoch 350/1000\n",
            "10/10 [==============================] - 2s 195ms/step - loss: 4.4565 - accuracy: 0.3875 - val_loss: 3.7736 - val_accuracy: 0.4828\n",
            "Epoch 351/1000\n",
            "10/10 [==============================] - 2s 215ms/step - loss: 4.0079 - accuracy: 0.4500 - val_loss: 3.7728 - val_accuracy: 0.4828\n",
            "Epoch 352/1000\n",
            "10/10 [==============================] - 2s 198ms/step - loss: 4.5445 - accuracy: 0.3750 - val_loss: 3.7720 - val_accuracy: 0.4828\n",
            "Epoch 353/1000\n",
            "10/10 [==============================] - 2s 204ms/step - loss: 4.0063 - accuracy: 0.4500 - val_loss: 3.7712 - val_accuracy: 0.4828\n",
            "Epoch 354/1000\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 3.6473 - accuracy: 0.5000 - val_loss: 3.7704 - val_accuracy: 0.4828\n",
            "Epoch 355/1000\n",
            "10/10 [==============================] - 2s 199ms/step - loss: 4.3630 - accuracy: 0.4000 - val_loss: 3.7696 - val_accuracy: 0.4828\n",
            "Epoch 356/1000\n",
            "10/10 [==============================] - 2s 210ms/step - loss: 4.3622 - accuracy: 0.4000 - val_loss: 3.7689 - val_accuracy: 0.4828\n",
            "Epoch 357/1000\n",
            "10/10 [==============================] - 2s 198ms/step - loss: 4.0928 - accuracy: 0.4375 - val_loss: 3.7681 - val_accuracy: 0.4828\n",
            "Epoch 358/1000\n",
            "10/10 [==============================] - 2s 210ms/step - loss: 3.8234 - accuracy: 0.4750 - val_loss: 3.7674 - val_accuracy: 0.4828\n",
            "Epoch 359/1000\n",
            "10/10 [==============================] - 2s 195ms/step - loss: 4.1833 - accuracy: 0.4247 - val_loss: 3.7666 - val_accuracy: 0.4828\n",
            "Epoch 360/1000\n",
            "10/10 [==============================] - 2s 202ms/step - loss: 3.4955 - accuracy: 0.5205 - val_loss: 3.7659 - val_accuracy: 0.4828\n",
            "Epoch 361/1000\n",
            "10/10 [==============================] - 2s 200ms/step - loss: 4.6272 - accuracy: 0.3625 - val_loss: 3.7652 - val_accuracy: 0.4828\n",
            "Epoch 362/1000\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 4.9847 - accuracy: 0.3125 - val_loss: 3.7645 - val_accuracy: 0.4828\n",
            "Epoch 363/1000\n",
            "10/10 [==============================] - 2s 210ms/step - loss: 3.9988 - accuracy: 0.4500 - val_loss: 3.7638 - val_accuracy: 0.4828\n",
            "Epoch 364/1000\n",
            "10/10 [==============================] - 2s 199ms/step - loss: 4.2668 - accuracy: 0.4125 - val_loss: 3.7631 - val_accuracy: 0.4828\n",
            "Epoch 365/1000\n",
            "10/10 [==============================] - 2s 199ms/step - loss: 4.4452 - accuracy: 0.3875 - val_loss: 3.7624 - val_accuracy: 0.4828\n",
            "Epoch 366/1000\n",
            "10/10 [==============================] - 2s 204ms/step - loss: 5.1610 - accuracy: 0.2875 - val_loss: 3.7617 - val_accuracy: 0.4828\n",
            "Epoch 367/1000\n",
            "10/10 [==============================] - 2s 195ms/step - loss: 3.9065 - accuracy: 0.4625 - val_loss: 3.7610 - val_accuracy: 0.4828\n",
            "Epoch 368/1000\n",
            "10/10 [==============================] - 2s 203ms/step - loss: 3.8163 - accuracy: 0.4750 - val_loss: 3.7604 - val_accuracy: 0.4828\n",
            "Epoch 369/1000\n",
            "10/10 [==============================] - 2s 196ms/step - loss: 4.6217 - accuracy: 0.3625 - val_loss: 3.7597 - val_accuracy: 0.4828\n",
            "Epoch 370/1000\n",
            "10/10 [==============================] - 2s 209ms/step - loss: 3.4568 - accuracy: 0.5250 - val_loss: 3.7591 - val_accuracy: 0.4828\n",
            "Epoch 371/1000\n",
            "10/10 [==============================] - 2s 224ms/step - loss: 3.8144 - accuracy: 0.4750 - val_loss: 3.7584 - val_accuracy: 0.4828\n",
            "Epoch 372/1000\n",
            "10/10 [==============================] - 2s 199ms/step - loss: 3.7242 - accuracy: 0.4875 - val_loss: 3.7578 - val_accuracy: 0.4828\n",
            "Epoch 373/1000\n",
            "10/10 [==============================] - 2s 211ms/step - loss: 4.1713 - accuracy: 0.4250 - val_loss: 3.7572 - val_accuracy: 0.4828\n",
            "Epoch 374/1000\n",
            "10/10 [==============================] - 2s 206ms/step - loss: 4.2603 - accuracy: 0.4125 - val_loss: 3.7566 - val_accuracy: 0.4828\n",
            "Epoch 375/1000\n",
            "10/10 [==============================] - 2s 204ms/step - loss: 3.0930 - accuracy: 0.5753 - val_loss: 3.7559 - val_accuracy: 0.4828\n",
            "Epoch 376/1000\n",
            "10/10 [==============================] - 2s 210ms/step - loss: 3.8113 - accuracy: 0.4750 - val_loss: 3.7553 - val_accuracy: 0.4828\n",
            "Epoch 377/1000\n",
            "10/10 [==============================] - 2s 206ms/step - loss: 3.8769 - accuracy: 0.4658 - val_loss: 3.7548 - val_accuracy: 0.4828\n",
            "Epoch 378/1000\n",
            "10/10 [==============================] - 2s 195ms/step - loss: 3.8763 - accuracy: 0.4658 - val_loss: 3.7542 - val_accuracy: 0.4828\n",
            "Epoch 379/1000\n",
            "10/10 [==============================] - 2s 209ms/step - loss: 4.1677 - accuracy: 0.4250 - val_loss: 3.7536 - val_accuracy: 0.4828\n",
            "Epoch 380/1000\n",
            "10/10 [==============================] - 2s 195ms/step - loss: 3.9880 - accuracy: 0.4500 - val_loss: 3.7530 - val_accuracy: 0.4828\n",
            "Epoch 381/1000\n",
            "10/10 [==============================] - 2s 200ms/step - loss: 3.8979 - accuracy: 0.4625 - val_loss: 3.7525 - val_accuracy: 0.4828\n",
            "Epoch 382/1000\n",
            "10/10 [==============================] - 2s 210ms/step - loss: 3.7182 - accuracy: 0.4875 - val_loss: 3.7519 - val_accuracy: 0.4828\n",
            "Epoch 383/1000\n",
            "10/10 [==============================] - 2s 197ms/step - loss: 3.6281 - accuracy: 0.5000 - val_loss: 3.7513 - val_accuracy: 0.4828\n",
            "Epoch 384/1000\n",
            "10/10 [==============================] - 2s 207ms/step - loss: 3.8729 - accuracy: 0.4658 - val_loss: 3.7508 - val_accuracy: 0.4828\n",
            "Epoch 385/1000\n",
            "10/10 [==============================] - 2s 210ms/step - loss: 4.4613 - accuracy: 0.3836 - val_loss: 3.7503 - val_accuracy: 0.4828\n",
            "Epoch 386/1000\n",
            "10/10 [==============================] - 2s 204ms/step - loss: 4.2534 - accuracy: 0.4125 - val_loss: 3.7497 - val_accuracy: 0.4828\n",
            "Epoch 387/1000\n",
            "10/10 [==============================] - 2s 197ms/step - loss: 3.3573 - accuracy: 0.5375 - val_loss: 3.7492 - val_accuracy: 0.4828\n",
            "Epoch 388/1000\n",
            "10/10 [==============================] - 2s 202ms/step - loss: 3.9690 - accuracy: 0.4521 - val_loss: 3.7487 - val_accuracy: 0.4828\n",
            "Epoch 389/1000\n",
            "10/10 [==============================] - 2s 207ms/step - loss: 4.2518 - accuracy: 0.4125 - val_loss: 3.7482 - val_accuracy: 0.4828\n",
            "Epoch 390/1000\n",
            "10/10 [==============================] - 2s 209ms/step - loss: 3.5753 - accuracy: 0.5068 - val_loss: 3.7477 - val_accuracy: 0.4828\n",
            "Epoch 391/1000\n",
            "10/10 [==============================] - 2s 210ms/step - loss: 3.2657 - accuracy: 0.5500 - val_loss: 3.7472 - val_accuracy: 0.4828\n",
            "Epoch 392/1000\n",
            "10/10 [==============================] - 2s 213ms/step - loss: 4.0712 - accuracy: 0.4375 - val_loss: 3.7467 - val_accuracy: 0.4828\n",
            "Epoch 393/1000\n",
            "10/10 [==============================] - 2s 246ms/step - loss: 3.8020 - accuracy: 0.4750 - val_loss: 3.7462 - val_accuracy: 0.4828\n",
            "Epoch 394/1000\n",
            "10/10 [==============================] - 2s 194ms/step - loss: 4.6971 - accuracy: 0.3500 - val_loss: 3.7457 - val_accuracy: 0.4828\n",
            "Epoch 395/1000\n",
            "10/10 [==============================] - 2s 202ms/step - loss: 4.2489 - accuracy: 0.4125 - val_loss: 3.7452 - val_accuracy: 0.4828\n",
            "Epoch 396/1000\n",
            "10/10 [==============================] - 2s 209ms/step - loss: 3.4424 - accuracy: 0.5250 - val_loss: 3.7447 - val_accuracy: 0.4828\n",
            "Epoch 397/1000\n",
            "10/10 [==============================] - 2s 203ms/step - loss: 4.1584 - accuracy: 0.4250 - val_loss: 3.7443 - val_accuracy: 0.4828\n",
            "Epoch 398/1000\n",
            "10/10 [==============================] - 2s 200ms/step - loss: 3.7997 - accuracy: 0.4750 - val_loss: 3.7438 - val_accuracy: 0.4828\n",
            "Epoch 399/1000\n",
            "10/10 [==============================] - 2s 196ms/step - loss: 4.4261 - accuracy: 0.3875 - val_loss: 3.7434 - val_accuracy: 0.4828\n",
            "Epoch 400/1000\n",
            "10/10 [==============================] - 2s 199ms/step - loss: 3.5301 - accuracy: 0.5125 - val_loss: 3.7429 - val_accuracy: 0.4828\n",
            "Epoch 401/1000\n",
            "10/10 [==============================] - 2s 203ms/step - loss: 4.4252 - accuracy: 0.3875 - val_loss: 3.7425 - val_accuracy: 0.4828\n",
            "Epoch 402/1000\n",
            "10/10 [==============================] - 2s 204ms/step - loss: 4.0665 - accuracy: 0.4375 - val_loss: 3.7420 - val_accuracy: 0.4828\n",
            "Epoch 403/1000\n",
            "10/10 [==============================] - 2s 212ms/step - loss: 3.7974 - accuracy: 0.4750 - val_loss: 3.7416 - val_accuracy: 0.4828\n",
            "Epoch 404/1000\n",
            "10/10 [==============================] - 2s 199ms/step - loss: 3.5283 - accuracy: 0.5125 - val_loss: 3.7412 - val_accuracy: 0.4828\n",
            "Epoch 405/1000\n",
            "10/10 [==============================] - 2s 197ms/step - loss: 4.0652 - accuracy: 0.4375 - val_loss: 3.7407 - val_accuracy: 0.4828\n",
            "Epoch 406/1000\n",
            "10/10 [==============================] - 2s 204ms/step - loss: 4.4230 - accuracy: 0.3875 - val_loss: 3.7403 - val_accuracy: 0.4828\n",
            "Epoch 407/1000\n",
            "10/10 [==============================] - 2s 208ms/step - loss: 3.2584 - accuracy: 0.5500 - val_loss: 3.7399 - val_accuracy: 0.4828\n",
            "Epoch 408/1000\n",
            "10/10 [==============================] - 2s 197ms/step - loss: 3.5671 - accuracy: 0.5068 - val_loss: 3.7395 - val_accuracy: 0.4828\n",
            "Epoch 409/1000\n",
            "10/10 [==============================] - 2s 193ms/step - loss: 4.2537 - accuracy: 0.4110 - val_loss: 3.7391 - val_accuracy: 0.4828\n",
            "Epoch 410/1000\n",
            "10/10 [==============================] - 2s 196ms/step - loss: 3.4363 - accuracy: 0.5250 - val_loss: 3.7387 - val_accuracy: 0.4828\n",
            "Epoch 411/1000\n",
            "10/10 [==============================] - 2s 197ms/step - loss: 4.5106 - accuracy: 0.3750 - val_loss: 3.7383 - val_accuracy: 0.4828\n",
            "Epoch 412/1000\n",
            "10/10 [==============================] - 2s 205ms/step - loss: 3.9728 - accuracy: 0.4500 - val_loss: 3.7379 - val_accuracy: 0.4828\n",
            "Epoch 413/1000\n",
            "10/10 [==============================] - 2s 206ms/step - loss: 3.6142 - accuracy: 0.5000 - val_loss: 3.7375 - val_accuracy: 0.4828\n",
            "Epoch 414/1000\n",
            "10/10 [==============================] - 2s 202ms/step - loss: 3.3452 - accuracy: 0.5375 - val_loss: 3.7372 - val_accuracy: 0.4828\n",
            "Epoch 415/1000\n",
            "10/10 [==============================] - 2s 198ms/step - loss: 3.3681 - accuracy: 0.5342 - val_loss: 3.7368 - val_accuracy: 0.4828\n",
            "Epoch 416/1000\n",
            "10/10 [==============================] - 2s 199ms/step - loss: 4.2400 - accuracy: 0.4125 - val_loss: 3.7364 - val_accuracy: 0.4828\n",
            "Epoch 417/1000\n",
            "10/10 [==============================] - 2s 196ms/step - loss: 4.3292 - accuracy: 0.4000 - val_loss: 3.7360 - val_accuracy: 0.4828\n",
            "Epoch 418/1000\n",
            "10/10 [==============================] - 2s 205ms/step - loss: 3.7019 - accuracy: 0.4875 - val_loss: 3.7357 - val_accuracy: 0.4828\n",
            "Epoch 419/1000\n",
            "10/10 [==============================] - 2s 197ms/step - loss: 3.4329 - accuracy: 0.5250 - val_loss: 3.7353 - val_accuracy: 0.4828\n",
            "Epoch 420/1000\n",
            "10/10 [==============================] - 2s 199ms/step - loss: 4.3281 - accuracy: 0.4000 - val_loss: 3.7350 - val_accuracy: 0.4828\n",
            "Epoch 421/1000\n",
            "10/10 [==============================] - 2s 202ms/step - loss: 3.6113 - accuracy: 0.5000 - val_loss: 3.7346 - val_accuracy: 0.4828\n",
            "Epoch 422/1000\n",
            "10/10 [==============================] - 2s 208ms/step - loss: 4.5065 - accuracy: 0.3750 - val_loss: 3.7343 - val_accuracy: 0.4828\n",
            "Epoch 423/1000\n",
            "10/10 [==============================] - 2s 212ms/step - loss: 4.1479 - accuracy: 0.4250 - val_loss: 3.7339 - val_accuracy: 0.4828\n",
            "Epoch 424/1000\n",
            "10/10 [==============================] - 2s 207ms/step - loss: 3.9685 - accuracy: 0.4500 - val_loss: 3.7336 - val_accuracy: 0.4828\n",
            "Epoch 425/1000\n",
            "10/10 [==============================] - 2s 193ms/step - loss: 4.1497 - accuracy: 0.4247 - val_loss: 3.7333 - val_accuracy: 0.4828\n",
            "Epoch 426/1000\n",
            "10/10 [==============================] - 2s 206ms/step - loss: 4.0574 - accuracy: 0.4375 - val_loss: 3.7329 - val_accuracy: 0.4828\n",
            "Epoch 427/1000\n",
            "10/10 [==============================] - 2s 214ms/step - loss: 3.9675 - accuracy: 0.4500 - val_loss: 3.7326 - val_accuracy: 0.4828\n",
            "Epoch 428/1000\n",
            "10/10 [==============================] - 2s 198ms/step - loss: 3.7881 - accuracy: 0.4750 - val_loss: 3.7323 - val_accuracy: 0.4828\n",
            "Epoch 429/1000\n",
            "10/10 [==============================] - 2s 197ms/step - loss: 4.3251 - accuracy: 0.4000 - val_loss: 3.7320 - val_accuracy: 0.4828\n",
            "Epoch 430/1000\n",
            "10/10 [==============================] - 2s 210ms/step - loss: 4.0561 - accuracy: 0.4375 - val_loss: 3.7317 - val_accuracy: 0.4828\n",
            "Epoch 431/1000\n",
            "10/10 [==============================] - 2s 204ms/step - loss: 3.8767 - accuracy: 0.4625 - val_loss: 3.7313 - val_accuracy: 0.4828\n",
            "Epoch 432/1000\n",
            "10/10 [==============================] - 2s 203ms/step - loss: 3.6567 - accuracy: 0.4932 - val_loss: 3.7310 - val_accuracy: 0.4828\n",
            "Epoch 433/1000\n",
            "10/10 [==============================] - 2s 210ms/step - loss: 4.0490 - accuracy: 0.4384 - val_loss: 3.7307 - val_accuracy: 0.4828\n",
            "Epoch 434/1000\n",
            "10/10 [==============================] - 2s 200ms/step - loss: 4.4131 - accuracy: 0.3875 - val_loss: 3.7304 - val_accuracy: 0.4828\n",
            "Epoch 435/1000\n",
            "10/10 [==============================] - 2s 200ms/step - loss: 3.4277 - accuracy: 0.5250 - val_loss: 3.7301 - val_accuracy: 0.4828\n",
            "Epoch 436/1000\n",
            "10/10 [==============================] - 2s 203ms/step - loss: 3.9647 - accuracy: 0.4500 - val_loss: 3.7299 - val_accuracy: 0.4828\n",
            "Epoch 437/1000\n",
            "10/10 [==============================] - 2s 214ms/step - loss: 4.0540 - accuracy: 0.4375 - val_loss: 3.7296 - val_accuracy: 0.4828\n",
            "Epoch 438/1000\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 4.3224 - accuracy: 0.4000 - val_loss: 3.7293 - val_accuracy: 0.4828\n",
            "Epoch 439/1000\n",
            "10/10 [==============================] - 2s 215ms/step - loss: 4.1430 - accuracy: 0.4250 - val_loss: 3.7290 - val_accuracy: 0.4828\n",
            "Epoch 440/1000\n",
            "10/10 [==============================] - 2s 204ms/step - loss: 3.6054 - accuracy: 0.5000 - val_loss: 3.7287 - val_accuracy: 0.4828\n",
            "Epoch 441/1000\n",
            "10/10 [==============================] - 2s 194ms/step - loss: 3.4260 - accuracy: 0.5250 - val_loss: 3.7285 - val_accuracy: 0.4828\n",
            "Epoch 442/1000\n",
            "10/10 [==============================] - 2s 197ms/step - loss: 3.6944 - accuracy: 0.4875 - val_loss: 3.7282 - val_accuracy: 0.4828\n",
            "Epoch 443/1000\n",
            "10/10 [==============================] - 2s 199ms/step - loss: 3.6941 - accuracy: 0.4875 - val_loss: 3.7279 - val_accuracy: 0.4828\n",
            "Epoch 444/1000\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 3.7834 - accuracy: 0.4750 - val_loss: 3.7277 - val_accuracy: 0.4828\n",
            "Epoch 445/1000\n",
            "10/10 [==============================] - 2s 195ms/step - loss: 3.9475 - accuracy: 0.4521 - val_loss: 3.7274 - val_accuracy: 0.4828\n",
            "Epoch 446/1000\n",
            "10/10 [==============================] - 2s 199ms/step - loss: 3.6933 - accuracy: 0.4875 - val_loss: 3.7271 - val_accuracy: 0.4828\n",
            "Epoch 447/1000\n",
            "10/10 [==============================] - 2s 200ms/step - loss: 3.7826 - accuracy: 0.4750 - val_loss: 3.7269 - val_accuracy: 0.4828\n",
            "Epoch 448/1000\n",
            "10/10 [==============================] - 2s 209ms/step - loss: 3.8719 - accuracy: 0.4625 - val_loss: 3.7266 - val_accuracy: 0.4828\n",
            "Epoch 449/1000\n",
            "10/10 [==============================] - 2s 195ms/step - loss: 4.2299 - accuracy: 0.4125 - val_loss: 3.7264 - val_accuracy: 0.4828\n",
            "Epoch 450/1000\n",
            "10/10 [==============================] - 2s 206ms/step - loss: 3.8714 - accuracy: 0.4625 - val_loss: 3.7261 - val_accuracy: 0.4828\n",
            "Epoch 451/1000\n",
            "10/10 [==============================] - 2s 192ms/step - loss: 3.8478 - accuracy: 0.4658 - val_loss: 3.7259 - val_accuracy: 0.4828\n",
            "Epoch 452/1000\n",
            "10/10 [==============================] - 2s 207ms/step - loss: 4.1396 - accuracy: 0.4250 - val_loss: 3.7256 - val_accuracy: 0.4828\n",
            "Epoch 453/1000\n",
            "10/10 [==============================] - 2s 202ms/step - loss: 3.8707 - accuracy: 0.4625 - val_loss: 3.7254 - val_accuracy: 0.4828\n",
            "Epoch 454/1000\n",
            "10/10 [==============================] - 2s 207ms/step - loss: 3.6913 - accuracy: 0.4875 - val_loss: 3.7252 - val_accuracy: 0.4828\n",
            "Epoch 455/1000\n",
            "10/10 [==============================] - 2s 204ms/step - loss: 3.7807 - accuracy: 0.4750 - val_loss: 3.7249 - val_accuracy: 0.4828\n",
            "Epoch 456/1000\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 3.6909 - accuracy: 0.4875 - val_loss: 3.7247 - val_accuracy: 0.4828\n",
            "Epoch 457/1000\n",
            "10/10 [==============================] - 2s 192ms/step - loss: 3.9446 - accuracy: 0.4521 - val_loss: 3.7245 - val_accuracy: 0.4828\n",
            "Epoch 458/1000\n",
            "10/10 [==============================] - 2s 200ms/step - loss: 3.8695 - accuracy: 0.4625 - val_loss: 3.7243 - val_accuracy: 0.4828\n",
            "Epoch 459/1000\n",
            "10/10 [==============================] - 2s 211ms/step - loss: 3.6902 - accuracy: 0.4875 - val_loss: 3.7240 - val_accuracy: 0.4828\n",
            "Epoch 460/1000\n",
            "10/10 [==============================] - 2s 209ms/step - loss: 4.3169 - accuracy: 0.4000 - val_loss: 3.7238 - val_accuracy: 0.4828\n",
            "Epoch 461/1000\n",
            "10/10 [==============================] - 2s 199ms/step - loss: 4.1376 - accuracy: 0.4250 - val_loss: 3.7236 - val_accuracy: 0.4828\n",
            "Epoch 462/1000\n",
            "10/10 [==============================] - 2s 195ms/step - loss: 3.7472 - accuracy: 0.4795 - val_loss: 3.7234 - val_accuracy: 0.4828\n",
            "Epoch 463/1000\n",
            "10/10 [==============================] - 2s 217ms/step - loss: 3.9580 - accuracy: 0.4500 - val_loss: 3.7232 - val_accuracy: 0.4828\n",
            "Epoch 464/1000\n",
            "10/10 [==============================] - 2s 210ms/step - loss: 3.9578 - accuracy: 0.4500 - val_loss: 3.7230 - val_accuracy: 0.4828\n",
            "Epoch 465/1000\n",
            "10/10 [==============================] - 2s 203ms/step - loss: 4.0472 - accuracy: 0.4375 - val_loss: 3.7228 - val_accuracy: 0.4828\n",
            "Epoch 466/1000\n",
            "10/10 [==============================] - 2s 219ms/step - loss: 4.2261 - accuracy: 0.4125 - val_loss: 3.7226 - val_accuracy: 0.4828\n",
            "Epoch 467/1000\n",
            "10/10 [==============================] - 2s 200ms/step - loss: 4.0406 - accuracy: 0.4384 - val_loss: 3.7224 - val_accuracy: 0.4828\n",
            "Epoch 468/1000\n",
            "10/10 [==============================] - 2s 194ms/step - loss: 3.9570 - accuracy: 0.4500 - val_loss: 3.7222 - val_accuracy: 0.4828\n",
            "Epoch 469/1000\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 4.3347 - accuracy: 0.3973 - val_loss: 3.7220 - val_accuracy: 0.4828\n",
            "Epoch 470/1000\n",
            "10/10 [==============================] - 2s 198ms/step - loss: 3.9566 - accuracy: 0.4500 - val_loss: 3.7218 - val_accuracy: 0.4828\n",
            "Epoch 471/1000\n",
            "10/10 [==============================] - 2s 204ms/step - loss: 4.2251 - accuracy: 0.4125 - val_loss: 3.7216 - val_accuracy: 0.4828\n",
            "Epoch 472/1000\n",
            "10/10 [==============================] - 2s 203ms/step - loss: 4.2249 - accuracy: 0.4125 - val_loss: 3.7214 - val_accuracy: 0.4828\n",
            "Epoch 473/1000\n",
            "10/10 [==============================] - 2s 195ms/step - loss: 3.6874 - accuracy: 0.4875 - val_loss: 3.7212 - val_accuracy: 0.4828\n",
            "Epoch 474/1000\n",
            "10/10 [==============================] - 2s 202ms/step - loss: 4.2245 - accuracy: 0.4125 - val_loss: 3.7210 - val_accuracy: 0.4828\n",
            "Epoch 475/1000\n",
            "10/10 [==============================] - 2s 196ms/step - loss: 4.2243 - accuracy: 0.4125 - val_loss: 3.7209 - val_accuracy: 0.4828\n",
            "Epoch 476/1000\n",
            "10/10 [==============================] - 2s 193ms/step - loss: 4.1346 - accuracy: 0.4250 - val_loss: 3.7207 - val_accuracy: 0.4828\n",
            "Epoch 477/1000\n",
            "10/10 [==============================] - 2s 197ms/step - loss: 3.8657 - accuracy: 0.4625 - val_loss: 3.7205 - val_accuracy: 0.4828\n",
            "Epoch 478/1000\n",
            "10/10 [==============================] - 2s 197ms/step - loss: 3.6864 - accuracy: 0.4875 - val_loss: 3.7203 - val_accuracy: 0.4828\n",
            "Epoch 479/1000\n",
            "10/10 [==============================] - 2s 210ms/step - loss: 3.5072 - accuracy: 0.5125 - val_loss: 3.7201 - val_accuracy: 0.4828\n",
            "Epoch 480/1000\n",
            "10/10 [==============================] - 2s 208ms/step - loss: 3.7757 - accuracy: 0.4750 - val_loss: 3.7200 - val_accuracy: 0.4828\n",
            "Epoch 481/1000\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 3.8650 - accuracy: 0.4625 - val_loss: 3.7198 - val_accuracy: 0.4828\n",
            "Epoch 482/1000\n",
            "10/10 [==============================] - 2s 198ms/step - loss: 4.1360 - accuracy: 0.4247 - val_loss: 3.7196 - val_accuracy: 0.4828\n",
            "Epoch 483/1000\n",
            "10/10 [==============================] - 2s 215ms/step - loss: 4.1334 - accuracy: 0.4250 - val_loss: 3.7195 - val_accuracy: 0.4828\n",
            "Epoch 484/1000\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 3.7431 - accuracy: 0.4795 - val_loss: 3.7193 - val_accuracy: 0.4828\n",
            "Epoch 485/1000\n",
            "10/10 [==============================] - 2s 200ms/step - loss: 4.3318 - accuracy: 0.3973 - val_loss: 3.7192 - val_accuracy: 0.4828\n",
            "Epoch 486/1000\n",
            "10/10 [==============================] - 2s 214ms/step - loss: 4.0433 - accuracy: 0.4375 - val_loss: 3.7190 - val_accuracy: 0.4828\n",
            "Epoch 487/1000\n",
            "10/10 [==============================] - 2s 205ms/step - loss: 3.5463 - accuracy: 0.5068 - val_loss: 3.7188 - val_accuracy: 0.4828\n",
            "Epoch 488/1000\n",
            "10/10 [==============================] - 2s 203ms/step - loss: 3.2370 - accuracy: 0.5500 - val_loss: 3.7187 - val_accuracy: 0.4828\n",
            "Epoch 489/1000\n",
            "10/10 [==============================] - 2s 208ms/step - loss: 4.2330 - accuracy: 0.4110 - val_loss: 3.7185 - val_accuracy: 0.4828\n",
            "Epoch 490/1000\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 3.7740 - accuracy: 0.4750 - val_loss: 3.7184 - val_accuracy: 0.4828\n",
            "Epoch 491/1000\n",
            "10/10 [==============================] - 2s 214ms/step - loss: 3.6843 - accuracy: 0.4875 - val_loss: 3.7182 - val_accuracy: 0.4828\n",
            "Epoch 492/1000\n",
            "10/10 [==============================] - 2s 209ms/step - loss: 3.5456 - accuracy: 0.5068 - val_loss: 3.7181 - val_accuracy: 0.4828\n",
            "Epoch 493/1000\n",
            "10/10 [==============================] - 2s 200ms/step - loss: 4.3110 - accuracy: 0.4000 - val_loss: 3.7179 - val_accuracy: 0.4828\n",
            "Epoch 494/1000\n",
            "10/10 [==============================] - 2s 197ms/step - loss: 3.2508 - accuracy: 0.5479 - val_loss: 3.7178 - val_accuracy: 0.4828\n",
            "Epoch 495/1000\n",
            "10/10 [==============================] - 2s 199ms/step - loss: 3.8629 - accuracy: 0.4625 - val_loss: 3.7176 - val_accuracy: 0.4828\n",
            "Epoch 496/1000\n",
            "10/10 [==============================] - 2s 202ms/step - loss: 3.4468 - accuracy: 0.5205 - val_loss: 3.7175 - val_accuracy: 0.4828\n",
            "Epoch 497/1000\n",
            "10/10 [==============================] - 2s 215ms/step - loss: 3.6835 - accuracy: 0.4875 - val_loss: 3.7174 - val_accuracy: 0.4828\n",
            "Epoch 498/1000\n",
            "10/10 [==============================] - 2s 194ms/step - loss: 4.2317 - accuracy: 0.4110 - val_loss: 3.7172 - val_accuracy: 0.4828\n",
            "Epoch 499/1000\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 4.4892 - accuracy: 0.3750 - val_loss: 3.7171 - val_accuracy: 0.4828\n",
            "Epoch 500/1000\n",
            "10/10 [==============================] - 2s 204ms/step - loss: 4.0413 - accuracy: 0.4375 - val_loss: 3.7170 - val_accuracy: 0.4828\n",
            "Epoch 501/1000\n",
            "10/10 [==============================] - 2s 205ms/step - loss: 4.0412 - accuracy: 0.4375 - val_loss: 3.7168 - val_accuracy: 0.4828\n",
            "Epoch 502/1000\n",
            "10/10 [==============================] - 2s 203ms/step - loss: 4.5784 - accuracy: 0.3625 - val_loss: 3.7167 - val_accuracy: 0.4828\n",
            "Epoch 503/1000\n",
            "10/10 [==============================] - 2s 204ms/step - loss: 3.5035 - accuracy: 0.5125 - val_loss: 3.7166 - val_accuracy: 0.4828\n",
            "Epoch 504/1000\n",
            "10/10 [==============================] - 2s 206ms/step - loss: 3.5890 - accuracy: 0.5000 - val_loss: 3.7163 - val_accuracy: 0.4828\n",
            "Epoch 505/1000\n",
            "10/10 [==============================] - 2s 195ms/step - loss: 3.7356 - accuracy: 0.4795 - val_loss: 3.7160 - val_accuracy: 0.4828\n",
            "Epoch 506/1000\n",
            "10/10 [==============================] - 2s 213ms/step - loss: 3.6414 - accuracy: 0.4932 - val_loss: 3.7142 - val_accuracy: 0.4828\n",
            "Epoch 507/1000\n",
            "10/10 [==============================] - 2s 205ms/step - loss: 3.6283 - accuracy: 0.4932 - val_loss: 3.6670 - val_accuracy: 0.4828\n",
            "Epoch 508/1000\n",
            "10/10 [==============================] - 2s 203ms/step - loss: 2.8334 - accuracy: 0.4521 - val_loss: 0.3793 - val_accuracy: 0.6995\n",
            "Epoch 509/1000\n",
            "10/10 [==============================] - 2s 203ms/step - loss: 1.0013 - accuracy: 0.6164 - val_loss: 0.7062 - val_accuracy: 0.6207\n",
            "Epoch 510/1000\n",
            "10/10 [==============================] - 2s 197ms/step - loss: 0.8070 - accuracy: 0.6500 - val_loss: 1.4221 - val_accuracy: 0.5813\n",
            "Epoch 511/1000\n",
            "10/10 [==============================] - 2s 208ms/step - loss: 0.7042 - accuracy: 0.6750 - val_loss: 0.7492 - val_accuracy: 0.6207\n",
            "Epoch 512/1000\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 0.3288 - accuracy: 0.7125 - val_loss: 0.6180 - val_accuracy: 0.7094\n",
            "Epoch 513/1000\n",
            "10/10 [==============================] - 2s 203ms/step - loss: 0.3847 - accuracy: 0.7875 - val_loss: 0.4005 - val_accuracy: 0.7192\n",
            "Epoch 514/1000\n",
            "10/10 [==============================] - 2s 190ms/step - loss: 0.1924 - accuracy: 0.9041 - val_loss: 0.4563 - val_accuracy: 0.7340\n",
            "Epoch 515/1000\n",
            "10/10 [==============================] - 2s 204ms/step - loss: 0.2197 - accuracy: 0.8125 - val_loss: 0.3474 - val_accuracy: 0.7438\n",
            "Epoch 516/1000\n",
            "10/10 [==============================] - 2s 200ms/step - loss: 0.2060 - accuracy: 0.8375 - val_loss: 0.3577 - val_accuracy: 0.7094\n",
            "Epoch 517/1000\n",
            "10/10 [==============================] - 2s 200ms/step - loss: 0.2498 - accuracy: 0.7750 - val_loss: 0.3379 - val_accuracy: 0.7586\n",
            "Epoch 518/1000\n",
            "10/10 [==============================] - 2s 206ms/step - loss: 0.1863 - accuracy: 0.8625 - val_loss: 0.3685 - val_accuracy: 0.7488\n",
            "Epoch 519/1000\n",
            "10/10 [==============================] - 2s 206ms/step - loss: 0.2002 - accuracy: 0.8250 - val_loss: 0.3268 - val_accuracy: 0.7586\n",
            "Epoch 520/1000\n",
            "10/10 [==============================] - 2s 208ms/step - loss: 0.1657 - accuracy: 0.8767 - val_loss: 0.3249 - val_accuracy: 0.7094\n",
            "Epoch 521/1000\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 0.2517 - accuracy: 0.8219 - val_loss: 0.6819 - val_accuracy: 0.5567\n",
            "Epoch 522/1000\n",
            "10/10 [==============================] - 2s 202ms/step - loss: 0.2998 - accuracy: 0.6875 - val_loss: 0.3147 - val_accuracy: 0.7537\n",
            "Epoch 523/1000\n",
            "10/10 [==============================] - 2s 200ms/step - loss: 0.2757 - accuracy: 0.7125 - val_loss: 0.5533 - val_accuracy: 0.6897\n",
            "Epoch 524/1000\n",
            "10/10 [==============================] - 2s 208ms/step - loss: 0.2538 - accuracy: 0.7875 - val_loss: 0.3058 - val_accuracy: 0.7586\n",
            "Epoch 525/1000\n",
            "10/10 [==============================] - 2s 197ms/step - loss: 0.1574 - accuracy: 0.8750 - val_loss: 0.3109 - val_accuracy: 0.7586\n",
            "Epoch 526/1000\n",
            "10/10 [==============================] - 2s 196ms/step - loss: 0.1337 - accuracy: 0.9250 - val_loss: 0.3784 - val_accuracy: 0.7488\n",
            "Epoch 527/1000\n",
            "10/10 [==============================] - 2s 203ms/step - loss: 0.1613 - accuracy: 0.8500 - val_loss: 0.3078 - val_accuracy: 0.7537\n",
            "Epoch 528/1000\n",
            "10/10 [==============================] - 2s 215ms/step - loss: 0.1332 - accuracy: 0.9125 - val_loss: 0.3344 - val_accuracy: 0.6946\n",
            "Epoch 529/1000\n",
            "10/10 [==============================] - 2s 194ms/step - loss: 0.1240 - accuracy: 0.9125 - val_loss: 0.3339 - val_accuracy: 0.7438\n",
            "Epoch 530/1000\n",
            "10/10 [==============================] - 2s 208ms/step - loss: 0.1547 - accuracy: 0.8904 - val_loss: 0.3128 - val_accuracy: 0.7438\n",
            "Epoch 531/1000\n",
            "10/10 [==============================] - 2s 206ms/step - loss: 0.2284 - accuracy: 0.8250 - val_loss: 0.3498 - val_accuracy: 0.7094\n",
            "Epoch 532/1000\n",
            "10/10 [==============================] - 2s 197ms/step - loss: 0.1456 - accuracy: 0.9125 - val_loss: 0.3984 - val_accuracy: 0.7389\n",
            "Epoch 533/1000\n",
            "10/10 [==============================] - 2s 203ms/step - loss: 0.1595 - accuracy: 0.8750 - val_loss: 0.3213 - val_accuracy: 0.7537\n",
            "Epoch 534/1000\n",
            "10/10 [==============================] - 2s 207ms/step - loss: 0.1646 - accuracy: 0.9125 - val_loss: 0.3215 - val_accuracy: 0.7241\n",
            "Epoch 535/1000\n",
            "10/10 [==============================] - 2s 206ms/step - loss: 0.1476 - accuracy: 0.8904 - val_loss: 0.3134 - val_accuracy: 0.7586\n",
            "Epoch 536/1000\n",
            "10/10 [==============================] - 2s 203ms/step - loss: 0.1541 - accuracy: 0.8875 - val_loss: 0.3058 - val_accuracy: 0.7635\n",
            "Epoch 537/1000\n",
            "10/10 [==============================] - 2s 198ms/step - loss: 0.1221 - accuracy: 0.9250 - val_loss: 0.3816 - val_accuracy: 0.7389\n",
            "Epoch 538/1000\n",
            "10/10 [==============================] - 2s 218ms/step - loss: 0.1903 - accuracy: 0.8250 - val_loss: 0.2973 - val_accuracy: 0.7783\n",
            "Epoch 539/1000\n",
            "10/10 [==============================] - 2s 207ms/step - loss: 0.1962 - accuracy: 0.8493 - val_loss: 0.5110 - val_accuracy: 0.6355\n",
            "Epoch 540/1000\n",
            "10/10 [==============================] - 2s 194ms/step - loss: 0.1558 - accuracy: 0.8750 - val_loss: 0.3516 - val_accuracy: 0.7340\n",
            "Epoch 541/1000\n",
            "10/10 [==============================] - 2s 197ms/step - loss: 0.0969 - accuracy: 0.9589 - val_loss: 0.3111 - val_accuracy: 0.7734\n",
            "Epoch 542/1000\n",
            "10/10 [==============================] - 2s 208ms/step - loss: 0.1001 - accuracy: 0.9500 - val_loss: 0.3089 - val_accuracy: 0.7635\n",
            "Epoch 543/1000\n",
            "10/10 [==============================] - 2s 204ms/step - loss: 0.1103 - accuracy: 0.9250 - val_loss: 0.3312 - val_accuracy: 0.7438\n",
            "Epoch 544/1000\n",
            "10/10 [==============================] - 2s 198ms/step - loss: 0.1097 - accuracy: 0.9000 - val_loss: 0.3067 - val_accuracy: 0.7438\n",
            "Epoch 545/1000\n",
            "10/10 [==============================] - 2s 204ms/step - loss: 0.1159 - accuracy: 0.9041 - val_loss: 0.3134 - val_accuracy: 0.7192\n",
            "Epoch 546/1000\n",
            "10/10 [==============================] - 2s 190ms/step - loss: 0.2054 - accuracy: 0.8219 - val_loss: 0.3766 - val_accuracy: 0.7438\n",
            "Epoch 547/1000\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 0.1314 - accuracy: 0.8875 - val_loss: 0.4236 - val_accuracy: 0.7241\n",
            "Epoch 548/1000\n",
            "10/10 [==============================] - 2s 192ms/step - loss: 0.1757 - accuracy: 0.8493 - val_loss: 0.3028 - val_accuracy: 0.7635\n",
            "Epoch 549/1000\n",
            "10/10 [==============================] - 2s 208ms/step - loss: 0.1185 - accuracy: 0.9125 - val_loss: 0.3317 - val_accuracy: 0.7192\n",
            "Epoch 550/1000\n",
            "10/10 [==============================] - 2s 199ms/step - loss: 0.1424 - accuracy: 0.9250 - val_loss: 0.3167 - val_accuracy: 0.7635\n",
            "Epoch 551/1000\n",
            "10/10 [==============================] - 2s 202ms/step - loss: 0.0997 - accuracy: 0.9625 - val_loss: 0.3050 - val_accuracy: 0.7685\n",
            "Epoch 552/1000\n",
            "10/10 [==============================] - 2s 206ms/step - loss: 0.1111 - accuracy: 0.9500 - val_loss: 0.3314 - val_accuracy: 0.7537\n",
            "Epoch 553/1000\n",
            "10/10 [==============================] - 2s 196ms/step - loss: 0.1167 - accuracy: 0.9589 - val_loss: 0.3114 - val_accuracy: 0.7389\n",
            "Epoch 554/1000\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 0.1312 - accuracy: 0.9125 - val_loss: 0.3224 - val_accuracy: 0.7340\n",
            "Epoch 555/1000\n",
            "10/10 [==============================] - 2s 197ms/step - loss: 0.0934 - accuracy: 0.9500 - val_loss: 0.3088 - val_accuracy: 0.7389\n",
            "Epoch 556/1000\n",
            "10/10 [==============================] - 2s 204ms/step - loss: 0.1198 - accuracy: 0.9589 - val_loss: 0.3097 - val_accuracy: 0.7537\n",
            "Epoch 557/1000\n",
            "10/10 [==============================] - 2s 209ms/step - loss: 0.1120 - accuracy: 0.9625 - val_loss: 0.3237 - val_accuracy: 0.7537\n",
            "Epoch 558/1000\n",
            "10/10 [==============================] - 2s 208ms/step - loss: 0.1155 - accuracy: 0.9250 - val_loss: 0.3299 - val_accuracy: 0.7438\n",
            "Epoch 559/1000\n",
            "10/10 [==============================] - 2s 203ms/step - loss: 0.1046 - accuracy: 0.9500 - val_loss: 0.3060 - val_accuracy: 0.7389\n",
            "Epoch 560/1000\n",
            "10/10 [==============================] - 2s 207ms/step - loss: 0.0902 - accuracy: 0.9625 - val_loss: 0.3096 - val_accuracy: 0.7389\n",
            "Epoch 561/1000\n",
            "10/10 [==============================] - 2s 194ms/step - loss: 0.0936 - accuracy: 0.9875 - val_loss: 0.3113 - val_accuracy: 0.7488\n",
            "Epoch 562/1000\n",
            "10/10 [==============================] - 2s 207ms/step - loss: 0.1020 - accuracy: 0.9375 - val_loss: 0.4242 - val_accuracy: 0.7192\n",
            "Epoch 563/1000\n",
            "10/10 [==============================] - 2s 200ms/step - loss: 0.1044 - accuracy: 0.9750 - val_loss: 0.3020 - val_accuracy: 0.7537\n",
            "Epoch 564/1000\n",
            "10/10 [==============================] - 2s 202ms/step - loss: 0.1111 - accuracy: 0.9375 - val_loss: 0.2951 - val_accuracy: 0.7586\n",
            "Epoch 565/1000\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 0.0805 - accuracy: 0.9875 - val_loss: 0.3528 - val_accuracy: 0.7488\n",
            "Epoch 566/1000\n",
            "10/10 [==============================] - 2s 195ms/step - loss: 0.1436 - accuracy: 0.9125 - val_loss: 0.3245 - val_accuracy: 0.7586\n",
            "Epoch 567/1000\n",
            "10/10 [==============================] - 2s 202ms/step - loss: 0.1243 - accuracy: 0.9452 - val_loss: 0.3052 - val_accuracy: 0.7488\n",
            "Epoch 568/1000\n",
            "10/10 [==============================] - 2s 194ms/step - loss: 0.1276 - accuracy: 0.9000 - val_loss: 0.3047 - val_accuracy: 0.7586\n",
            "Epoch 569/1000\n",
            "10/10 [==============================] - 2s 196ms/step - loss: 0.1056 - accuracy: 0.9500 - val_loss: 0.3312 - val_accuracy: 0.7438\n",
            "Epoch 570/1000\n",
            "10/10 [==============================] - 2s 197ms/step - loss: 0.1166 - accuracy: 0.9178 - val_loss: 0.3114 - val_accuracy: 0.7635\n",
            "Epoch 571/1000\n",
            "10/10 [==============================] - 2s 191ms/step - loss: 0.1235 - accuracy: 0.9315 - val_loss: 0.3247 - val_accuracy: 0.7389\n",
            "Epoch 572/1000\n",
            "10/10 [==============================] - 2s 192ms/step - loss: 0.1023 - accuracy: 0.9589 - val_loss: 0.3292 - val_accuracy: 0.7340\n",
            "Epoch 573/1000\n",
            "10/10 [==============================] - 2s 196ms/step - loss: 0.1303 - accuracy: 0.9125 - val_loss: 0.4845 - val_accuracy: 0.6995\n",
            "Epoch 574/1000\n",
            "10/10 [==============================] - 2s 205ms/step - loss: 0.1650 - accuracy: 0.8750 - val_loss: 0.3549 - val_accuracy: 0.7044\n",
            "Epoch 575/1000\n",
            "10/10 [==============================] - 2s 192ms/step - loss: 0.1166 - accuracy: 0.9315 - val_loss: 0.3075 - val_accuracy: 0.7488\n",
            "Epoch 576/1000\n",
            "10/10 [==============================] - 2s 198ms/step - loss: 0.0946 - accuracy: 0.9750 - val_loss: 0.3731 - val_accuracy: 0.7241\n",
            "Epoch 577/1000\n",
            "10/10 [==============================] - 2s 199ms/step - loss: 0.1359 - accuracy: 0.9000 - val_loss: 0.3250 - val_accuracy: 0.7340\n",
            "Epoch 578/1000\n",
            "10/10 [==============================] - 2s 197ms/step - loss: 0.0886 - accuracy: 0.9875 - val_loss: 0.3336 - val_accuracy: 0.7291\n",
            "Epoch 579/1000\n",
            "10/10 [==============================] - 2s 204ms/step - loss: 0.0815 - accuracy: 0.9875 - val_loss: 0.3240 - val_accuracy: 0.7488\n",
            "Epoch 580/1000\n",
            "10/10 [==============================] - 2s 203ms/step - loss: 0.0812 - accuracy: 0.9750 - val_loss: 0.3320 - val_accuracy: 0.7586\n",
            "Epoch 581/1000\n",
            "10/10 [==============================] - 2s 196ms/step - loss: 0.1202 - accuracy: 0.9178 - val_loss: 0.4380 - val_accuracy: 0.7044\n",
            "Epoch 582/1000\n",
            "10/10 [==============================] - 2s 206ms/step - loss: 0.1085 - accuracy: 0.9625 - val_loss: 0.3268 - val_accuracy: 0.7340\n",
            "Epoch 583/1000\n",
            "10/10 [==============================] - 2s 202ms/step - loss: 0.0979 - accuracy: 0.9375 - val_loss: 0.3527 - val_accuracy: 0.7192\n",
            "Epoch 584/1000\n",
            "10/10 [==============================] - 2s 189ms/step - loss: 0.0947 - accuracy: 0.9726 - val_loss: 0.5146 - val_accuracy: 0.6946\n",
            "Epoch 585/1000\n",
            "10/10 [==============================] - 2s 205ms/step - loss: 0.1727 - accuracy: 0.8750 - val_loss: 0.3305 - val_accuracy: 0.7192\n",
            "Epoch 586/1000\n",
            "10/10 [==============================] - 2s 204ms/step - loss: 0.0970 - accuracy: 0.9750 - val_loss: 0.3352 - val_accuracy: 0.7488\n",
            "Epoch 587/1000\n",
            "10/10 [==============================] - 2s 195ms/step - loss: 0.0923 - accuracy: 0.9625 - val_loss: 0.3511 - val_accuracy: 0.7389\n",
            "Epoch 588/1000\n",
            "10/10 [==============================] - 2s 198ms/step - loss: 0.1253 - accuracy: 0.9500 - val_loss: 0.3038 - val_accuracy: 0.7833\n",
            "Epoch 589/1000\n",
            "10/10 [==============================] - 2s 196ms/step - loss: 0.0864 - accuracy: 0.9750 - val_loss: 0.3155 - val_accuracy: 0.7734\n",
            "Epoch 590/1000\n",
            "10/10 [==============================] - 2s 206ms/step - loss: 0.0818 - accuracy: 1.0000 - val_loss: 0.3051 - val_accuracy: 0.7389\n",
            "Epoch 591/1000\n",
            "10/10 [==============================] - 2s 206ms/step - loss: 0.1153 - accuracy: 0.9625 - val_loss: 0.3067 - val_accuracy: 0.7931\n",
            "Epoch 592/1000\n",
            "10/10 [==============================] - 2s 187ms/step - loss: 0.1121 - accuracy: 0.9500 - val_loss: 0.3805 - val_accuracy: 0.7340\n",
            "Epoch 593/1000\n",
            "10/10 [==============================] - 2s 209ms/step - loss: 0.1521 - accuracy: 0.8750 - val_loss: 0.3076 - val_accuracy: 0.7783\n",
            "Epoch 594/1000\n",
            "10/10 [==============================] - 2s 199ms/step - loss: 0.1057 - accuracy: 0.9625 - val_loss: 0.2969 - val_accuracy: 0.7635\n",
            "Epoch 595/1000\n",
            "10/10 [==============================] - 2s 195ms/step - loss: 0.1161 - accuracy: 0.9625 - val_loss: 0.2998 - val_accuracy: 0.7931\n",
            "Epoch 596/1000\n",
            "10/10 [==============================] - 2s 195ms/step - loss: 0.0868 - accuracy: 0.9875 - val_loss: 0.3456 - val_accuracy: 0.7734\n",
            "Epoch 597/1000\n",
            "10/10 [==============================] - 2s 192ms/step - loss: 0.0867 - accuracy: 0.9750 - val_loss: 0.3093 - val_accuracy: 0.7340\n",
            "Epoch 598/1000\n",
            "10/10 [==============================] - 2s 212ms/step - loss: 0.0945 - accuracy: 0.9625 - val_loss: 0.3032 - val_accuracy: 0.7438\n",
            "Epoch 599/1000\n",
            "10/10 [==============================] - 2s 189ms/step - loss: 0.1066 - accuracy: 0.9625 - val_loss: 0.3032 - val_accuracy: 0.7783\n",
            "Epoch 600/1000\n",
            "10/10 [==============================] - 2s 202ms/step - loss: 0.0911 - accuracy: 0.9589 - val_loss: 0.3413 - val_accuracy: 0.7685\n",
            "Epoch 601/1000\n",
            "10/10 [==============================] - 2s 193ms/step - loss: 0.1085 - accuracy: 0.9625 - val_loss: 0.4832 - val_accuracy: 0.7044\n",
            "Epoch 602/1000\n",
            "10/10 [==============================] - 2s 198ms/step - loss: 0.1605 - accuracy: 0.8767 - val_loss: 0.5302 - val_accuracy: 0.6897\n",
            "Epoch 603/1000\n",
            "10/10 [==============================] - 2s 192ms/step - loss: 0.1465 - accuracy: 0.8630 - val_loss: 0.5123 - val_accuracy: 0.6946\n",
            "Epoch 604/1000\n",
            "10/10 [==============================] - 2s 195ms/step - loss: 0.1714 - accuracy: 0.8500 - val_loss: 0.4802 - val_accuracy: 0.6995\n",
            "Epoch 605/1000\n",
            "10/10 [==============================] - 2s 199ms/step - loss: 0.1467 - accuracy: 0.9000 - val_loss: 0.4419 - val_accuracy: 0.7143\n",
            "Epoch 606/1000\n",
            "10/10 [==============================] - 2s 196ms/step - loss: 0.1272 - accuracy: 0.9375 - val_loss: 0.4097 - val_accuracy: 0.7389\n",
            "Epoch 607/1000\n",
            "10/10 [==============================] - 2s 196ms/step - loss: 0.1572 - accuracy: 0.8875 - val_loss: 0.3819 - val_accuracy: 0.7586\n",
            "Epoch 608/1000\n",
            "10/10 [==============================] - 2s 193ms/step - loss: 0.1313 - accuracy: 0.9250 - val_loss: 0.3583 - val_accuracy: 0.7635\n",
            "Epoch 609/1000\n",
            "10/10 [==============================] - 2s 194ms/step - loss: 0.1166 - accuracy: 0.9500 - val_loss: 0.3418 - val_accuracy: 0.7734\n",
            "Epoch 610/1000\n",
            "10/10 [==============================] - 2s 193ms/step - loss: 0.1102 - accuracy: 0.9452 - val_loss: 0.3321 - val_accuracy: 0.7635\n",
            "Epoch 611/1000\n",
            "10/10 [==============================] - 2s 200ms/step - loss: 0.0997 - accuracy: 0.9452 - val_loss: 0.3277 - val_accuracy: 0.7734\n",
            "Epoch 612/1000\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 0.0953 - accuracy: 0.9875 - val_loss: 0.3237 - val_accuracy: 0.7734\n",
            "Epoch 613/1000\n",
            "10/10 [==============================] - 2s 195ms/step - loss: 0.0915 - accuracy: 0.9750 - val_loss: 0.3197 - val_accuracy: 0.7783\n",
            "Epoch 614/1000\n",
            "10/10 [==============================] - 2s 198ms/step - loss: 0.0827 - accuracy: 0.9875 - val_loss: 0.3178 - val_accuracy: 0.7734\n",
            "Epoch 615/1000\n",
            "10/10 [==============================] - 2s 207ms/step - loss: 0.0960 - accuracy: 0.9726 - val_loss: 0.3171 - val_accuracy: 0.7685\n",
            "Epoch 616/1000\n",
            "10/10 [==============================] - 2s 202ms/step - loss: 0.0876 - accuracy: 0.9625 - val_loss: 0.3152 - val_accuracy: 0.7685\n",
            "Epoch 617/1000\n",
            "10/10 [==============================] - 2s 202ms/step - loss: 0.0926 - accuracy: 0.9875 - val_loss: 0.3134 - val_accuracy: 0.7635\n",
            "Epoch 618/1000\n",
            "10/10 [==============================] - 2s 207ms/step - loss: 0.1057 - accuracy: 0.9625 - val_loss: 0.3116 - val_accuracy: 0.7685\n",
            "Epoch 619/1000\n",
            "10/10 [==============================] - 2s 206ms/step - loss: 0.0912 - accuracy: 0.9750 - val_loss: 0.3099 - val_accuracy: 0.7734\n",
            "Epoch 620/1000\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 0.0940 - accuracy: 0.9750 - val_loss: 0.3084 - val_accuracy: 0.7783\n",
            "Epoch 621/1000\n",
            "10/10 [==============================] - 2s 210ms/step - loss: 0.0663 - accuracy: 0.9875 - val_loss: 0.3076 - val_accuracy: 0.7734\n",
            "Epoch 622/1000\n",
            "10/10 [==============================] - 2s 200ms/step - loss: 0.0928 - accuracy: 0.9863 - val_loss: 0.3069 - val_accuracy: 0.7882\n",
            "Epoch 623/1000\n",
            "10/10 [==============================] - 2s 194ms/step - loss: 0.0907 - accuracy: 0.9875 - val_loss: 0.3072 - val_accuracy: 0.7882\n",
            "Epoch 624/1000\n",
            "10/10 [==============================] - 2s 189ms/step - loss: 0.0846 - accuracy: 0.9726 - val_loss: 0.3077 - val_accuracy: 0.7734\n",
            "Epoch 625/1000\n",
            "10/10 [==============================] - 2s 200ms/step - loss: 0.0856 - accuracy: 0.9750 - val_loss: 0.3086 - val_accuracy: 0.7783\n",
            "Epoch 626/1000\n",
            "10/10 [==============================] - 2s 194ms/step - loss: 0.0735 - accuracy: 0.9875 - val_loss: 0.3089 - val_accuracy: 0.7783\n",
            "Epoch 627/1000\n",
            "10/10 [==============================] - 2s 198ms/step - loss: 0.0788 - accuracy: 0.9750 - val_loss: 0.3091 - val_accuracy: 0.7783\n",
            "Epoch 628/1000\n",
            "10/10 [==============================] - 2s 192ms/step - loss: 0.0887 - accuracy: 0.9750 - val_loss: 0.3101 - val_accuracy: 0.7783\n",
            "Epoch 629/1000\n",
            "10/10 [==============================] - 2s 203ms/step - loss: 0.0841 - accuracy: 0.9863 - val_loss: 0.3089 - val_accuracy: 0.7783\n",
            "Epoch 630/1000\n",
            "10/10 [==============================] - 2s 198ms/step - loss: 0.1081 - accuracy: 0.9625 - val_loss: 0.3074 - val_accuracy: 0.7783\n",
            "Epoch 631/1000\n",
            "10/10 [==============================] - 2s 196ms/step - loss: 0.0864 - accuracy: 0.9875 - val_loss: 0.3065 - val_accuracy: 0.7882\n",
            "Epoch 632/1000\n",
            "10/10 [==============================] - 2s 192ms/step - loss: 0.1009 - accuracy: 0.9726 - val_loss: 0.3059 - val_accuracy: 0.7882\n",
            "Epoch 633/1000\n",
            "10/10 [==============================] - 2s 200ms/step - loss: 0.0924 - accuracy: 0.9875 - val_loss: 0.3074 - val_accuracy: 0.7833\n",
            "Epoch 634/1000\n",
            "10/10 [==============================] - 2s 199ms/step - loss: 0.0914 - accuracy: 0.9500 - val_loss: 0.3077 - val_accuracy: 0.7783\n",
            "Epoch 635/1000\n",
            "10/10 [==============================] - 2s 204ms/step - loss: 0.0803 - accuracy: 1.0000 - val_loss: 0.3076 - val_accuracy: 0.7833\n",
            "Epoch 636/1000\n",
            "10/10 [==============================] - 2s 198ms/step - loss: 0.0909 - accuracy: 0.9750 - val_loss: 0.3084 - val_accuracy: 0.7783\n",
            "Epoch 637/1000\n",
            "10/10 [==============================] - 2s 205ms/step - loss: 0.1181 - accuracy: 0.9500 - val_loss: 0.3088 - val_accuracy: 0.7783\n",
            "Epoch 638/1000\n",
            "10/10 [==============================] - 2s 195ms/step - loss: 0.1008 - accuracy: 0.9500 - val_loss: 0.3097 - val_accuracy: 0.7734\n",
            "Epoch 639/1000\n",
            "10/10 [==============================] - 2s 199ms/step - loss: 0.0905 - accuracy: 0.9875 - val_loss: 0.3099 - val_accuracy: 0.7734\n",
            "Epoch 640/1000\n",
            "10/10 [==============================] - 2s 202ms/step - loss: 0.1073 - accuracy: 0.9250 - val_loss: 0.3099 - val_accuracy: 0.7734\n",
            "Epoch 641/1000\n",
            "10/10 [==============================] - 2s 192ms/step - loss: 0.0883 - accuracy: 0.9863 - val_loss: 0.3111 - val_accuracy: 0.7685\n",
            "Epoch 642/1000\n",
            "10/10 [==============================] - 2s 195ms/step - loss: 0.0970 - accuracy: 0.9750 - val_loss: 0.3126 - val_accuracy: 0.7635\n",
            "Epoch 643/1000\n",
            "10/10 [==============================] - 2s 203ms/step - loss: 0.0948 - accuracy: 0.9625 - val_loss: 0.3122 - val_accuracy: 0.7635\n",
            "Epoch 644/1000\n",
            "10/10 [==============================] - 2s 198ms/step - loss: 0.0870 - accuracy: 0.9875 - val_loss: 0.3113 - val_accuracy: 0.7635\n",
            "Epoch 645/1000\n",
            "10/10 [==============================] - 2s 195ms/step - loss: 0.0989 - accuracy: 0.9500 - val_loss: 0.3109 - val_accuracy: 0.7734\n",
            "Epoch 646/1000\n",
            "10/10 [==============================] - 2s 189ms/step - loss: 0.0912 - accuracy: 0.9625 - val_loss: 0.3098 - val_accuracy: 0.7734\n",
            "Epoch 647/1000\n",
            "10/10 [==============================] - 2s 190ms/step - loss: 0.0855 - accuracy: 0.9750 - val_loss: 0.3105 - val_accuracy: 0.7734\n",
            "Epoch 648/1000\n",
            "10/10 [==============================] - 2s 200ms/step - loss: 0.1174 - accuracy: 0.9500 - val_loss: 0.3106 - val_accuracy: 0.7734\n",
            "Epoch 649/1000\n",
            "10/10 [==============================] - 2s 208ms/step - loss: 0.1004 - accuracy: 0.9500 - val_loss: 0.3107 - val_accuracy: 0.7734\n",
            "Epoch 650/1000\n",
            "10/10 [==============================] - 2s 207ms/step - loss: 0.1169 - accuracy: 0.9589 - val_loss: 0.3101 - val_accuracy: 0.7734\n",
            "Epoch 651/1000\n",
            "10/10 [==============================] - 2s 195ms/step - loss: 0.0908 - accuracy: 0.9726 - val_loss: 0.3095 - val_accuracy: 0.7734\n",
            "Epoch 652/1000\n",
            "10/10 [==============================] - 2s 200ms/step - loss: 0.1013 - accuracy: 0.9625 - val_loss: 0.3082 - val_accuracy: 0.7783\n",
            "Epoch 653/1000\n",
            "10/10 [==============================] - 2s 212ms/step - loss: 0.0930 - accuracy: 0.9500 - val_loss: 0.3083 - val_accuracy: 0.7783\n",
            "Epoch 654/1000\n",
            "10/10 [==============================] - 2s 194ms/step - loss: 0.1002 - accuracy: 0.9500 - val_loss: 0.3094 - val_accuracy: 0.7734\n",
            "Epoch 655/1000\n",
            "10/10 [==============================] - 2s 208ms/step - loss: 0.0725 - accuracy: 1.0000 - val_loss: 0.3097 - val_accuracy: 0.7734\n",
            "Epoch 656/1000\n",
            "10/10 [==============================] - 2s 203ms/step - loss: 0.0951 - accuracy: 0.9863 - val_loss: 0.3087 - val_accuracy: 0.7734\n",
            "Epoch 657/1000\n",
            "10/10 [==============================] - 2s 194ms/step - loss: 0.1037 - accuracy: 0.9750 - val_loss: 0.3084 - val_accuracy: 0.7734\n",
            "Epoch 658/1000\n",
            "10/10 [==============================] - 2s 205ms/step - loss: 0.0784 - accuracy: 1.0000 - val_loss: 0.3080 - val_accuracy: 0.7783\n",
            "Epoch 659/1000\n",
            "10/10 [==============================] - 2s 202ms/step - loss: 0.0795 - accuracy: 0.9863 - val_loss: 0.3083 - val_accuracy: 0.7783\n",
            "Epoch 660/1000\n",
            "10/10 [==============================] - 2s 195ms/step - loss: 0.0796 - accuracy: 0.9875 - val_loss: 0.3087 - val_accuracy: 0.7734\n",
            "Epoch 661/1000\n",
            "10/10 [==============================] - 2s 202ms/step - loss: 0.0934 - accuracy: 0.9875 - val_loss: 0.3095 - val_accuracy: 0.7734\n",
            "Epoch 662/1000\n",
            "10/10 [==============================] - 2s 195ms/step - loss: 0.1044 - accuracy: 0.9625 - val_loss: 0.3102 - val_accuracy: 0.7734\n",
            "Epoch 663/1000\n",
            "10/10 [==============================] - 2s 204ms/step - loss: 0.1026 - accuracy: 0.9452 - val_loss: 0.3110 - val_accuracy: 0.7635\n",
            "Epoch 664/1000\n",
            "10/10 [==============================] - 2s 198ms/step - loss: 0.0892 - accuracy: 1.0000 - val_loss: 0.3123 - val_accuracy: 0.7635\n",
            "Epoch 665/1000\n",
            "10/10 [==============================] - 2s 198ms/step - loss: 0.0950 - accuracy: 0.9625 - val_loss: 0.3120 - val_accuracy: 0.7635\n",
            "Epoch 666/1000\n",
            "10/10 [==============================] - 2s 217ms/step - loss: 0.0986 - accuracy: 0.9500 - val_loss: 0.3114 - val_accuracy: 0.7635\n",
            "Epoch 667/1000\n",
            "10/10 [==============================] - 2s 207ms/step - loss: 0.0923 - accuracy: 0.9750 - val_loss: 0.3127 - val_accuracy: 0.7685\n",
            "Epoch 668/1000\n",
            "10/10 [==============================] - 2s 204ms/step - loss: 0.0875 - accuracy: 0.9875 - val_loss: 0.3130 - val_accuracy: 0.7685\n",
            "Epoch 669/1000\n",
            "10/10 [==============================] - 2s 217ms/step - loss: 0.0761 - accuracy: 1.0000 - val_loss: 0.3143 - val_accuracy: 0.7685\n",
            "Epoch 670/1000\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 0.0883 - accuracy: 0.9750 - val_loss: 0.3140 - val_accuracy: 0.7685\n",
            "Epoch 671/1000\n",
            "10/10 [==============================] - 2s 199ms/step - loss: 0.1018 - accuracy: 0.9500 - val_loss: 0.3140 - val_accuracy: 0.7685\n",
            "Epoch 672/1000\n",
            "10/10 [==============================] - 2s 199ms/step - loss: 0.0730 - accuracy: 1.0000 - val_loss: 0.3129 - val_accuracy: 0.7635\n",
            "Epoch 673/1000\n",
            "10/10 [==============================] - 2s 208ms/step - loss: 0.0908 - accuracy: 0.9863 - val_loss: 0.3119 - val_accuracy: 0.7635\n",
            "Epoch 674/1000\n",
            "10/10 [==============================] - 2s 195ms/step - loss: 0.0817 - accuracy: 0.9875 - val_loss: 0.3106 - val_accuracy: 0.7635\n",
            "Epoch 675/1000\n",
            "10/10 [==============================] - 2s 191ms/step - loss: 0.1012 - accuracy: 0.9625 - val_loss: 0.3095 - val_accuracy: 0.7734\n",
            "Epoch 676/1000\n",
            "10/10 [==============================] - 2s 195ms/step - loss: 0.0941 - accuracy: 0.9625 - val_loss: 0.3090 - val_accuracy: 0.7734\n",
            "Epoch 677/1000\n",
            "10/10 [==============================] - 2s 205ms/step - loss: 0.0831 - accuracy: 0.9750 - val_loss: 0.3092 - val_accuracy: 0.7734\n",
            "Epoch 678/1000\n",
            "10/10 [==============================] - 2s 194ms/step - loss: 0.0784 - accuracy: 0.9875 - val_loss: 0.3091 - val_accuracy: 0.7734\n",
            "Epoch 679/1000\n",
            "10/10 [==============================] - 2s 199ms/step - loss: 0.0859 - accuracy: 0.9750 - val_loss: 0.3097 - val_accuracy: 0.7685\n",
            "Epoch 680/1000\n",
            "10/10 [==============================] - 2s 206ms/step - loss: 0.0799 - accuracy: 0.9750 - val_loss: 0.3096 - val_accuracy: 0.7734\n",
            "Epoch 681/1000\n",
            "10/10 [==============================] - 2s 193ms/step - loss: 0.1073 - accuracy: 0.9375 - val_loss: 0.3087 - val_accuracy: 0.7734\n",
            "Epoch 682/1000\n",
            "10/10 [==============================] - 2s 192ms/step - loss: 0.0819 - accuracy: 0.9875 - val_loss: 0.3080 - val_accuracy: 0.7783\n",
            "Epoch 683/1000\n",
            "10/10 [==============================] - 2s 206ms/step - loss: 0.0883 - accuracy: 0.9875 - val_loss: 0.3071 - val_accuracy: 0.7783\n",
            "Epoch 684/1000\n",
            "10/10 [==============================] - 2s 195ms/step - loss: 0.1092 - accuracy: 0.9625 - val_loss: 0.3065 - val_accuracy: 0.7833\n",
            "Epoch 685/1000\n",
            "10/10 [==============================] - 2s 197ms/step - loss: 0.0928 - accuracy: 0.9875 - val_loss: 0.3067 - val_accuracy: 0.7833\n",
            "Epoch 686/1000\n",
            "10/10 [==============================] - 2s 200ms/step - loss: 0.0869 - accuracy: 1.0000 - val_loss: 0.3064 - val_accuracy: 0.7833\n",
            "Epoch 687/1000\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 0.0982 - accuracy: 0.9750 - val_loss: 0.3059 - val_accuracy: 0.7882\n",
            "Epoch 688/1000\n",
            "10/10 [==============================] - 2s 198ms/step - loss: 0.0868 - accuracy: 0.9875 - val_loss: 0.3062 - val_accuracy: 0.7833\n",
            "Epoch 689/1000\n",
            "10/10 [==============================] - 2s 202ms/step - loss: 0.0941 - accuracy: 0.9875 - val_loss: 0.3081 - val_accuracy: 0.7783\n",
            "Epoch 690/1000\n",
            "10/10 [==============================] - 2s 197ms/step - loss: 0.0794 - accuracy: 1.0000 - val_loss: 0.3096 - val_accuracy: 0.7685\n",
            "Epoch 691/1000\n",
            "10/10 [==============================] - 2s 211ms/step - loss: 0.1054 - accuracy: 0.9500 - val_loss: 0.3105 - val_accuracy: 0.7635\n",
            "Epoch 692/1000\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 0.0919 - accuracy: 0.9750 - val_loss: 0.3107 - val_accuracy: 0.7635\n",
            "Epoch 693/1000\n",
            "10/10 [==============================] - 2s 199ms/step - loss: 0.0943 - accuracy: 0.9750 - val_loss: 0.3105 - val_accuracy: 0.7635\n",
            "Epoch 694/1000\n",
            "10/10 [==============================] - 2s 196ms/step - loss: 0.0974 - accuracy: 0.9625 - val_loss: 0.3103 - val_accuracy: 0.7635\n",
            "Epoch 695/1000\n",
            "10/10 [==============================] - 2s 196ms/step - loss: 0.1034 - accuracy: 0.9500 - val_loss: 0.3103 - val_accuracy: 0.7635\n",
            "Epoch 696/1000\n",
            "10/10 [==============================] - 2s 210ms/step - loss: 0.0840 - accuracy: 0.9750 - val_loss: 0.3103 - val_accuracy: 0.7635\n",
            "Epoch 697/1000\n",
            "10/10 [==============================] - 2s 197ms/step - loss: 0.0789 - accuracy: 0.9875 - val_loss: 0.3108 - val_accuracy: 0.7635\n",
            "Epoch 698/1000\n",
            "10/10 [==============================] - 2s 205ms/step - loss: 0.1050 - accuracy: 0.9500 - val_loss: 0.3113 - val_accuracy: 0.7635\n",
            "Epoch 699/1000\n",
            "10/10 [==============================] - 2s 206ms/step - loss: 0.0798 - accuracy: 0.9875 - val_loss: 0.3109 - val_accuracy: 0.7635\n",
            "Epoch 700/1000\n",
            "10/10 [==============================] - 2s 207ms/step - loss: 0.0704 - accuracy: 1.0000 - val_loss: 0.3106 - val_accuracy: 0.7635\n",
            "Epoch 701/1000\n",
            "10/10 [==============================] - 2s 200ms/step - loss: 0.0983 - accuracy: 0.9625 - val_loss: 0.3097 - val_accuracy: 0.7685\n",
            "Epoch 702/1000\n",
            "10/10 [==============================] - 2s 202ms/step - loss: 0.0983 - accuracy: 0.9625 - val_loss: 0.3092 - val_accuracy: 0.7685\n",
            "Epoch 703/1000\n",
            "10/10 [==============================] - 2s 200ms/step - loss: 0.0774 - accuracy: 0.9750 - val_loss: 0.3092 - val_accuracy: 0.7734\n",
            "Epoch 704/1000\n",
            "10/10 [==============================] - 2s 199ms/step - loss: 0.1046 - accuracy: 0.9500 - val_loss: 0.3099 - val_accuracy: 0.7635\n",
            "Epoch 705/1000\n",
            "10/10 [==============================] - 2s 203ms/step - loss: 0.0864 - accuracy: 0.9625 - val_loss: 0.3104 - val_accuracy: 0.7635\n",
            "Epoch 706/1000\n",
            "10/10 [==============================] - 2s 206ms/step - loss: 0.0996 - accuracy: 0.9625 - val_loss: 0.3100 - val_accuracy: 0.7635\n",
            "Epoch 707/1000\n",
            "10/10 [==============================] - 2s 200ms/step - loss: 0.0894 - accuracy: 0.9750 - val_loss: 0.3104 - val_accuracy: 0.7635\n",
            "Epoch 708/1000\n",
            "10/10 [==============================] - 2s 203ms/step - loss: 0.1022 - accuracy: 0.9375 - val_loss: 0.3099 - val_accuracy: 0.7635\n",
            "Epoch 709/1000\n",
            "10/10 [==============================] - 2s 195ms/step - loss: 0.0859 - accuracy: 0.9875 - val_loss: 0.3093 - val_accuracy: 0.7734\n",
            "Epoch 710/1000\n",
            "10/10 [==============================] - 2s 206ms/step - loss: 0.0955 - accuracy: 0.9750 - val_loss: 0.3100 - val_accuracy: 0.7635\n",
            "Epoch 711/1000\n",
            "10/10 [==============================] - 2s 193ms/step - loss: 0.1044 - accuracy: 0.9452 - val_loss: 0.3116 - val_accuracy: 0.7635\n",
            "Epoch 712/1000\n",
            "10/10 [==============================] - 2s 196ms/step - loss: 0.0805 - accuracy: 0.9875 - val_loss: 0.3124 - val_accuracy: 0.7635\n",
            "Epoch 713/1000\n",
            "10/10 [==============================] - 2s 198ms/step - loss: 0.0864 - accuracy: 0.9875 - val_loss: 0.3130 - val_accuracy: 0.7635\n",
            "Epoch 714/1000\n",
            "10/10 [==============================] - 2s 202ms/step - loss: 0.0880 - accuracy: 1.0000 - val_loss: 0.3133 - val_accuracy: 0.7635\n",
            "Epoch 715/1000\n",
            "10/10 [==============================] - 2s 194ms/step - loss: 0.0985 - accuracy: 0.9750 - val_loss: 0.3127 - val_accuracy: 0.7635\n",
            "Epoch 716/1000\n",
            "10/10 [==============================] - 2s 212ms/step - loss: 0.0882 - accuracy: 1.0000 - val_loss: 0.3123 - val_accuracy: 0.7635\n",
            "Epoch 717/1000\n",
            "10/10 [==============================] - 2s 205ms/step - loss: 0.1038 - accuracy: 0.9875 - val_loss: 0.3122 - val_accuracy: 0.7635\n",
            "Epoch 718/1000\n",
            "10/10 [==============================] - 2s 203ms/step - loss: 0.0999 - accuracy: 0.9750 - val_loss: 0.3111 - val_accuracy: 0.7635\n",
            "Epoch 719/1000\n",
            "10/10 [==============================] - 2s 199ms/step - loss: 0.1050 - accuracy: 0.9500 - val_loss: 0.3104 - val_accuracy: 0.7635\n",
            "Epoch 720/1000\n",
            "10/10 [==============================] - 2s 190ms/step - loss: 0.0825 - accuracy: 0.9863 - val_loss: 0.3104 - val_accuracy: 0.7635\n",
            "Epoch 721/1000\n",
            "10/10 [==============================] - 2s 214ms/step - loss: 0.0968 - accuracy: 0.9500 - val_loss: 0.3085 - val_accuracy: 0.7734\n",
            "Epoch 722/1000\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 0.0908 - accuracy: 1.0000 - val_loss: 0.3070 - val_accuracy: 0.7783\n",
            "Epoch 723/1000\n",
            "10/10 [==============================] - 2s 202ms/step - loss: 0.0819 - accuracy: 1.0000 - val_loss: 0.3069 - val_accuracy: 0.7783\n",
            "Epoch 724/1000\n",
            "10/10 [==============================] - 2s 203ms/step - loss: 0.1048 - accuracy: 0.9500 - val_loss: 0.3072 - val_accuracy: 0.7783\n",
            "Epoch 725/1000\n",
            "10/10 [==============================] - 2s 198ms/step - loss: 0.1088 - accuracy: 0.9589 - val_loss: 0.3078 - val_accuracy: 0.7783\n",
            "Epoch 726/1000\n",
            "10/10 [==============================] - 2s 188ms/step - loss: 0.0930 - accuracy: 0.9750 - val_loss: 0.3094 - val_accuracy: 0.7685\n",
            "Epoch 727/1000\n",
            "10/10 [==============================] - 2s 215ms/step - loss: 0.0881 - accuracy: 0.9750 - val_loss: 0.3096 - val_accuracy: 0.7685\n",
            "Epoch 728/1000\n",
            "10/10 [==============================] - 2s 197ms/step - loss: 0.0918 - accuracy: 0.9625 - val_loss: 0.3097 - val_accuracy: 0.7685\n",
            "Epoch 729/1000\n",
            "10/10 [==============================] - 2s 203ms/step - loss: 0.0905 - accuracy: 0.9875 - val_loss: 0.3092 - val_accuracy: 0.7685\n",
            "Epoch 730/1000\n",
            "10/10 [==============================] - 2s 195ms/step - loss: 0.0971 - accuracy: 0.9500 - val_loss: 0.3080 - val_accuracy: 0.7734\n",
            "Epoch 731/1000\n",
            "10/10 [==============================] - 2s 206ms/step - loss: 0.0884 - accuracy: 0.9875 - val_loss: 0.3076 - val_accuracy: 0.7783\n",
            "Epoch 732/1000\n",
            "10/10 [==============================] - 2s 200ms/step - loss: 0.1201 - accuracy: 0.9500 - val_loss: 0.3092 - val_accuracy: 0.7685\n",
            "Epoch 733/1000\n",
            "10/10 [==============================] - 2s 208ms/step - loss: 0.0806 - accuracy: 0.9750 - val_loss: 0.3099 - val_accuracy: 0.7685\n",
            "Epoch 734/1000\n",
            "10/10 [==============================] - 2s 194ms/step - loss: 0.0869 - accuracy: 0.9863 - val_loss: 0.3111 - val_accuracy: 0.7635\n",
            "Epoch 735/1000\n",
            "10/10 [==============================] - 2s 193ms/step - loss: 0.1034 - accuracy: 0.9863 - val_loss: 0.3150 - val_accuracy: 0.7685\n",
            "Epoch 736/1000\n",
            "10/10 [==============================] - 2s 193ms/step - loss: 0.0893 - accuracy: 0.9750 - val_loss: 0.3193 - val_accuracy: 0.7734\n",
            "Epoch 737/1000\n",
            "10/10 [==============================] - 2s 193ms/step - loss: 0.0797 - accuracy: 0.9863 - val_loss: 0.3203 - val_accuracy: 0.7685\n",
            "Epoch 738/1000\n",
            "10/10 [==============================] - 2s 215ms/step - loss: 0.0807 - accuracy: 1.0000 - val_loss: 0.3199 - val_accuracy: 0.7734\n",
            "Epoch 739/1000\n",
            "10/10 [==============================] - 2s 200ms/step - loss: 0.0922 - accuracy: 0.9875 - val_loss: 0.3178 - val_accuracy: 0.7635\n",
            "Epoch 740/1000\n",
            "10/10 [==============================] - 2s 200ms/step - loss: 0.1029 - accuracy: 0.9625 - val_loss: 0.3149 - val_accuracy: 0.7734\n",
            "Epoch 741/1000\n",
            "10/10 [==============================] - 2s 189ms/step - loss: 0.0994 - accuracy: 0.9625 - val_loss: 0.3121 - val_accuracy: 0.7635\n",
            "Epoch 742/1000\n",
            "10/10 [==============================] - 2s 196ms/step - loss: 0.0997 - accuracy: 0.9625 - val_loss: 0.3103 - val_accuracy: 0.7635\n",
            "Epoch 743/1000\n",
            "10/10 [==============================] - 2s 189ms/step - loss: 0.0897 - accuracy: 0.9750 - val_loss: 0.3084 - val_accuracy: 0.7685\n",
            "Epoch 744/1000\n",
            "10/10 [==============================] - 2s 191ms/step - loss: 0.0969 - accuracy: 0.9625 - val_loss: 0.3081 - val_accuracy: 0.7734\n",
            "Epoch 745/1000\n",
            "10/10 [==============================] - 2s 191ms/step - loss: 0.0933 - accuracy: 0.9875 - val_loss: 0.3084 - val_accuracy: 0.7685\n",
            "Epoch 746/1000\n",
            "10/10 [==============================] - 2s 191ms/step - loss: 0.0818 - accuracy: 1.0000 - val_loss: 0.3084 - val_accuracy: 0.7685\n",
            "Epoch 747/1000\n",
            "10/10 [==============================] - 2s 193ms/step - loss: 0.0929 - accuracy: 0.9750 - val_loss: 0.3090 - val_accuracy: 0.7734\n",
            "Epoch 748/1000\n",
            "10/10 [==============================] - 2s 202ms/step - loss: 0.0843 - accuracy: 0.9750 - val_loss: 0.3105 - val_accuracy: 0.7635\n",
            "Epoch 749/1000\n",
            "10/10 [==============================] - 2s 189ms/step - loss: 0.0933 - accuracy: 0.9726 - val_loss: 0.3108 - val_accuracy: 0.7635\n",
            "Epoch 750/1000\n",
            "10/10 [==============================] - 2s 203ms/step - loss: 0.0820 - accuracy: 0.9875 - val_loss: 0.3095 - val_accuracy: 0.7685\n",
            "Epoch 751/1000\n",
            "10/10 [==============================] - 2s 191ms/step - loss: 0.0891 - accuracy: 0.9875 - val_loss: 0.3096 - val_accuracy: 0.7685\n",
            "Epoch 752/1000\n",
            "10/10 [==============================] - 2s 190ms/step - loss: 0.0844 - accuracy: 0.9875 - val_loss: 0.3099 - val_accuracy: 0.7685\n",
            "Epoch 753/1000\n",
            "10/10 [==============================] - 2s 192ms/step - loss: 0.1049 - accuracy: 0.9500 - val_loss: 0.3086 - val_accuracy: 0.7734\n",
            "Epoch 754/1000\n",
            "10/10 [==============================] - 2s 195ms/step - loss: 0.1010 - accuracy: 0.9750 - val_loss: 0.3080 - val_accuracy: 0.7685\n",
            "Epoch 755/1000\n",
            "10/10 [==============================] - 2s 196ms/step - loss: 0.0900 - accuracy: 1.0000 - val_loss: 0.3079 - val_accuracy: 0.7734\n",
            "Epoch 756/1000\n",
            "10/10 [==============================] - 2s 198ms/step - loss: 0.0850 - accuracy: 0.9750 - val_loss: 0.3082 - val_accuracy: 0.7685\n",
            "Epoch 757/1000\n",
            "10/10 [==============================] - 2s 199ms/step - loss: 0.1032 - accuracy: 0.9500 - val_loss: 0.3090 - val_accuracy: 0.7685\n",
            "Epoch 758/1000\n",
            "10/10 [==============================] - 2s 191ms/step - loss: 0.1067 - accuracy: 0.9589 - val_loss: 0.3115 - val_accuracy: 0.7635\n",
            "Epoch 759/1000\n",
            "10/10 [==============================] - 2s 197ms/step - loss: 0.0919 - accuracy: 0.9750 - val_loss: 0.3122 - val_accuracy: 0.7685\n",
            "Epoch 760/1000\n",
            "10/10 [==============================] - 2s 207ms/step - loss: 0.0765 - accuracy: 1.0000 - val_loss: 0.3114 - val_accuracy: 0.7635\n",
            "Epoch 761/1000\n",
            "10/10 [==============================] - 2s 193ms/step - loss: 0.0950 - accuracy: 0.9875 - val_loss: 0.3114 - val_accuracy: 0.7635\n",
            "Epoch 762/1000\n",
            "10/10 [==============================] - 2s 190ms/step - loss: 0.1005 - accuracy: 0.9750 - val_loss: 0.3124 - val_accuracy: 0.7685\n",
            "Epoch 763/1000\n",
            "10/10 [==============================] - 2s 196ms/step - loss: 0.0931 - accuracy: 0.9750 - val_loss: 0.3115 - val_accuracy: 0.7685\n",
            "Epoch 764/1000\n",
            "10/10 [==============================] - 2s 195ms/step - loss: 0.0969 - accuracy: 0.9625 - val_loss: 0.3103 - val_accuracy: 0.7635\n",
            "Epoch 765/1000\n",
            "10/10 [==============================] - 2s 191ms/step - loss: 0.0834 - accuracy: 0.9750 - val_loss: 0.3101 - val_accuracy: 0.7685\n",
            "Epoch 766/1000\n",
            "10/10 [==============================] - 2s 199ms/step - loss: 0.0941 - accuracy: 0.9875 - val_loss: 0.3105 - val_accuracy: 0.7635\n",
            "Epoch 767/1000\n",
            "10/10 [==============================] - 2s 191ms/step - loss: 0.0987 - accuracy: 0.9875 - val_loss: 0.3108 - val_accuracy: 0.7635\n",
            "Epoch 768/1000\n",
            "10/10 [==============================] - 2s 196ms/step - loss: 0.0864 - accuracy: 0.9750 - val_loss: 0.3101 - val_accuracy: 0.7685\n",
            "Epoch 769/1000\n",
            "10/10 [==============================] - 2s 203ms/step - loss: 0.0992 - accuracy: 0.9625 - val_loss: 0.3107 - val_accuracy: 0.7635\n",
            "Epoch 770/1000\n",
            "10/10 [==============================] - 2s 200ms/step - loss: 0.0901 - accuracy: 0.9875 - val_loss: 0.3112 - val_accuracy: 0.7685\n",
            "Epoch 771/1000\n",
            "10/10 [==============================] - 2s 206ms/step - loss: 0.1027 - accuracy: 0.9500 - val_loss: 0.3122 - val_accuracy: 0.7685\n",
            "Epoch 772/1000\n",
            "10/10 [==============================] - 2s 195ms/step - loss: 0.0919 - accuracy: 0.9863 - val_loss: 0.3106 - val_accuracy: 0.7635\n",
            "Epoch 773/1000\n",
            "10/10 [==============================] - 2s 202ms/step - loss: 0.0871 - accuracy: 0.9875 - val_loss: 0.3099 - val_accuracy: 0.7685\n",
            "Epoch 774/1000\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 0.0863 - accuracy: 0.9875 - val_loss: 0.3095 - val_accuracy: 0.7685\n",
            "Epoch 775/1000\n",
            "10/10 [==============================] - 2s 190ms/step - loss: 0.0954 - accuracy: 0.9625 - val_loss: 0.3089 - val_accuracy: 0.7685\n",
            "Epoch 776/1000\n",
            "10/10 [==============================] - 2s 202ms/step - loss: 0.1060 - accuracy: 0.9500 - val_loss: 0.3088 - val_accuracy: 0.7685\n",
            "Epoch 777/1000\n",
            "10/10 [==============================] - 2s 193ms/step - loss: 0.0876 - accuracy: 0.9875 - val_loss: 0.3090 - val_accuracy: 0.7685\n",
            "Epoch 778/1000\n",
            "10/10 [==============================] - 2s 200ms/step - loss: 0.0788 - accuracy: 1.0000 - val_loss: 0.3103 - val_accuracy: 0.7685\n",
            "Epoch 779/1000\n",
            "10/10 [==============================] - 2s 192ms/step - loss: 0.0982 - accuracy: 0.9625 - val_loss: 0.3116 - val_accuracy: 0.7685\n",
            "Epoch 780/1000\n",
            "10/10 [==============================] - 2s 205ms/step - loss: 0.0855 - accuracy: 0.9875 - val_loss: 0.3121 - val_accuracy: 0.7685\n",
            "Epoch 781/1000\n",
            "10/10 [==============================] - 2s 188ms/step - loss: 0.0827 - accuracy: 0.9875 - val_loss: 0.3133 - val_accuracy: 0.7734\n",
            "Epoch 782/1000\n",
            "10/10 [==============================] - 2s 206ms/step - loss: 0.1040 - accuracy: 0.9589 - val_loss: 0.3126 - val_accuracy: 0.7685\n",
            "Epoch 783/1000\n",
            "10/10 [==============================] - 2s 200ms/step - loss: 0.0901 - accuracy: 0.9625 - val_loss: 0.3121 - val_accuracy: 0.7685\n",
            "Epoch 784/1000\n",
            "10/10 [==============================] - 2s 200ms/step - loss: 0.1028 - accuracy: 0.9625 - val_loss: 0.3117 - val_accuracy: 0.7685\n",
            "Epoch 785/1000\n",
            "10/10 [==============================] - 2s 192ms/step - loss: 0.0944 - accuracy: 0.9625 - val_loss: 0.3109 - val_accuracy: 0.7685\n",
            "Epoch 786/1000\n",
            "10/10 [==============================] - 2s 202ms/step - loss: 0.0891 - accuracy: 1.0000 - val_loss: 0.3094 - val_accuracy: 0.7685\n",
            "Epoch 787/1000\n",
            "10/10 [==============================] - 2s 206ms/step - loss: 0.0852 - accuracy: 1.0000 - val_loss: 0.3084 - val_accuracy: 0.7685\n",
            "Epoch 788/1000\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 0.1047 - accuracy: 0.9625 - val_loss: 0.3086 - val_accuracy: 0.7685\n",
            "Epoch 789/1000\n",
            "10/10 [==============================] - 2s 193ms/step - loss: 0.0861 - accuracy: 0.9875 - val_loss: 0.3093 - val_accuracy: 0.7685\n",
            "Epoch 790/1000\n",
            "10/10 [==============================] - 2s 192ms/step - loss: 0.1086 - accuracy: 0.9726 - val_loss: 0.3102 - val_accuracy: 0.7685\n",
            "Epoch 791/1000\n",
            "10/10 [==============================] - 2s 200ms/step - loss: 0.1067 - accuracy: 0.9750 - val_loss: 0.3108 - val_accuracy: 0.7685\n",
            "Epoch 792/1000\n",
            "10/10 [==============================] - 2s 194ms/step - loss: 0.0862 - accuracy: 0.9750 - val_loss: 0.3113 - val_accuracy: 0.7685\n",
            "Epoch 793/1000\n",
            "10/10 [==============================] - 2s 196ms/step - loss: 0.0915 - accuracy: 0.9750 - val_loss: 0.3101 - val_accuracy: 0.7685\n",
            "Epoch 794/1000\n",
            "10/10 [==============================] - 2s 205ms/step - loss: 0.0870 - accuracy: 0.9875 - val_loss: 0.3082 - val_accuracy: 0.7685\n",
            "Epoch 795/1000\n",
            "10/10 [==============================] - 2s 195ms/step - loss: 0.1067 - accuracy: 0.9625 - val_loss: 0.3076 - val_accuracy: 0.7734\n",
            "Epoch 796/1000\n",
            "10/10 [==============================] - 2s 197ms/step - loss: 0.0791 - accuracy: 1.0000 - val_loss: 0.3080 - val_accuracy: 0.7685\n",
            "Epoch 797/1000\n",
            "10/10 [==============================] - 2s 195ms/step - loss: 0.0844 - accuracy: 0.9875 - val_loss: 0.3092 - val_accuracy: 0.7685\n",
            "Epoch 798/1000\n",
            "10/10 [==============================] - 2s 207ms/step - loss: 0.0998 - accuracy: 0.9589 - val_loss: 0.3085 - val_accuracy: 0.7685\n",
            "Epoch 799/1000\n",
            "10/10 [==============================] - 2s 202ms/step - loss: 0.0917 - accuracy: 0.9875 - val_loss: 0.3081 - val_accuracy: 0.7685\n",
            "Epoch 800/1000\n",
            "10/10 [==============================] - 2s 200ms/step - loss: 0.0941 - accuracy: 0.9875 - val_loss: 0.3073 - val_accuracy: 0.7734\n",
            "Epoch 801/1000\n",
            "10/10 [==============================] - 2s 198ms/step - loss: 0.0805 - accuracy: 0.9875 - val_loss: 0.3059 - val_accuracy: 0.7783\n",
            "Epoch 802/1000\n",
            "10/10 [==============================] - 2s 198ms/step - loss: 0.0987 - accuracy: 0.9625 - val_loss: 0.3057 - val_accuracy: 0.7783\n",
            "Epoch 803/1000\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 0.1003 - accuracy: 0.9726 - val_loss: 0.3064 - val_accuracy: 0.7734\n",
            "Epoch 804/1000\n",
            "10/10 [==============================] - 2s 200ms/step - loss: 0.0958 - accuracy: 0.9875 - val_loss: 0.3072 - val_accuracy: 0.7734\n",
            "Epoch 805/1000\n",
            "10/10 [==============================] - 2s 194ms/step - loss: 0.0868 - accuracy: 1.0000 - val_loss: 0.3060 - val_accuracy: 0.7783\n",
            "Epoch 806/1000\n",
            "10/10 [==============================] - 2s 209ms/step - loss: 0.0830 - accuracy: 0.9875 - val_loss: 0.3053 - val_accuracy: 0.7734\n",
            "Epoch 807/1000\n",
            "10/10 [==============================] - 2s 199ms/step - loss: 0.0833 - accuracy: 0.9875 - val_loss: 0.3048 - val_accuracy: 0.7734\n",
            "Epoch 808/1000\n",
            "10/10 [==============================] - 2s 200ms/step - loss: 0.1045 - accuracy: 0.9625 - val_loss: 0.3045 - val_accuracy: 0.7783\n",
            "Epoch 809/1000\n",
            "10/10 [==============================] - 2s 198ms/step - loss: 0.1001 - accuracy: 0.9750 - val_loss: 0.3049 - val_accuracy: 0.7734\n",
            "Epoch 810/1000\n",
            "10/10 [==============================] - 2s 198ms/step - loss: 0.1003 - accuracy: 0.9500 - val_loss: 0.3063 - val_accuracy: 0.7734\n",
            "Epoch 811/1000\n",
            "10/10 [==============================] - 2s 196ms/step - loss: 0.0897 - accuracy: 0.9750 - val_loss: 0.3070 - val_accuracy: 0.7734\n",
            "Epoch 812/1000\n",
            "10/10 [==============================] - 2s 209ms/step - loss: 0.1016 - accuracy: 0.9863 - val_loss: 0.3067 - val_accuracy: 0.7734\n",
            "Epoch 813/1000\n",
            "10/10 [==============================] - 2s 196ms/step - loss: 0.1062 - accuracy: 0.9726 - val_loss: 0.3055 - val_accuracy: 0.7734\n",
            "Epoch 814/1000\n",
            "10/10 [==============================] - 2s 199ms/step - loss: 0.1208 - accuracy: 0.9375 - val_loss: 0.3051 - val_accuracy: 0.7734\n",
            "Epoch 815/1000\n",
            "10/10 [==============================] - 2s 207ms/step - loss: 0.1089 - accuracy: 0.9500 - val_loss: 0.3058 - val_accuracy: 0.7734\n",
            "Epoch 816/1000\n",
            "10/10 [==============================] - 2s 214ms/step - loss: 0.0852 - accuracy: 0.9875 - val_loss: 0.3062 - val_accuracy: 0.7734\n",
            "Epoch 817/1000\n",
            "10/10 [==============================] - 2s 210ms/step - loss: 0.0778 - accuracy: 1.0000 - val_loss: 0.3067 - val_accuracy: 0.7734\n",
            "Epoch 818/1000\n",
            "10/10 [==============================] - 2s 216ms/step - loss: 0.0895 - accuracy: 0.9750 - val_loss: 0.3079 - val_accuracy: 0.7685\n",
            "Epoch 819/1000\n",
            "10/10 [==============================] - 2s 195ms/step - loss: 0.1025 - accuracy: 0.9750 - val_loss: 0.3090 - val_accuracy: 0.7685\n",
            "Epoch 820/1000\n",
            "10/10 [==============================] - 2s 199ms/step - loss: 0.0909 - accuracy: 0.9625 - val_loss: 0.3095 - val_accuracy: 0.7685\n",
            "Epoch 821/1000\n",
            "10/10 [==============================] - 2s 207ms/step - loss: 0.1006 - accuracy: 0.9863 - val_loss: 0.3109 - val_accuracy: 0.7734\n",
            "Epoch 822/1000\n",
            "10/10 [==============================] - 2s 195ms/step - loss: 0.0796 - accuracy: 0.9875 - val_loss: 0.3103 - val_accuracy: 0.7734\n",
            "Epoch 823/1000\n",
            "10/10 [==============================] - 2s 195ms/step - loss: 0.1020 - accuracy: 0.9625 - val_loss: 0.3105 - val_accuracy: 0.7734\n",
            "Epoch 824/1000\n",
            "10/10 [==============================] - 2s 205ms/step - loss: 0.0745 - accuracy: 1.0000 - val_loss: 0.3106 - val_accuracy: 0.7734\n",
            "Epoch 825/1000\n",
            "10/10 [==============================] - 2s 196ms/step - loss: 0.0709 - accuracy: 1.0000 - val_loss: 0.3112 - val_accuracy: 0.7635\n",
            "Epoch 826/1000\n",
            "10/10 [==============================] - 2s 205ms/step - loss: 0.0844 - accuracy: 0.9875 - val_loss: 0.3116 - val_accuracy: 0.7635\n",
            "Epoch 827/1000\n",
            "10/10 [==============================] - 2s 213ms/step - loss: 0.0845 - accuracy: 0.9875 - val_loss: 0.3115 - val_accuracy: 0.7635\n",
            "Epoch 828/1000\n",
            "10/10 [==============================] - 2s 199ms/step - loss: 0.0855 - accuracy: 0.9875 - val_loss: 0.3105 - val_accuracy: 0.7734\n",
            "Epoch 829/1000\n",
            "10/10 [==============================] - 2s 191ms/step - loss: 0.0827 - accuracy: 0.9750 - val_loss: 0.3097 - val_accuracy: 0.7734\n",
            "Epoch 830/1000\n",
            "10/10 [==============================] - 2s 192ms/step - loss: 0.0962 - accuracy: 0.9750 - val_loss: 0.3088 - val_accuracy: 0.7685\n",
            "Epoch 831/1000\n",
            "10/10 [==============================] - 2s 196ms/step - loss: 0.0833 - accuracy: 1.0000 - val_loss: 0.3079 - val_accuracy: 0.7685\n",
            "Epoch 832/1000\n",
            "10/10 [==============================] - 2s 199ms/step - loss: 0.1172 - accuracy: 0.9375 - val_loss: 0.3073 - val_accuracy: 0.7685\n",
            "Epoch 833/1000\n",
            "10/10 [==============================] - 2s 192ms/step - loss: 0.0951 - accuracy: 0.9625 - val_loss: 0.3077 - val_accuracy: 0.7685\n",
            "Epoch 834/1000\n",
            "10/10 [==============================] - 2s 190ms/step - loss: 0.0999 - accuracy: 0.9625 - val_loss: 0.3075 - val_accuracy: 0.7685\n",
            "Epoch 835/1000\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 0.0914 - accuracy: 0.9726 - val_loss: 0.3059 - val_accuracy: 0.7685\n",
            "Epoch 836/1000\n",
            "10/10 [==============================] - 2s 206ms/step - loss: 0.0882 - accuracy: 0.9863 - val_loss: 0.3050 - val_accuracy: 0.7734\n",
            "Epoch 837/1000\n",
            "10/10 [==============================] - 2s 198ms/step - loss: 0.0959 - accuracy: 0.9625 - val_loss: 0.3040 - val_accuracy: 0.7783\n",
            "Epoch 838/1000\n",
            "10/10 [==============================] - 2s 194ms/step - loss: 0.0886 - accuracy: 0.9875 - val_loss: 0.3045 - val_accuracy: 0.7734\n",
            "Epoch 839/1000\n",
            "10/10 [==============================] - 2s 194ms/step - loss: 0.0933 - accuracy: 0.9750 - val_loss: 0.3044 - val_accuracy: 0.7734\n",
            "Epoch 840/1000\n",
            "10/10 [==============================] - 2s 197ms/step - loss: 0.0841 - accuracy: 0.9625 - val_loss: 0.3042 - val_accuracy: 0.7783\n",
            "Epoch 841/1000\n",
            "10/10 [==============================] - 2s 189ms/step - loss: 0.0915 - accuracy: 0.9625 - val_loss: 0.3044 - val_accuracy: 0.7734\n",
            "Epoch 842/1000\n",
            "10/10 [==============================] - 2s 194ms/step - loss: 0.0995 - accuracy: 0.9625 - val_loss: 0.3046 - val_accuracy: 0.7734\n",
            "Epoch 843/1000\n",
            "10/10 [==============================] - 2s 208ms/step - loss: 0.0974 - accuracy: 0.9589 - val_loss: 0.3045 - val_accuracy: 0.7734\n",
            "Epoch 844/1000\n",
            "10/10 [==============================] - 2s 186ms/step - loss: 0.0921 - accuracy: 0.9863 - val_loss: 0.3061 - val_accuracy: 0.7685\n",
            "Epoch 845/1000\n",
            "10/10 [==============================] - 2s 199ms/step - loss: 0.0898 - accuracy: 0.9750 - val_loss: 0.3072 - val_accuracy: 0.7685\n",
            "Epoch 846/1000\n",
            "10/10 [==============================] - 2s 204ms/step - loss: 0.0788 - accuracy: 0.9875 - val_loss: 0.3076 - val_accuracy: 0.7685\n",
            "Epoch 847/1000\n",
            "10/10 [==============================] - 2s 196ms/step - loss: 0.1075 - accuracy: 0.9863 - val_loss: 0.3075 - val_accuracy: 0.7685\n",
            "Epoch 848/1000\n",
            "10/10 [==============================] - 2s 191ms/step - loss: 0.1198 - accuracy: 0.9375 - val_loss: 0.3087 - val_accuracy: 0.7734\n",
            "Epoch 849/1000\n",
            "10/10 [==============================] - 2s 195ms/step - loss: 0.1136 - accuracy: 0.9375 - val_loss: 0.3104 - val_accuracy: 0.7685\n",
            "Epoch 850/1000\n",
            "10/10 [==============================] - 2s 206ms/step - loss: 0.0759 - accuracy: 1.0000 - val_loss: 0.3109 - val_accuracy: 0.7685\n",
            "Epoch 851/1000\n",
            "10/10 [==============================] - 2s 196ms/step - loss: 0.0810 - accuracy: 0.9875 - val_loss: 0.3104 - val_accuracy: 0.7685\n",
            "Epoch 852/1000\n",
            "10/10 [==============================] - 2s 198ms/step - loss: 0.0869 - accuracy: 0.9875 - val_loss: 0.3109 - val_accuracy: 0.7685\n",
            "Epoch 853/1000\n",
            "10/10 [==============================] - 2s 209ms/step - loss: 0.0916 - accuracy: 0.9875 - val_loss: 0.3115 - val_accuracy: 0.7635\n",
            "Epoch 854/1000\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 0.0908 - accuracy: 0.9750 - val_loss: 0.3131 - val_accuracy: 0.7635\n",
            "Epoch 855/1000\n",
            "10/10 [==============================] - 2s 195ms/step - loss: 0.0851 - accuracy: 0.9625 - val_loss: 0.3132 - val_accuracy: 0.7635\n",
            "Epoch 856/1000\n",
            "10/10 [==============================] - 2s 205ms/step - loss: 0.0878 - accuracy: 0.9875 - val_loss: 0.3127 - val_accuracy: 0.7635\n",
            "Epoch 857/1000\n",
            "10/10 [==============================] - 2s 194ms/step - loss: 0.0853 - accuracy: 0.9863 - val_loss: 0.3131 - val_accuracy: 0.7635\n",
            "Epoch 858/1000\n",
            "10/10 [==============================] - 2s 197ms/step - loss: 0.0817 - accuracy: 1.0000 - val_loss: 0.3145 - val_accuracy: 0.7635\n",
            "Epoch 859/1000\n",
            "10/10 [==============================] - 2s 196ms/step - loss: 0.1210 - accuracy: 0.9375 - val_loss: 0.3140 - val_accuracy: 0.7635\n",
            "Epoch 860/1000\n",
            "10/10 [==============================] - 2s 205ms/step - loss: 0.0790 - accuracy: 0.9863 - val_loss: 0.3114 - val_accuracy: 0.7685\n",
            "Epoch 861/1000\n",
            "10/10 [==============================] - 2s 192ms/step - loss: 0.1146 - accuracy: 0.9726 - val_loss: 0.3105 - val_accuracy: 0.7685\n",
            "Epoch 862/1000\n",
            "10/10 [==============================] - 2s 198ms/step - loss: 0.0973 - accuracy: 0.9726 - val_loss: 0.3097 - val_accuracy: 0.7685\n",
            "Epoch 863/1000\n",
            "10/10 [==============================] - 2s 203ms/step - loss: 0.1052 - accuracy: 0.9750 - val_loss: 0.3098 - val_accuracy: 0.7685\n",
            "Epoch 864/1000\n",
            "10/10 [==============================] - 2s 193ms/step - loss: 0.1119 - accuracy: 0.9452 - val_loss: 0.3092 - val_accuracy: 0.7734\n",
            "Epoch 865/1000\n",
            "10/10 [==============================] - 2s 193ms/step - loss: 0.0785 - accuracy: 0.9750 - val_loss: 0.3087 - val_accuracy: 0.7635\n",
            "Epoch 866/1000\n",
            "10/10 [==============================] - 2s 199ms/step - loss: 0.0926 - accuracy: 0.9726 - val_loss: 0.3084 - val_accuracy: 0.7635\n",
            "Epoch 867/1000\n",
            "10/10 [==============================] - 2s 196ms/step - loss: 0.0998 - accuracy: 0.9750 - val_loss: 0.3080 - val_accuracy: 0.7685\n",
            "Epoch 868/1000\n",
            "10/10 [==============================] - 2s 203ms/step - loss: 0.0820 - accuracy: 0.9875 - val_loss: 0.3093 - val_accuracy: 0.7734\n",
            "Epoch 869/1000\n",
            "10/10 [==============================] - 2s 196ms/step - loss: 0.0722 - accuracy: 0.9875 - val_loss: 0.3102 - val_accuracy: 0.7685\n",
            "Epoch 870/1000\n",
            "10/10 [==============================] - 2s 198ms/step - loss: 0.0906 - accuracy: 0.9750 - val_loss: 0.3104 - val_accuracy: 0.7685\n",
            "Epoch 871/1000\n",
            "10/10 [==============================] - 2s 192ms/step - loss: 0.0925 - accuracy: 0.9750 - val_loss: 0.3111 - val_accuracy: 0.7685\n",
            "Epoch 872/1000\n",
            "10/10 [==============================] - 2s 196ms/step - loss: 0.0891 - accuracy: 0.9500 - val_loss: 0.3113 - val_accuracy: 0.7685\n",
            "Epoch 873/1000\n",
            "10/10 [==============================] - 2s 189ms/step - loss: 0.0816 - accuracy: 1.0000 - val_loss: 0.3120 - val_accuracy: 0.7685\n",
            "Epoch 874/1000\n",
            "10/10 [==============================] - 2s 196ms/step - loss: 0.0922 - accuracy: 0.9875 - val_loss: 0.3111 - val_accuracy: 0.7685\n",
            "Epoch 875/1000\n",
            "10/10 [==============================] - 2s 187ms/step - loss: 0.0849 - accuracy: 0.9863 - val_loss: 0.3119 - val_accuracy: 0.7685\n",
            "Epoch 876/1000\n",
            "10/10 [==============================] - 2s 193ms/step - loss: 0.0911 - accuracy: 0.9875 - val_loss: 0.3139 - val_accuracy: 0.7635\n",
            "Epoch 877/1000\n",
            "10/10 [==============================] - 2s 194ms/step - loss: 0.0837 - accuracy: 0.9875 - val_loss: 0.3145 - val_accuracy: 0.7635\n",
            "Epoch 878/1000\n",
            "10/10 [==============================] - 2s 195ms/step - loss: 0.0736 - accuracy: 0.9875 - val_loss: 0.3140 - val_accuracy: 0.7635\n",
            "Epoch 879/1000\n",
            "10/10 [==============================] - 2s 192ms/step - loss: 0.0817 - accuracy: 1.0000 - val_loss: 0.3136 - val_accuracy: 0.7635\n",
            "Epoch 880/1000\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 0.0849 - accuracy: 1.0000 - val_loss: 0.3132 - val_accuracy: 0.7635\n",
            "Epoch 881/1000\n",
            "10/10 [==============================] - 2s 198ms/step - loss: 0.0896 - accuracy: 0.9750 - val_loss: 0.3107 - val_accuracy: 0.7685\n",
            "Epoch 882/1000\n",
            "10/10 [==============================] - 2s 214ms/step - loss: 0.0915 - accuracy: 0.9875 - val_loss: 0.3082 - val_accuracy: 0.7685\n",
            "Epoch 883/1000\n",
            "10/10 [==============================] - 2s 189ms/step - loss: 0.0888 - accuracy: 0.9875 - val_loss: 0.3071 - val_accuracy: 0.7635\n",
            "Epoch 884/1000\n",
            "10/10 [==============================] - 2s 197ms/step - loss: 0.0764 - accuracy: 1.0000 - val_loss: 0.3064 - val_accuracy: 0.7635\n",
            "Epoch 885/1000\n",
            "10/10 [==============================] - 2s 195ms/step - loss: 0.0915 - accuracy: 0.9750 - val_loss: 0.3063 - val_accuracy: 0.7685\n",
            "Epoch 886/1000\n",
            "10/10 [==============================] - 2s 192ms/step - loss: 0.0875 - accuracy: 0.9875 - val_loss: 0.3059 - val_accuracy: 0.7685\n",
            "Epoch 887/1000\n",
            "10/10 [==============================] - 2s 193ms/step - loss: 0.0867 - accuracy: 0.9875 - val_loss: 0.3074 - val_accuracy: 0.7635\n",
            "Epoch 888/1000\n",
            "10/10 [==============================] - 2s 191ms/step - loss: 0.0974 - accuracy: 0.9750 - val_loss: 0.3084 - val_accuracy: 0.7635\n",
            "Epoch 889/1000\n",
            "10/10 [==============================] - 2s 204ms/step - loss: 0.1047 - accuracy: 0.9625 - val_loss: 0.3096 - val_accuracy: 0.7685\n",
            "Epoch 890/1000\n",
            "10/10 [==============================] - 2s 192ms/step - loss: 0.0988 - accuracy: 0.9625 - val_loss: 0.3115 - val_accuracy: 0.7685\n",
            "Epoch 891/1000\n",
            "10/10 [==============================] - 2s 191ms/step - loss: 0.0966 - accuracy: 0.9589 - val_loss: 0.3127 - val_accuracy: 0.7635\n",
            "Epoch 892/1000\n",
            "10/10 [==============================] - 2s 195ms/step - loss: 0.0908 - accuracy: 0.9750 - val_loss: 0.3126 - val_accuracy: 0.7635\n",
            "Epoch 893/1000\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 0.1183 - accuracy: 0.9452 - val_loss: 0.3126 - val_accuracy: 0.7635\n",
            "Epoch 894/1000\n",
            "10/10 [==============================] - 2s 188ms/step - loss: 0.0756 - accuracy: 1.0000 - val_loss: 0.3133 - val_accuracy: 0.7635\n",
            "Epoch 895/1000\n",
            "10/10 [==============================] - 2s 203ms/step - loss: 0.0922 - accuracy: 0.9863 - val_loss: 0.3136 - val_accuracy: 0.7635\n",
            "Epoch 896/1000\n",
            "10/10 [==============================] - 2s 197ms/step - loss: 0.0865 - accuracy: 0.9875 - val_loss: 0.3127 - val_accuracy: 0.7586\n",
            "Epoch 897/1000\n",
            "10/10 [==============================] - 2s 220ms/step - loss: 0.0912 - accuracy: 0.9750 - val_loss: 0.3120 - val_accuracy: 0.7685\n",
            "Epoch 898/1000\n",
            "10/10 [==============================] - 2s 190ms/step - loss: 0.0867 - accuracy: 0.9875 - val_loss: 0.3121 - val_accuracy: 0.7685\n",
            "Epoch 899/1000\n",
            "10/10 [==============================] - 2s 204ms/step - loss: 0.0930 - accuracy: 0.9875 - val_loss: 0.3124 - val_accuracy: 0.7685\n",
            "Epoch 900/1000\n",
            "10/10 [==============================] - 2s 197ms/step - loss: 0.0930 - accuracy: 0.9750 - val_loss: 0.3133 - val_accuracy: 0.7635\n",
            "Epoch 901/1000\n",
            "10/10 [==============================] - 2s 196ms/step - loss: 0.0883 - accuracy: 0.9726 - val_loss: 0.3129 - val_accuracy: 0.7586\n",
            "Epoch 902/1000\n",
            "10/10 [==============================] - 2s 195ms/step - loss: 0.0960 - accuracy: 0.9625 - val_loss: 0.3127 - val_accuracy: 0.7586\n",
            "Epoch 903/1000\n",
            "10/10 [==============================] - 2s 241ms/step - loss: 0.0936 - accuracy: 0.9875 - val_loss: 0.3126 - val_accuracy: 0.7635\n",
            "Epoch 904/1000\n",
            "10/10 [==============================] - 2s 190ms/step - loss: 0.0868 - accuracy: 0.9863 - val_loss: 0.3124 - val_accuracy: 0.7635\n",
            "Epoch 905/1000\n",
            "10/10 [==============================] - 2s 186ms/step - loss: 0.0849 - accuracy: 0.9726 - val_loss: 0.3121 - val_accuracy: 0.7685\n",
            "Epoch 906/1000\n",
            "10/10 [==============================] - 2s 202ms/step - loss: 0.0869 - accuracy: 0.9863 - val_loss: 0.3120 - val_accuracy: 0.7685\n",
            "Epoch 907/1000\n",
            "10/10 [==============================] - 2s 187ms/step - loss: 0.0780 - accuracy: 0.9750 - val_loss: 0.3119 - val_accuracy: 0.7685\n",
            "Epoch 908/1000\n",
            "10/10 [==============================] - 2s 188ms/step - loss: 0.0735 - accuracy: 1.0000 - val_loss: 0.3119 - val_accuracy: 0.7685\n",
            "Epoch 909/1000\n",
            "10/10 [==============================] - 2s 192ms/step - loss: 0.0852 - accuracy: 0.9875 - val_loss: 0.3119 - val_accuracy: 0.7685\n",
            "Epoch 910/1000\n",
            "10/10 [==============================] - 2s 210ms/step - loss: 0.1056 - accuracy: 0.9375 - val_loss: 0.3119 - val_accuracy: 0.7685\n",
            "Epoch 911/1000\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 0.0775 - accuracy: 0.9875 - val_loss: 0.3119 - val_accuracy: 0.7685\n",
            "Epoch 912/1000\n",
            "10/10 [==============================] - 2s 191ms/step - loss: 0.0914 - accuracy: 0.9750 - val_loss: 0.3118 - val_accuracy: 0.7685\n",
            "Epoch 913/1000\n",
            "10/10 [==============================] - 2s 200ms/step - loss: 0.0919 - accuracy: 1.0000 - val_loss: 0.3118 - val_accuracy: 0.7685\n",
            "Epoch 914/1000\n",
            "10/10 [==============================] - 2s 195ms/step - loss: 0.0913 - accuracy: 0.9625 - val_loss: 0.3118 - val_accuracy: 0.7685\n",
            "Epoch 915/1000\n",
            "10/10 [==============================] - 2s 204ms/step - loss: 0.0846 - accuracy: 0.9863 - val_loss: 0.3119 - val_accuracy: 0.7685\n",
            "Epoch 916/1000\n",
            "10/10 [==============================] - 2s 194ms/step - loss: 0.0881 - accuracy: 0.9750 - val_loss: 0.3119 - val_accuracy: 0.7685\n",
            "Epoch 917/1000\n",
            "10/10 [==============================] - 2s 189ms/step - loss: 0.0692 - accuracy: 1.0000 - val_loss: 0.3120 - val_accuracy: 0.7685\n",
            "Epoch 918/1000\n",
            "10/10 [==============================] - 2s 210ms/step - loss: 0.0847 - accuracy: 0.9875 - val_loss: 0.3120 - val_accuracy: 0.7685\n",
            "Epoch 919/1000\n",
            "10/10 [==============================] - 2s 191ms/step - loss: 0.0915 - accuracy: 1.0000 - val_loss: 0.3120 - val_accuracy: 0.7685\n",
            "Epoch 920/1000\n",
            "10/10 [==============================] - 2s 214ms/step - loss: 0.1014 - accuracy: 0.9750 - val_loss: 0.3119 - val_accuracy: 0.7685\n",
            "Epoch 921/1000\n",
            "10/10 [==============================] - 2s 204ms/step - loss: 0.0979 - accuracy: 0.9625 - val_loss: 0.3118 - val_accuracy: 0.7685\n",
            "Epoch 922/1000\n",
            "10/10 [==============================] - 2s 198ms/step - loss: 0.0815 - accuracy: 1.0000 - val_loss: 0.3118 - val_accuracy: 0.7685\n",
            "Epoch 923/1000\n",
            "10/10 [==============================] - 2s 204ms/step - loss: 0.1013 - accuracy: 0.9750 - val_loss: 0.3118 - val_accuracy: 0.7685\n",
            "Epoch 924/1000\n",
            "10/10 [==============================] - 2s 187ms/step - loss: 0.0842 - accuracy: 0.9726 - val_loss: 0.3118 - val_accuracy: 0.7685\n",
            "Epoch 925/1000\n",
            "10/10 [==============================] - 2s 196ms/step - loss: 0.1030 - accuracy: 0.9750 - val_loss: 0.3118 - val_accuracy: 0.7685\n",
            "Epoch 926/1000\n",
            "10/10 [==============================] - 2s 192ms/step - loss: 0.0843 - accuracy: 0.9875 - val_loss: 0.3118 - val_accuracy: 0.7685\n",
            "Epoch 927/1000\n",
            "10/10 [==============================] - 2s 198ms/step - loss: 0.0925 - accuracy: 0.9625 - val_loss: 0.3119 - val_accuracy: 0.7685\n",
            "Epoch 928/1000\n",
            "10/10 [==============================] - 2s 193ms/step - loss: 0.0951 - accuracy: 0.9625 - val_loss: 0.3118 - val_accuracy: 0.7685\n",
            "Epoch 929/1000\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 0.0979 - accuracy: 0.9625 - val_loss: 0.3117 - val_accuracy: 0.7685\n",
            "Epoch 930/1000\n",
            "10/10 [==============================] - 2s 208ms/step - loss: 0.0851 - accuracy: 0.9875 - val_loss: 0.3116 - val_accuracy: 0.7685\n",
            "Epoch 931/1000\n",
            "10/10 [==============================] - 2s 197ms/step - loss: 0.1014 - accuracy: 0.9750 - val_loss: 0.3115 - val_accuracy: 0.7685\n",
            "Epoch 932/1000\n",
            "10/10 [==============================] - 2s 192ms/step - loss: 0.0941 - accuracy: 0.9589 - val_loss: 0.3115 - val_accuracy: 0.7685\n",
            "Epoch 933/1000\n",
            "10/10 [==============================] - 2s 192ms/step - loss: 0.0913 - accuracy: 0.9875 - val_loss: 0.3115 - val_accuracy: 0.7685\n",
            "Epoch 934/1000\n",
            "10/10 [==============================] - 2s 192ms/step - loss: 0.0867 - accuracy: 1.0000 - val_loss: 0.3115 - val_accuracy: 0.7685\n",
            "Epoch 935/1000\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 0.0917 - accuracy: 1.0000 - val_loss: 0.3115 - val_accuracy: 0.7685\n",
            "Epoch 936/1000\n",
            "10/10 [==============================] - 2s 200ms/step - loss: 0.0788 - accuracy: 0.9875 - val_loss: 0.3116 - val_accuracy: 0.7685\n",
            "Epoch 937/1000\n",
            "10/10 [==============================] - 2s 194ms/step - loss: 0.0749 - accuracy: 1.0000 - val_loss: 0.3117 - val_accuracy: 0.7685\n",
            "Epoch 938/1000\n",
            "10/10 [==============================] - 2s 188ms/step - loss: 0.0926 - accuracy: 0.9875 - val_loss: 0.3117 - val_accuracy: 0.7685\n",
            "Epoch 939/1000\n",
            "10/10 [==============================] - 2s 194ms/step - loss: 0.1010 - accuracy: 0.9500 - val_loss: 0.3117 - val_accuracy: 0.7685\n",
            "Epoch 940/1000\n",
            "10/10 [==============================] - 2s 204ms/step - loss: 0.0827 - accuracy: 0.9875 - val_loss: 0.3117 - val_accuracy: 0.7685\n",
            "Epoch 941/1000\n",
            "10/10 [==============================] - 2s 204ms/step - loss: 0.0809 - accuracy: 0.9750 - val_loss: 0.3117 - val_accuracy: 0.7685\n",
            "Epoch 942/1000\n",
            "10/10 [==============================] - 2s 209ms/step - loss: 0.0800 - accuracy: 0.9875 - val_loss: 0.3117 - val_accuracy: 0.7685\n",
            "Epoch 943/1000\n",
            "10/10 [==============================] - 2s 196ms/step - loss: 0.0942 - accuracy: 0.9625 - val_loss: 0.3116 - val_accuracy: 0.7685\n",
            "Epoch 944/1000\n",
            "10/10 [==============================] - 2s 190ms/step - loss: 0.0816 - accuracy: 0.9875 - val_loss: 0.3117 - val_accuracy: 0.7685\n",
            "Epoch 945/1000\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 0.0885 - accuracy: 0.9863 - val_loss: 0.3117 - val_accuracy: 0.7685\n",
            "Epoch 946/1000\n",
            "10/10 [==============================] - 2s 204ms/step - loss: 0.0877 - accuracy: 0.9726 - val_loss: 0.3116 - val_accuracy: 0.7685\n",
            "Epoch 947/1000\n",
            "10/10 [==============================] - 2s 202ms/step - loss: 0.0995 - accuracy: 0.9500 - val_loss: 0.3116 - val_accuracy: 0.7685\n",
            "Epoch 948/1000\n",
            "10/10 [==============================] - 2s 194ms/step - loss: 0.0979 - accuracy: 0.9750 - val_loss: 0.3115 - val_accuracy: 0.7685\n",
            "Epoch 949/1000\n",
            "10/10 [==============================] - 2s 192ms/step - loss: 0.0847 - accuracy: 0.9875 - val_loss: 0.3114 - val_accuracy: 0.7685\n",
            "Epoch 950/1000\n",
            "10/10 [==============================] - 2s 203ms/step - loss: 0.1061 - accuracy: 0.9500 - val_loss: 0.3114 - val_accuracy: 0.7685\n",
            "Epoch 951/1000\n",
            "10/10 [==============================] - 2s 190ms/step - loss: 0.0866 - accuracy: 0.9750 - val_loss: 0.3114 - val_accuracy: 0.7685\n",
            "Epoch 952/1000\n",
            "10/10 [==============================] - 2s 195ms/step - loss: 0.0939 - accuracy: 0.9875 - val_loss: 0.3114 - val_accuracy: 0.7685\n",
            "Epoch 953/1000\n",
            "10/10 [==============================] - 2s 199ms/step - loss: 0.0938 - accuracy: 0.9750 - val_loss: 0.3113 - val_accuracy: 0.7685\n",
            "Epoch 954/1000\n",
            "10/10 [==============================] - 2s 188ms/step - loss: 0.1216 - accuracy: 0.9452 - val_loss: 0.3113 - val_accuracy: 0.7685\n",
            "Epoch 955/1000\n",
            "10/10 [==============================] - 2s 199ms/step - loss: 0.0832 - accuracy: 1.0000 - val_loss: 0.3113 - val_accuracy: 0.7685\n",
            "Epoch 956/1000\n",
            "10/10 [==============================] - 2s 191ms/step - loss: 0.0912 - accuracy: 0.9589 - val_loss: 0.3113 - val_accuracy: 0.7685\n",
            "Epoch 957/1000\n",
            "10/10 [==============================] - 2s 197ms/step - loss: 0.0961 - accuracy: 0.9750 - val_loss: 0.3115 - val_accuracy: 0.7685\n",
            "Epoch 958/1000\n",
            "10/10 [==============================] - 2s 195ms/step - loss: 0.0847 - accuracy: 0.9750 - val_loss: 0.3115 - val_accuracy: 0.7685\n",
            "Epoch 959/1000\n",
            "10/10 [==============================] - 2s 191ms/step - loss: 0.0878 - accuracy: 0.9875 - val_loss: 0.3116 - val_accuracy: 0.7685\n",
            "Epoch 960/1000\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 0.0962 - accuracy: 0.9625 - val_loss: 0.3117 - val_accuracy: 0.7685\n",
            "Epoch 961/1000\n",
            "10/10 [==============================] - 2s 198ms/step - loss: 0.0882 - accuracy: 0.9875 - val_loss: 0.3117 - val_accuracy: 0.7685\n",
            "Epoch 962/1000\n",
            "10/10 [==============================] - 2s 203ms/step - loss: 0.0850 - accuracy: 0.9875 - val_loss: 0.3118 - val_accuracy: 0.7685\n",
            "Epoch 963/1000\n",
            "10/10 [==============================] - 2s 187ms/step - loss: 0.1081 - accuracy: 0.9178 - val_loss: 0.3118 - val_accuracy: 0.7685\n",
            "Epoch 964/1000\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 0.0883 - accuracy: 0.9875 - val_loss: 0.3118 - val_accuracy: 0.7685\n",
            "Epoch 965/1000\n",
            "10/10 [==============================] - 2s 205ms/step - loss: 0.0847 - accuracy: 0.9750 - val_loss: 0.3118 - val_accuracy: 0.7685\n",
            "Epoch 966/1000\n",
            "10/10 [==============================] - 2s 199ms/step - loss: 0.0942 - accuracy: 0.9750 - val_loss: 0.3119 - val_accuracy: 0.7685\n",
            "Epoch 967/1000\n",
            "10/10 [==============================] - 2s 205ms/step - loss: 0.1052 - accuracy: 0.9625 - val_loss: 0.3119 - val_accuracy: 0.7685\n",
            "Epoch 968/1000\n",
            "10/10 [==============================] - 2s 200ms/step - loss: 0.0997 - accuracy: 0.9589 - val_loss: 0.3119 - val_accuracy: 0.7685\n",
            "Epoch 969/1000\n",
            "10/10 [==============================] - 2s 216ms/step - loss: 0.0937 - accuracy: 0.9750 - val_loss: 0.3117 - val_accuracy: 0.7685\n",
            "Epoch 970/1000\n",
            "10/10 [==============================] - 2s 196ms/step - loss: 0.0853 - accuracy: 1.0000 - val_loss: 0.3116 - val_accuracy: 0.7685\n",
            "Epoch 971/1000\n",
            "10/10 [==============================] - 2s 190ms/step - loss: 0.0884 - accuracy: 0.9875 - val_loss: 0.3115 - val_accuracy: 0.7685\n",
            "Epoch 972/1000\n",
            "10/10 [==============================] - 2s 196ms/step - loss: 0.0898 - accuracy: 0.9750 - val_loss: 0.3116 - val_accuracy: 0.7685\n",
            "Epoch 973/1000\n",
            "10/10 [==============================] - 2s 193ms/step - loss: 0.1016 - accuracy: 0.9625 - val_loss: 0.3116 - val_accuracy: 0.7685\n",
            "Epoch 974/1000\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 0.0981 - accuracy: 0.9726 - val_loss: 0.3115 - val_accuracy: 0.7685\n",
            "Epoch 975/1000\n",
            "10/10 [==============================] - 2s 203ms/step - loss: 0.0781 - accuracy: 1.0000 - val_loss: 0.3114 - val_accuracy: 0.7685\n",
            "Epoch 976/1000\n",
            "10/10 [==============================] - 2s 190ms/step - loss: 0.0907 - accuracy: 0.9863 - val_loss: 0.3113 - val_accuracy: 0.7685\n",
            "Epoch 977/1000\n",
            "10/10 [==============================] - 2s 194ms/step - loss: 0.0977 - accuracy: 0.9726 - val_loss: 0.3111 - val_accuracy: 0.7685\n",
            "Epoch 978/1000\n",
            "10/10 [==============================] - 2s 195ms/step - loss: 0.0779 - accuracy: 1.0000 - val_loss: 0.3110 - val_accuracy: 0.7685\n",
            "Epoch 979/1000\n",
            "10/10 [==============================] - 2s 198ms/step - loss: 0.0795 - accuracy: 0.9875 - val_loss: 0.3109 - val_accuracy: 0.7685\n",
            "Epoch 980/1000\n",
            "10/10 [==============================] - 2s 203ms/step - loss: 0.0927 - accuracy: 0.9589 - val_loss: 0.3109 - val_accuracy: 0.7685\n",
            "Epoch 981/1000\n",
            "10/10 [==============================] - 2s 188ms/step - loss: 0.0911 - accuracy: 0.9750 - val_loss: 0.3110 - val_accuracy: 0.7685\n",
            "Epoch 982/1000\n",
            "10/10 [==============================] - 2s 189ms/step - loss: 0.0770 - accuracy: 1.0000 - val_loss: 0.3111 - val_accuracy: 0.7685\n",
            "Epoch 983/1000\n",
            "10/10 [==============================] - 2s 196ms/step - loss: 0.0836 - accuracy: 0.9875 - val_loss: 0.3111 - val_accuracy: 0.7685\n",
            "Epoch 984/1000\n",
            "10/10 [==============================] - 2s 189ms/step - loss: 0.0848 - accuracy: 0.9875 - val_loss: 0.3110 - val_accuracy: 0.7685\n",
            "Epoch 985/1000\n",
            "10/10 [==============================] - 2s 192ms/step - loss: 0.0908 - accuracy: 1.0000 - val_loss: 0.3110 - val_accuracy: 0.7685\n",
            "Epoch 986/1000\n",
            "10/10 [==============================] - 2s 207ms/step - loss: 0.0824 - accuracy: 1.0000 - val_loss: 0.3108 - val_accuracy: 0.7685\n",
            "Epoch 987/1000\n",
            "10/10 [==============================] - 2s 197ms/step - loss: 0.0913 - accuracy: 0.9726 - val_loss: 0.3108 - val_accuracy: 0.7685\n",
            "Epoch 988/1000\n",
            "10/10 [==============================] - 2s 204ms/step - loss: 0.0818 - accuracy: 0.9875 - val_loss: 0.3110 - val_accuracy: 0.7685\n",
            "Epoch 989/1000\n",
            "10/10 [==============================] - 2s 194ms/step - loss: 0.1100 - accuracy: 0.9750 - val_loss: 0.3111 - val_accuracy: 0.7685\n",
            "Epoch 990/1000\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 0.0713 - accuracy: 1.0000 - val_loss: 0.3113 - val_accuracy: 0.7685\n",
            "Epoch 991/1000\n",
            "10/10 [==============================] - 2s 205ms/step - loss: 0.1111 - accuracy: 0.9625 - val_loss: 0.3114 - val_accuracy: 0.7685\n",
            "Epoch 992/1000\n",
            "10/10 [==============================] - 2s 192ms/step - loss: 0.0754 - accuracy: 0.9875 - val_loss: 0.3115 - val_accuracy: 0.7685\n",
            "Epoch 993/1000\n",
            "10/10 [==============================] - 2s 191ms/step - loss: 0.0869 - accuracy: 0.9875 - val_loss: 0.3115 - val_accuracy: 0.7685\n",
            "Epoch 994/1000\n",
            "10/10 [==============================] - 2s 200ms/step - loss: 0.1000 - accuracy: 0.9726 - val_loss: 0.3115 - val_accuracy: 0.7685\n",
            "Epoch 995/1000\n",
            "10/10 [==============================] - 2s 199ms/step - loss: 0.0858 - accuracy: 0.9875 - val_loss: 0.3117 - val_accuracy: 0.7685\n",
            "Epoch 996/1000\n",
            "10/10 [==============================] - 2s 199ms/step - loss: 0.0898 - accuracy: 0.9726 - val_loss: 0.3117 - val_accuracy: 0.7685\n",
            "Epoch 997/1000\n",
            "10/10 [==============================] - 2s 194ms/step - loss: 0.0906 - accuracy: 0.9750 - val_loss: 0.3119 - val_accuracy: 0.7685\n",
            "Epoch 998/1000\n",
            "10/10 [==============================] - 2s 194ms/step - loss: 0.0793 - accuracy: 0.9875 - val_loss: 0.3120 - val_accuracy: 0.7685\n",
            "Epoch 999/1000\n",
            "10/10 [==============================] - 2s 195ms/step - loss: 0.0807 - accuracy: 1.0000 - val_loss: 0.3121 - val_accuracy: 0.7685\n",
            "Epoch 1000/1000\n",
            "10/10 [==============================] - 2s 196ms/step - loss: 0.0909 - accuracy: 0.9625 - val_loss: 0.3122 - val_accuracy: 0.7635\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8gKiHqGul8e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "7ae52e4a-7d39-4c48-a188-a38ac0bd52b1"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"my_bi_t_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                multiple                  2049      \n",
            "_________________________________________________________________\n",
            "keras_layer (KerasLayer)     multiple                  23500352  \n",
            "=================================================================\n",
            "Total params: 23,502,401\n",
            "Trainable params: 2,049\n",
            "Non-trainable params: 23,500,352\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YO185nPrF7JE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "3a450506-e05e-4442-90d5-da37c4389828"
      },
      "source": [
        "model.evaluate(test_generator_192)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "26/26 [==============================] - 1s 53ms/step - loss: 0.3122 - accuracy: 0.7635\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.31219911575317383, 0.7635468244552612]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2liaSegQGGgg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predict = model.predict(test_generator_192)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHru6O3uGg5X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import roc_auc_score, roc_curve"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylQBY7oYGjHL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_roc_curve(labels, predicted_vals, generator):\n",
        "    auc_roc_vals = []\n",
        "    for i in range(len(labels)):\n",
        "        try:\n",
        "            gt = generator.labels[:, i]\n",
        "            pred = predicted_vals[:, i]\n",
        "            auc_roc = roc_auc_score(gt, pred)\n",
        "            auc_roc_vals.append(auc_roc)\n",
        "            fpr_rf, tpr_rf, _ = roc_curve(gt, pred)\n",
        "            plt.figure(1, figsize=(10, 10))\n",
        "            plt.plot([0, 1], [0, 1], 'k--')\n",
        "            plt.plot(fpr_rf, tpr_rf,\n",
        "                     label=labels[i] + \" (\" + str(round(auc_roc, 3)) + \")\")\n",
        "            plt.xlabel('False positive rate')\n",
        "            plt.ylabel('True positive rate')\n",
        "            plt.title('ROC curve')\n",
        "            plt.legend(loc='best')\n",
        "        except:\n",
        "            print(\n",
        "                f\"Error in generating ROC curve for {labels[i]}. \"\n",
        "                f\"Dataset lacks enough examples.\"\n",
        "            )\n",
        "    plt.show()\n",
        "    return auc_roc_vals"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bw-bNW45Gzli",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 621
        },
        "outputId": "f5aa3e19-8d7e-45af-b12f-5bb9f8809372"
      },
      "source": [
        "auc_rocs = get_roc_curve(labels, predict, test_generator_192)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvZE8yefG6OK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "677e1691-8089-4640-f044-ce40382640f5"
      },
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.ylabel(\"loss\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.title(\"Training- Val loss Curve\")\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxzcYkTiHLRz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "44a8d95c-c051-413d-f801-43ebccef6cd1"
      },
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.title(\"Training- Val accuracy Curve\")\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NeYEcLAiHVpH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from sklearn.metrics import roc_auc_score, roc_curve\n",
        "from tensorflow.compat.v1.logging import INFO, set_verbosity"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYySgYDNHggw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_mean_std_per_batch(image_path, df, H=200, W=200):\n",
        "    sample_data = []\n",
        "    for idx, img in enumerate(df.sample(100)[\"Source\"].values):\n",
        "        # path = image_dir + img\n",
        "        sample_data.append(\n",
        "            np.array(image.load_img(image_path, target_size=(H, W))))\n",
        "\n",
        "    mean = np.mean(sample_data[0])\n",
        "    std = np.std(sample_data[0])\n",
        "    return mean, std\n",
        "def load_image(img, image_dir, df, preprocess=True, H=200, W=200):\n",
        "    \"\"\"Load and preprocess image.\"\"\"\n",
        "    img_path = image_dir + img\n",
        "    mean, std = get_mean_std_per_batch(img_path, df, H=H, W=W)\n",
        "    x = image.load_img(img_path, target_size=(H, W))\n",
        "    if preprocess:\n",
        "        x -= mean\n",
        "        x /= std\n",
        "        x = np.expand_dims(x, axis=0)\n",
        "    return x\n",
        "\n",
        "def grad_cam(input_model, image, cls, layer_name, H=200, W=200):\n",
        "    \"\"\"GradCAM method for visualizing input saliency.\"\"\"\n",
        "    y_c = input_model.output[0, cls]\n",
        "    conv_output = input_model.get_layer(layer_name).output\n",
        "    grads = K.gradients(y_c, conv_output)[0]\n",
        "\n",
        "    gradient_function = K.function([input_model.input], [conv_output, grads])\n",
        "\n",
        "    output, grads_val = gradient_function([image])\n",
        "    output, grads_val = output[0, :], grads_val[0, :, :, :]\n",
        "\n",
        "    weights = np.mean(grads_val, axis=(0, 1))\n",
        "    cam = np.dot(output, weights)\n",
        "\n",
        "    # Process CAM\n",
        "    cam = cv2.resize(cam, (W, H), cv2.INTER_LINEAR)\n",
        "    cam = np.maximum(cam, 0)\n",
        "    cam = cam / cam.max()\n",
        "    return cam\n",
        "\n",
        "\n",
        "def compute_gradcam(model, img, image_dir, df, labels, selected_labels,\n",
        "                    layer_name='conv5_block3_2_bn'):\n",
        "    preprocessed_input = load_image(img, image_dir, df)\n",
        "    predictions = model.predict(preprocessed_input)\n",
        "\n",
        "    print(\"Loading original image\")\n",
        "    plt.figure(figsize=(15, 10))\n",
        "    plt.subplot(151)\n",
        "    plt.title(\"Original\")\n",
        "    plt.axis('off')\n",
        "    plt.imshow(load_image(img, image_dir, df, preprocess=False), cmap='gray')\n",
        "\n",
        "    j = 1\n",
        "    for i in range(len(labels)):\n",
        "        if labels[i] in selected_labels:\n",
        "            print(f\"Generating gradcam for class {labels[i]}\")\n",
        "            gradcam = grad_cam(model, preprocessed_input, i, layer_name)\n",
        "            plt.subplot(151 + j)\n",
        "            plt.title(f\"{labels[i]}: p={predictions[0][i]:.3f}\")\n",
        "            plt.axis('off')\n",
        "            plt.imshow(load_image(img, image_dir, df, preprocess=False),\n",
        "                       cmap='gray')\n",
        "            plt.imshow(gradcam, cmap='jet', alpha=min(0.5, predictions[0][i]))\n",
        "            j += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-g4h0t9HpaB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels_to_show = np.take(labels, np.argsort(auc_rocs)[::-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SfXl_ycHueQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_labes = ['Covid']\n",
        "pred_labels = ['Covid_pred']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLzSUCq3H0KA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def true_positives(y, pred, th=0.4):\n",
        "    \"\"\"\n",
        "    Count true positives.\n",
        "\n",
        "    Args:\n",
        "        y (np.array): ground truth, size (n_examples)\n",
        "        pred (np.array): model output, size (n_examples)\n",
        "        th (float): cutoff value for positive prediction from model\n",
        "    Returns:\n",
        "        TP (int): true positives\n",
        "    \"\"\"\n",
        "    TP = 0\n",
        "    \n",
        "    # get thresholded predictions\n",
        "    thresholded_preds = pred >= th\n",
        "\n",
        "    # compute TP\n",
        "    TP = np.sum((y == 1) & (thresholded_preds == 1))\n",
        "    \n",
        "    return TP\n",
        "\n",
        "def true_negatives(y, pred, th=0.4):\n",
        "    \"\"\"\n",
        "    Count true negatives.\n",
        "\n",
        "    Args:\n",
        "        y (np.array): ground truth, size (n_examples)\n",
        "        pred (np.array): model output, size (n_examples)\n",
        "        th (float): cutoff value for positive prediction from model\n",
        "    Returns:\n",
        "        TN (int): true negatives\n",
        "    \"\"\"\n",
        "    TN = 0\n",
        "    \n",
        "    # get thresholded predictions\n",
        "    thresholded_preds = pred >= th\n",
        "\n",
        "    ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\n",
        "    \n",
        "    # compute TN\n",
        "    TN =  np.sum((y == 0) & (thresholded_preds == 0))\n",
        "    \n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    return TN\n",
        "\n",
        "def false_positives(y, pred, th=0.4):\n",
        "    \"\"\"\n",
        "    Count false positives.\n",
        "\n",
        "    Args:\n",
        "        y (np.array): ground truth, size (n_examples)\n",
        "        pred (np.array): model output, size (n_examples)\n",
        "        th (float): cutoff value for positive prediction from model\n",
        "    Returns:\n",
        "        FP (int): false positives\n",
        "    \"\"\"\n",
        "    FP = 0\n",
        "    \n",
        "    # get thresholded predictions\n",
        "    thresholded_preds = pred >= th\n",
        "    \n",
        "    ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\n",
        "\n",
        "    # compute FP\n",
        "    FP =  np.sum((y == 0) & (thresholded_preds == 1))\n",
        "    \n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    return FP\n",
        "\n",
        "def false_negatives(y, pred, th=0.4):\n",
        "    \"\"\"\n",
        "    Count false positives.\n",
        "\n",
        "    Args:\n",
        "        y (np.array): ground truth, size (n_examples)\n",
        "        pred (np.array): model output, size (n_examples)\n",
        "        th (float): cutoff value for positive prediction from model\n",
        "    Returns:\n",
        "        FN (int): false negatives\n",
        "    \"\"\"\n",
        "    FN = 0\n",
        "    \n",
        "    # get thresholded predictions\n",
        "    thresholded_preds = pred >= th\n",
        "\n",
        "    ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\n",
        "    \n",
        "    # compute FN\n",
        "    FN =  np.sum((y == 1) & (thresholded_preds == 0))\n",
        "    \n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    return FN"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WymB5oIH-sl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import (\n",
        "    average_precision_score,\n",
        "    precision_recall_curve,\n",
        "    roc_auc_score,\n",
        "    roc_curve,\n",
        ")\n",
        "\n",
        "\n",
        "def get_true_pos(y, pred, th=0.4):\n",
        "    pred_t = (pred > th)\n",
        "    return np.sum((pred_t == True) & (y == 1))\n",
        "\n",
        "\n",
        "def get_true_neg(y, pred, th=0.4):\n",
        "    pred_t = (pred > th)\n",
        "    return np.sum((pred_t == False) & (y == 0))\n",
        "\n",
        "\n",
        "def get_false_neg(y, pred, th=0.4):\n",
        "    pred_t = (pred > th)\n",
        "    return np.sum((pred_t == False) & (y == 1))\n",
        "\n",
        "\n",
        "def get_false_pos(y, pred, th=0.4):\n",
        "    pred_t = (pred > th)\n",
        "    return np.sum((pred_t == True) & (y == 0))\n",
        "\n",
        "\n",
        "def get_performance_metrics(y, pred, class_labels, tp=get_true_pos,\n",
        "                            tn=get_true_neg, fp=get_false_pos,\n",
        "                            fn=get_false_neg,\n",
        "                            acc=None, prevalence=None, spec=None,\n",
        "                            sens=None, ppv=None, npv=None, auc=None, f1=None,\n",
        "                            thresholds=[]):\n",
        "    if len(thresholds) != len(class_labels):\n",
        "        thresholds = [.5] * len(class_labels)\n",
        "\n",
        "    columns = [\"\", \"TP\", \"TN\", \"FP\", \"FN\", \"Accuracy\", \"Prevalence\",\n",
        "               \"Sensitivity\",\n",
        "               \"Specificity\", \"PPV\", \"NPV\", \"AUC\", \"F1\", \"Threshold\"]\n",
        "    df = pd.DataFrame(columns=columns)\n",
        "    for i in range(len(class_labels)):\n",
        "        df.loc[i] = [\"\"] + [0] * (len(columns) - 1)\n",
        "        df.loc[i][0] = class_labels[i]\n",
        "        df.loc[i][1] = round(tp(y[:, i], pred[:, i]),\n",
        "                             3) if tp != None else \"Not Defined\"\n",
        "        df.loc[i][2] = round(tn(y[:, i], pred[:, i]),\n",
        "                             3) if tn != None else \"Not Defined\"\n",
        "        df.loc[i][3] = round(fp(y[:, i], pred[:, i]),\n",
        "                             3) if fp != None else \"Not Defined\"\n",
        "        df.loc[i][4] = round(fn(y[:, i], pred[:, i]),\n",
        "                             3) if fn != None else \"Not Defined\"\n",
        "        df.loc[i][5] = round(acc(y[:, i], pred[:, i], thresholds[i]),\n",
        "                             3) if acc != None else \"Not Defined\"\n",
        "        df.loc[i][6] = round(prevalence(y[:, i]),\n",
        "                             3) if prevalence != None else \"Not Defined\"\n",
        "        df.loc[i][7] = round(sens(y[:, i], pred[:, i], thresholds[i]),\n",
        "                             3) if sens != None else \"Not Defined\"\n",
        "        df.loc[i][8] = round(spec(y[:, i], pred[:, i], thresholds[i]),\n",
        "                             3) if spec != None else \"Not Defined\"\n",
        "        df.loc[i][9] = round(ppv(y[:, i], pred[:, i], thresholds[i]),\n",
        "                             3) if ppv != None else \"Not Defined\"\n",
        "        df.loc[i][10] = round(npv(y[:, i], pred[:, i], thresholds[i]),\n",
        "                              3) if npv != None else \"Not Defined\"\n",
        "        df.loc[i][11] = round(auc(y[:, i], pred[:, i]),\n",
        "                              3) if auc != None else \"Not Defined\"\n",
        "        df.loc[i][12] = round(f1(y[:, i], pred[:, i] > thresholds[i]),\n",
        "                              3) if f1 != None else \"Not Defined\"\n",
        "        df.loc[i][13] = round(thresholds[i], 3)\n",
        "\n",
        "    df = df.set_index(\"\")\n",
        "    return df\n",
        "\n",
        "\n",
        "def print_confidence_intervals(class_labels, statistics):\n",
        "    df = pd.DataFrame(columns=[\"Mean AUC (CI 5%-95%)\"])\n",
        "    for i in range(len(class_labels)):\n",
        "        mean = statistics.mean(axis=1)[i]\n",
        "        max_ = np.quantile(statistics, .95, axis=1)[i]\n",
        "        min_ = np.quantile(statistics, .05, axis=1)[i]\n",
        "        df.loc[class_labels[i]] = [\"%.2f (%.2f-%.2f)\" % (mean, min_, max_)]\n",
        "    return df\n",
        "\n",
        "\n",
        "def get_curve(gt, pred, target_names, curve='roc'):\n",
        "    for i in range(len(target_names)):\n",
        "        if curve == 'roc':\n",
        "            curve_function = roc_curve\n",
        "            auc_roc = roc_auc_score(gt[:, i], pred[:, i])\n",
        "            label = target_names[i] + \" AUC: %.3f \" % auc_roc\n",
        "            xlabel = \"False positive rate\"\n",
        "            ylabel = \"True positive rate\"\n",
        "            a, b, _ = curve_function(gt[:, i], pred[:, i])\n",
        "            plt.figure(1, figsize=(7, 7))\n",
        "            plt.plot([0, 1], [0, 1], 'k--')\n",
        "            plt.plot(a, b, label=label)\n",
        "            plt.xlabel(xlabel)\n",
        "            plt.ylabel(ylabel)\n",
        "\n",
        "            plt.legend(loc='upper center', bbox_to_anchor=(1.3, 1),\n",
        "                       fancybox=True, ncol=1)\n",
        "        elif curve == 'prc':\n",
        "            precision, recall, _ = precision_recall_curve(gt[:, i], pred[:, i])\n",
        "            average_precision = average_precision_score(gt[:, i], pred[:, i])\n",
        "            label = target_names[i] + \" Avg.: %.3f \" % average_precision\n",
        "            plt.figure(1, figsize=(7, 7))\n",
        "            plt.step(recall, precision, where='post', label=label)\n",
        "            plt.xlabel('Recall')\n",
        "            plt.ylabel('Precision')\n",
        "            plt.ylim([0.0, 1.05])\n",
        "            plt.xlim([0.0, 1.0])\n",
        "            plt.legend(loc='upper center', bbox_to_anchor=(1.3, 1),\n",
        "                       fancybox=True, ncol=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6750ot6IBI7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df1 = pd.DataFrame(test_generator_192.labels, columns= ['Covid'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBqVOhPaIH0O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df2 = pd.DataFrame(predict,columns=['Covid_pred'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MiFVjItgIN5Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = [df1 , df2]\n",
        "\n",
        "result = pd.concat(df,axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6OiqFjcIQV-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = result[class_labes].values\n",
        "pred = result[pred_labels].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fuNElFWISit",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "a072252b-128b-4acf-dc35-868274900519"
      },
      "source": [
        "result[np.concatenate([class_labes, pred_labels])].head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Covid</th>\n",
              "      <th>Covid_pred</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0.993587</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.018506</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0.985685</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0.261371</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0.970502</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Covid  Covid_pred\n",
              "0      1    0.993587\n",
              "1      1    0.018506\n",
              "2      1    0.985685\n",
              "3      1    0.261371\n",
              "4      1    0.970502"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Qp_iTeCIVbG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "a6277db0-79e2-4ec1-df7a-6ee0bb4b8dca"
      },
      "source": [
        "get_performance_metrics(y, pred, class_labes)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TP</th>\n",
              "      <th>TN</th>\n",
              "      <th>FP</th>\n",
              "      <th>FN</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Prevalence</th>\n",
              "      <th>Sensitivity</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>PPV</th>\n",
              "      <th>NPV</th>\n",
              "      <th>AUC</th>\n",
              "      <th>F1</th>\n",
              "      <th>Threshold</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Covid</th>\n",
              "      <td>76</td>\n",
              "      <td>81</td>\n",
              "      <td>24</td>\n",
              "      <td>22</td>\n",
              "      <td>Not Defined</td>\n",
              "      <td>Not Defined</td>\n",
              "      <td>Not Defined</td>\n",
              "      <td>Not Defined</td>\n",
              "      <td>Not Defined</td>\n",
              "      <td>Not Defined</td>\n",
              "      <td>Not Defined</td>\n",
              "      <td>Not Defined</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       TP  TN  FP  FN  ...          NPV          AUC           F1 Threshold\n",
              "                       ...                                                 \n",
              "Covid  76  81  24  22  ...  Not Defined  Not Defined  Not Defined       0.5\n",
              "\n",
              "[1 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tm359TgxIXie",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_accuracy(y, pred, th=0.5):\n",
        "    \"\"\"\n",
        "    Compute accuracy of predictions at threshold.\n",
        "\n",
        "    Args:\n",
        "        y (np.array): ground truth, size (n_examples)\n",
        "        pred (np.array): model output, size (n_examples)\n",
        "        th (float): cutoff value for positive prediction from model\n",
        "    Returns:\n",
        "        accuracy (float): accuracy of predictions at threshold\n",
        "    \"\"\"\n",
        "    accuracy = 0.0\n",
        "    \n",
        "    ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\n",
        "    \n",
        "    # get TP, FP, TN, FN using our previously defined functions\n",
        "    TP = true_positives(y,pred,th=0.5)\n",
        "    FP = false_positives(y,pred, th=0.5)\n",
        "    TN = true_negatives(y, pred, th=0.5)\n",
        "    FN = false_negatives(y, pred, th=0.5)\n",
        "\n",
        "    # Compute accuracy using TP, FP, TN, FN\n",
        "    accuracy = (TP+TN)/(TP+TN+FP+FN)\n",
        "    \n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    return accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anXxmiV-Ia7W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "762f89a8-bc4a-4923-b1fc-8a0f8202bf66"
      },
      "source": [
        "get_performance_metrics(y, pred, class_labes, acc=get_accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TP</th>\n",
              "      <th>TN</th>\n",
              "      <th>FP</th>\n",
              "      <th>FN</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Prevalence</th>\n",
              "      <th>Sensitivity</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>PPV</th>\n",
              "      <th>NPV</th>\n",
              "      <th>AUC</th>\n",
              "      <th>F1</th>\n",
              "      <th>Threshold</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Covid</th>\n",
              "      <td>76</td>\n",
              "      <td>81</td>\n",
              "      <td>24</td>\n",
              "      <td>22</td>\n",
              "      <td>0.764</td>\n",
              "      <td>Not Defined</td>\n",
              "      <td>Not Defined</td>\n",
              "      <td>Not Defined</td>\n",
              "      <td>Not Defined</td>\n",
              "      <td>Not Defined</td>\n",
              "      <td>Not Defined</td>\n",
              "      <td>Not Defined</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       TP  TN  FP  FN  ...          NPV          AUC           F1 Threshold\n",
              "                       ...                                                 \n",
              "Covid  76  81  24  22  ...  Not Defined  Not Defined  Not Defined       0.5\n",
              "\n",
              "[1 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqAtOPrcIdgg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "702ca9c7-55a8-4a50-8056-9fa39538e106"
      },
      "source": [
        "get_accuracy(result[\"Covid\"].values, np.zeros(len(result)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5172413793103449"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_LQZQDKIiNv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_prevalence(y):\n",
        "    \"\"\"\n",
        "    Compute accuracy of predictions at threshold.\n",
        "\n",
        "    Args:\n",
        "        y (np.array): ground truth, size (n_examples)\n",
        "    Returns:\n",
        "        prevalence (float): prevalence of positive cases\n",
        "    \"\"\"\n",
        "    prevalence = 0.0\n",
        "    \n",
        "    ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\n",
        "    \n",
        "    prevalence = np.mean(y)\n",
        "    \n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    return prevalence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQOmfL7GIk2O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_sensitivity(y, pred, th=0.5):\n",
        "    \"\"\"\n",
        "    Compute sensitivity of predictions at threshold.\n",
        "\n",
        "    Args:\n",
        "        y (np.array): ground truth, size (n_examples)\n",
        "        pred (np.array): model output, size (n_examples)\n",
        "        th (float): cutoff value for positive prediction from model\n",
        "    Returns:\n",
        "        sensitivity (float): probability that our test outputs positive given that the case is actually positive\n",
        "    \"\"\"\n",
        "    sensitivity = 0.0\n",
        "    \n",
        "    ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\n",
        "    \n",
        "    # get TP and FN using our previously defined functions\n",
        "    TP = true_positives(y,pred, th =0.5)\n",
        "    FN = false_negatives(y,pred, th=0.5)\n",
        "\n",
        "    # use TP and FN to compute sensitivity\n",
        "    sensitivity = TP / (TP+FN)\n",
        "    \n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    return sensitivity\n",
        "\n",
        "def get_specificity(y, pred, th=0.5):\n",
        "    \"\"\"\n",
        "    Compute specificity of predictions at threshold.\n",
        "\n",
        "    Args:\n",
        "        y (np.array): ground truth, size (n_examples)\n",
        "        pred (np.array): model output, size (n_examples)\n",
        "        th (float): cutoff value for positive prediction from model\n",
        "    Returns:\n",
        "        specificity (float): probability that the test outputs negative given that the case is actually negative\n",
        "    \"\"\"\n",
        "    specificity = 0.0\n",
        "    \n",
        "    ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\n",
        "    \n",
        "    # get TN and FP using our previously defined functions\n",
        "    TN = true_negatives(y,pred,th=0.5)\n",
        "    FP = false_positives(y,pred, th=0.5)\n",
        "    \n",
        "    # use TN and FP to compute specificity \n",
        "    specificity = TN / (TN+FP)\n",
        "    \n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    return specificity"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kcc25NN0IoKO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# UNQ_C5 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\n",
        "def get_ppv(y, pred, th=0.5):\n",
        "    \"\"\"\n",
        "    Compute PPV of predictions at threshold.\n",
        "\n",
        "    Args:\n",
        "        y (np.array): ground truth, size (n_examples)\n",
        "        pred (np.array): model output, size (n_examples)\n",
        "        th (float): cutoff value for positive prediction from model\n",
        "    Returns:\n",
        "        PPV (float): positive predictive value of predictions at threshold\n",
        "    \"\"\"\n",
        "    PPV = 0.0\n",
        "    \n",
        "    ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\n",
        "    \n",
        "    # get TP and FP using our previously defined functions\n",
        "    TP = true_positives(y,pred,th=0.5)\n",
        "    FP = false_positives(y,pred, th =0.5)\n",
        "\n",
        "    # use TP and FP to compute PPV\n",
        "    PPV = TP / (TP+FP)\n",
        "    \n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    return PPV\n",
        "\n",
        "def get_npv(y, pred, th=0.5):\n",
        "    \"\"\"\n",
        "    Compute NPV of predictions at threshold.\n",
        "\n",
        "    Args:\n",
        "        y (np.array): ground truth, size (n_examples)\n",
        "        pred (np.array): model output, size (n_examples)\n",
        "        th (float): cutoff value for positive prediction from model\n",
        "    Returns:\n",
        "        NPV (float): negative predictive value of predictions at threshold\n",
        "    \"\"\"\n",
        "    NPV = 0.0\n",
        "    \n",
        "    ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\n",
        "    \n",
        "    # get TN and FN using our previously defined functions\n",
        "    TN = true_negatives(y,pred,th=0.5)\n",
        "    FN = false_negatives(y,pred,th=0.5)\n",
        "\n",
        "    # use TN and FN to compute NPV\n",
        "    NPV = TN / (FN+TN)\n",
        "    \n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    return NPV"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJS0KTCYIrqu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "f07e3d70-1a45-4840-a37e-97cabd56d9f8"
      },
      "source": [
        "get_curve(y, pred, class_labes)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAm4AAAGpCAYAAAA0rbqCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nOzdd3hUZf7+8fuThCohiLQIBFBATFgLsIhlKaEXAQWk2FBELLAiLIi9fd1FwY4uxRVRRNrSRJAWITZAkKKCKCIgTSlSQk3I8/sjYX8xEhggM2fK+3VducicOTNze8Bw8zzPOceccwIAAEDwi/I6AAAAAHxDcQMAAAgRFDcAAIAQQXEDAAAIERQ3AACAEBHjdYAzVapUKVe5cmWvYwAAgsjy5ct3OedKe50D8LeQK26VK1fWsmXLvI4BAAgiZrbJ6wxAIDBVCgAAECIobgAAACGC4gYAABAiQm6NGwAAkWL58uVlYmJi3pJUUwy2RIJMSd9mZGTcVbt27d9OtgPFDQCAIBUTE/NWuXLlLi1duvTvUVFR3Fw8zGVmZtrOnTsTd+zY8Zaktifbh/YOAEDwqlm6dOn9lLbIEBUV5UqXLr1PWSOsJ98ngHkAAMCZiaK0RZbs3+88+xnFDQAAIERQ3AAAQJ42b94c06ZNm4sqVqxYMykp6dIGDRpUXb16daEzfZ/U1NSi3bt3r3iy58qXL/+X7du3n3Td/RdffFHEzGpPnjy5+Ilt69atK1itWrWknPv169fvwieeeKLsicdPPPFE2SpVqiTVqFEjsWbNmpcOGzbsglPly8zMVPfu3SsmJCTUrF69euJnn31W9GT7jRgxomT16tUTq1evnvi3v/2tWu7cTz75ZFkzq31i++7du6OTk5OrXnLJJYlVq1ZNevXVV0+Z43QobgAA4KQyMzPVtm3bqvXr1z/wyy+/fPvdd9+tHTx48NZt27YVONP3ql+//qF33nnnlzN93XvvvVeyVq1aaePGjSvp62teeOGF0ikpKcWXL1++9vvvv1+Tmpq6zrlTzzhPmjQpbsOGDYU3btz47b///e9N9913X0LufdLT0/Xwww9XXLRo0Q8//PDDmqSkpMNDhgwpc+L59evXF1iwYEHx+Pj4Yye2DRkypPQll1xyeN26dWtSU1PXPfHEExWPHDlivv635EZxAwAAJzVz5szYmJgYN3DgwJ0ntl199dWHW7RokZaZmalevXpVqFatWlL16tUTR40adb4ktWnT5qLx48fHndi/Q4cOlUePHn3+zJkzYxs1alRVknbs2BF97bXXVqtatWpS586dK+VVqjIzM/Xhhx+WfPfddzd+9tlnxQ8dOuRT4Xn55ZfLjRw5clPJkiUzJalkyZKZffr02X2q10yfPr3EzTffvDsqKkqNGzc+uH///phNmzb9oaBmZmaac04HDhyIyszM1P79+6MuvPDC/5W03r17VxwyZMgWs/8f08x04MCB6BP7x8XFZRQoUOCs1y1yORAAAELAgMmrKv6w48BJp+/OVvVysYeGdLw8z1Gw1atXF7n88ssPney5d999t8Q333xTZO3atd9t3749pm7dupc2a9Ys7aabbtozceLE87t06bLvyJEj9vnnnxcfM2bMpoULFxY78dpBgwZdePXVV6cNHTp0+/jx4+MmTpxY6mSfMX/+/PMqVqx4NCkp6ehVV111YOLEiXHdu3ffe6r/pj179kQdPHgwOjEx8djJnu/bt++Ff/3rXw/efPPN+3Ju3759e4HKlSv/7zXx8fHHNm3aVKBSpUrpJ7YVKlTIvfTSS5tr1aqVVKRIkeOVKlU6+u67726WpLFjx5aIj49Pv/rqqw/nfN+BAwf+1qJFi6ply5a97ODBg9Fvv/32hujo6FP9J5yS30bczOxtM/vNzL7N43kzs9fMbL2ZrTazWv7KAgAA8tenn34ae9NNN+2JiYlRxYoVM6666qq0zz77rGjHjh33ffnll7GHDx+2yZMnx9WtW/dAsWLF/jDCtHjx4tg777xztyR16dJlX/HixY+f7DPGjh17QceOHfdk77dn/PjxJaWsUayTyWt7Tq+88sq23KXNV0ePHrWRI0eWXrJkyZpff/11dWJi4uFHHnkk/sCBA1EvvPBCuaFDh27L/Zpp06bF1axZ8/Cvv/66eunSpWv69++fsGfPnrPuX/4ccXtH0jBJ7+bxfEtJ1bK/rpL07+xfAQBALqcaGfOXv/zlL4enTZt2/pm8pmjRoq5evXoHpkyZUnzChAnnd+nSZc/ZfHZGRoZmz55dYu7cuSVeeumleOec9u7dG/P7779HlS1bNmPfvn1/GLbas2dPdJUqVY6WLFkys2jRoplr1qwpmNeo28nEx8enb9y4seCJx9u3by+Yc7RNkhYvXlxEkpKSko5KUteuXfcMHjy43Nq1awtt2bKl0GWXXZYoSb/++mvBWrVqXbpkyZK1Y8aMuWDQoEE7oqKiVLNmzaMVK1Y8umrVqsKNGjU66Ujm6fhtxM05lyrpVL9Z7SS967IsllTCzOL9lQcAAJyZ66+//sCxY8ds6NCh/5vKXLJkSZGPP/64WP369Q9Mnjy5ZEZGhrZt2xazdOnSYn/7298OSlLnzp1/f+edd0p99dVXsR06dNif+33r1at34J133rlAkiZOnFh8//79f5o7nDFjRvFLLrnk8I4dO1Zv3br1m23btn3TokWL399///3z4+LiMsuUKZM+Y8aMWEn69ddfoxcuXBiXnJycJkl9+/bdfs8991Q6MbK1b9++qNOdVdq2bdu977///gWZmZlasGDBebGxscdzF7dKlSqlr1+/vvC2bdtiJOnjjz8uXr169SN169Y9vGfPnlVbt279ZuvWrd+ULVv22Ndff702ISEho3z58sfmzp1bXJJ++eWXmA0bNhSuUaOGz4UyNy/XuJWXlPNfD1uyt233Jg4AhJ5xSzZr+sqtXsc4YwcPHtTPP/+s9g3q6LmOV3odB3mIiorSjBkzfrrvvvsqvvrqq+UKFSrkKlSocPT111//pVmzZmlffPFFsUsvvTTJzNzTTz+9JSEhIUOSbrjhhv29evWq0rRp072FCxf+00L8wYMHb+vQocNFVatWTapTp05azrMwTxg3blzJtm3b/mE9W4cOHX4fMWJEmd69e+8eM2bMz/fdd1/CwIEDK0rSQw89tO3ESNjAgQN3pqWlRdWqVSuxQIECLiYmxvXp02eHlPcat5tuumnfRx99FFepUqWaRYoUyXzrrbc2nniuRo0aid9///2aypUrpw8YMGD7ddddd0lMTIyrUKHCsXHjxv18qmP43HPPbb/55psrV69ePdE5Z0899dSW+Pj4DJ9/E3Kx050eey7MrLKkmc65P926wcxmShrsnPss+/ECSQ8555adZN+7Jd0tSQkJCbU3bdrkt8wAEEo6j/hSa7bvV2J88dPvHCTS0tK0evUqmUWpY+N6eunWa875Pc1suXOuTj7ECyqrVq3aePnll+/yOgcCa9WqVaUuv/zyyid7zssRt62Scl6Ir0L2tj9xzo2UNFKS6tSpw60/ACCHxPjimtDraq9j+OzLL79Uz9HvaNq0aapatarXcYCQ4mVxmyGpt5mNV9ZJCfucc0yTAggr/p7KDKXRth07dqhcuXK6+uqrtWrVKp3LJRGASOXPy4F8IOlLSZeY2RYz62Fm95jZPdm7zJK0QdJ6SaMk3eevLADglekrt2rN9j+tzc43ifHF1e6K8n57//zy6aefqlq1aho9erQkUdp8l5mZmXnWV9lH6Mn+/c7M63m/jbg557qe5nkn6X5/fT4ABItQm8rMbykpKbr++uuVkJCg5s2bex0n1Hy7c+fOxNKlS++LiopiqVCYy8zMtJ07d8ZJOuk1cCXunAAA8KM5c+aoffv2uvjii7VgwQKVLVv29C/C/2RkZNy1Y8eOt3bs2FFT3KYyEmRK+jYjI+OuvHaguAGIaKxB858tW7aoXbt2qlGjhubNm6fSpUt7HSnk1K5d+zdJbb3OgeBBewcQ0ViD5j8VKlTQO++8o5SUFEobkE8YcQMQ8SJ9DVp+mzRpksqUKaMGDRqoS5cuXscBwgrFDUDYOJtpz0ieyvSHsWPH6vbbb1fz5s3VoEEDr+MAYYepUgBh42ymPSN5KjO/vf3227rtttvUoEEDTZo0yes4QFhixA1AWGHa0xvDhw/Xvffeq2bNmmnq1KkqWrSo15GAsMSIGwDgnDjn9Pnnn6t169aaPn06pQ3wI0bcAABnLS0tTcWKFdPo0aOVmZmpggULeh0JCGuMuAEAzspzzz2nWrVqaefOnYqJiaG0AQFAcQMAnBHnnJ588kk99thjuuqqq3T++ed7HQmIGEyVAvArf9+ZICcu7eF/zjk9/PDDev7553XHHXdo1KhR3DAeCCBG3AD4lb/vTJATl/bwv1deeUXPP/+87rnnHr311luUNiDAGHED4HdcoiN83HrrrUpPT9eAAQNkZl7HASIOI24AgFPKzMzUm2++qWPHjqlUqVIaOHAgpQ3wCCNuAHxytmvVWHcW2o4fP64ePXpozJgxKlGihLp16+Z1JCCiMeIGwCdnu1aNdWehKyMjQ7feeqvGjBmjZ555htIGBAFG3AD4jLVqkSM9PV3dunXT5MmTNXjwYD300ENeRwIgihsQkc5m2pMpz8jy008/af78+XrppZf04IMPeh0HQDaKGxCBTkx7nkkRY8ozMmRkZCgmJkY1atTQDz/8oNKlS3sdCUAOFDcgQjHtidwOHTqkdu3aqXHjxho0aBClDQhCnJwAAFBaWppatWqllJQUXXjhhV7HAZAHRtyAIOePW0axXg057d+/Xy1bttSSJUs0duxYde3a1etIAPLAiBsQ5PxxyyjWq+GEjIwMNW/eXEuXLtWECRMobUCQY8QNCAGsR4O/xMTEqEePHnr44YfVtm1br+MAOA2KG+ARX6dAmdaEP/z222/6/vvvVb9+fd11111exwHgI6ZKAY/4OgXKtCby2/bt29WwYUPdeOONOnDggNdxAJwBRtwADzEFikDbsmWLkpOTtW3bNn300UeKjY31OhKAM0BxA4AIsWnTJiUnJ2vnzp2aM2eOrr32Wq8jAThDFDcggHKua2PtGgJt5MiR2r17t+bPn6+6det6HQfAWWCNGxBAOde1sXYNgeKckyQ9++yzWr58OaUNCGGMuAEBxro2BNLatWt111136YMPPlBCQoIuvvhiryMBOAcUNwAIU998840aN26sqKgopaWleR0HQD5gqhQAwtCKFSvUqFEjFShQQIsWLVJiYqLXkQDkA4obAISZlStXKjk5Weedd55SU1N1ySWXeB0JQD6huAFAmKlUqZIaN26s1NRU1rQBYYY1bsBZ8PV2VblxCRD409dff63ExESdf/75mjx5stdxAPgBI27AWfD1dlW5cQkQ+MuCBQt03XXXacCAAV5HAeBHjLgBZ4nLeiBYfPzxx7rhhhtUtWpVPfbYY17HAeBHFDdEnLOd5syJKU8Eiw8//FAdO3ZUYmKi5s2bp1KlSnkdCYAfMVWKiHO205w5MeWJYHDo0CH16tVLl19+uVJSUihtQARgxA0RiWlOhIOiRYtq3rx5qlChguLi4ryOAyAAGHEDgBDz3nvv6emnn5YkJSUlUdqACEJxA4AQ8p///Ee33367UlNTlZ6e7nUcAAFGcQOAEPHmm2/qrrvuUvPmzTVz5kwVKFDA60gAAoziBgAh4NVXX9X999+v66+/XtOmTVORIkW8jgTAAxQ3AAgBF1xwgTp16qTJkyerUKFCXscB4BHOKkXYyut6bVyDDaHkxx9/VLVq1XTLLbfo5ptvlpl5HQmAhxhxQ9jK63ptXIMNocA5p8cff1w1a9bUypUrJYnSBoARN4Q3rteGUOSc06BBg/TCCy/orrvu0mWXXeZ1JABBguKGsJF7apQpUYQi55z69eunV155Rffee6+GDRumqCgmRwBk4acBwkbuqVGmRBGKJk+erFdeeUV9+/bVG2+8QWkD8AeMuCGsMDWKUNehQwf997//1Q033MCaNgB/wj/lAMBjGRkZ6t+/v3766SdFRUXpxhtvpLQBOCmKGwB4KD09XbfeeqteeuklzZo1y+s4AIIcU6UA4JFjx46pa9eumjJlil544QX16dPH60gAghzFDQA8cPToUXXq1EkffvihXnnlFT3wwANeRwIQAihuAOCBY8eOadeuXXrzzTd17733eh0HQIiguAFAAB08eFCSFBsbq9TUVMXE8GMYgO/4iQEAAXLgwAG1adNGhQoV0pw5cyhtAM4YPzUAIAD27dunli1baunSpXr//fe53AeAs+LX4mZmLSS9Kila0lvOucG5nk+QNEZSiex9BjnnOB8eecp9W6ucuMUVgtXvv/+u5s2ba8WKFZo4caJuvPFGryMBCFF+u46bmUVLekNSS0mJkrqaWWKu3R6TNNE5d6WkLpLe9FcehIfct7XKiVtcIVjdfPPNWrVqlaZMmUJpA3BO/DniVlfSeufcBkkys/GS2klak2MfJ+nEEEmcpG1+zIMwwW2tEGqGDBmiLVu2qHnz5l5HARDi/Fncykv6JcfjLZKuyrXPU5LmmlkfSedJanKyNzKzuyXdLUkJCQn5HhTeONW0Z16YDkWo2L59u8aNG6d+/fopKSlJSUlJXkcCEAa8vuVVV0nvOOcqSGol6T0z+1Mm59xI51wd51yd0qVLBzwk/ONU0555YToUoWDLli1q0KCBnnzySW3cuNHrOADCiD9H3LZKqpjjcYXsbTn1kNRCkpxzX5pZYUmlJP3mx1wIIkx7Itxs3LhRycnJ2r17t+bOnasqVap4HQlAGPHniNtXkqqZWRUzK6iskw9m5Npns6TGkmRml0oqLGmnHzMBgN/89NNPatCggX7//XfNnz9f11xzjdeRAIQZv424OecyzKy3pDnKutTH286578zsGUnLnHMzJPWXNMrMHlTWiQrdnXPOX5kQGL6uXWO9GsLNt99+q6NHjyolJUVXXnml13EAhCELtZ5Up04dt2zZMq9j4BQ6j/jS51LW7ory6nYVJ5wgtB0+fFhFihSRJKWlpalYsWIeJ4o8ZrbcOVfH6xyAv3HnBPgFa9cQKVavXq2WLVtqxIgRatOmDaUNgF9R3HBWuIMBIH399ddq2rSpihQpourVq3sdB0AE8PpyIAhR3MEAkW7JkiVKTk5WbGysUlNTKW4AAoIRN5w1pkMRqX7++Wc1bdpUpUuXVkpKiipVquR1JAARghE3ADhDlStX1iOPPKLU1FRKG4CAYsQNAHy0YMEClS9fXjVq1NCgQYO8jgMgAjHiBgA+mDVrllq3bq0HH3zQ6ygAIhjFDQBOY/r06Wrfvr2SkpI0duxYr+MAiGBMleIPuOsB8EeTJ09W165dVatWLc2ZM0clSpTwOhKACMaIG/7gVJf5yIlLfiASOOc0fPhw1a1bV/PmzaO0AfAcI274Ey7zAUjHjx9XdHS0pk6dKjPjjggAggIjbgCQy6hRo5ScnKy0tDTFxsZS2gAEDYobAOTwxhtv6O6771axYsUUE8OkBIDgQnEDgGwvv/yyevfurXbt2mnKlCkqXLiw15EA4A8obgAg6c0331S/fv3UsWNHTZo0SYUKFfI6EgD8CcUNACQ1adJEffr00QcffKACBQp4HQcAToriBiBiOef04Ycfyjmn6tWr67XXXmNdG4CgRnEDEJGccxo4cKDatm2ryZMnex0HAHzCPy0BRBznnPr27avXXntN999/vzp06OB1JADwCcUtwuW+xRW3skK4y8zM1P3336/hw4frwQcf1Isvvigz8zoWAPiEqdIIl/sWV9zKCuFu1apVeuuttzRo0CBKG4CQw4gbuMUVIsqVV16pVatW6dJLL6W0AQg5FLcIkXtK9ASmRhEJ0tPT1b17d7Vt21adO3dWYmKi15EA4KwwVRohck+JnsDUKMLdsWPH1LlzZ40bN05btmzxOg4AnBNG3CIIU6KINEeOHFHHjh310Ucf6dVXX9Xf//53ryMBwDmhuAEIS+np6WrXrp3mzp2r4cOHq1evXl5HAoBzRnEDEJZiYmJUu3Ztde7cWXfeeafXcQAgX1DcAISVAwcOaOvWrapRo4b++c9/eh0HAPIVJycACBt79+5Vs2bN1LhxYx06dMjrOACQ7xhxAxAW9uzZo2bNmmn16tWaMGGCihYt6nUkAMh3FDcAIW/nzp1q2rSp1q5dqylTpqhNmzZeRwIAv6C4AQh5Tz31lNatW6cPP/xQzZo18zoOAPgNa9wAhLwhQ4Zo0aJFlDYAYY8RtzCV+xZX3NoK4eaXX37RwIEDNXz4cMXFxalu3bpeRwIAv2PELUzlvsUVt7ZCONm4caPq16+vWbNmacOGDV7HAYCAYcQtjHGLK4Sj9evXKzk5WWlpaVqwYIGuvPJKryMBQMBQ3ACEjHXr1ik5OVlHjx5VSkqKrrjiCq8jAUBAUdxCTO61a3lhTRvCUcGCBXXhhRdq9OjRqlmzptdxACDgWOMWYnKvXcsLa9oQTjZt2qTMzExVqVJFS5cupbQBiFiMuIUg1q4hkixfvlxNmzbV/fffr2effVZm5nUkAPAMxS0E5JweZQoUkWTx4sVq0aKFzj//fN15551exwEAzzFVGgJyTo8yBYpI8dlnn6lp06YqVaqUFi1apCpVqngdCQA8x4hbiGB6FJHkwIEDat++vcqXL6+UlBRdeOGFXkcCgKBAcQMQdGJjYzVx4kQlJSWpbNmyXscBgKBBcQMQNGbNmqVdu3bptttuU3JystdxACDosMYNQFCYNm2a2rdvr2HDhikjI8PrOAAQlChuADw3adIkderUSbVq1dLcuXMVE8NkAACcDMUNgKfGjRunLl26qF69epo7d65KlCjhdSQACFoUNwCeWr9+vRo0aKDZs2ereHGuUQgAp0JxA+CJPXv2SJIef/xxffzxxypWrJjHiQAg+FHcAATcsGHDVK1aNf3www8yMxUsWNDrSAAQEihuAALqxRdfVJ8+fVS/fn1VrlzZ6zgAEFIobgAC5l//+pf+8Y9/qFOnTpo4cSIjbQBwhihuAALigw8+0COPPKKbb75Z48aNU4ECBbyOBAAhh4slBYlxSzZr+sqtJ31uzfb9SoznbDuEthtuuEEvv/yy+vTpo+joaK/jAEBIYsQtSExfuVVrtu8/6XOJ8cXV7oryAU4EnDvnnF5++WXt2bNHhQsXVt++fSltAHAOfBpxM7MikhKcc+v8nCeiJcYX14ReV3sdA8gXmZmZeuCBBzRs2DA559SvXz+vIwFAyDvtiJuZXS9ppaSPsx9fYWYz/B0MQOjKzMzUPffco2HDhql///568MEHvY4EAGHBl6nSpyTVlbRXkpxzKyVV8WMmACHs+PHj6tGjh0aNGqVHHnlEQ4YMkZl5HQsAwoIvxS3dObcv1zbnjzAAQt/u3bu1aNEiPf300/q///s/ShsA5CNf1rh9Z2bdJEWbWTVJf5f0hS9vbmYtJL0qKVrSW865wSfZ5yZljeo5Saucc918zA4giKSnpysqKkplypTRihUrFBcX53UkAAg7voy49ZGUJOmopHGS9kl64HQvMrNoSW9IaikpUVJXM0vMtU81SQ9LutY5lySp7xmlBxAUjh49qk6dOqlnz55yzlHaAMBPfClurZ1zjzrn/pr99Ziktj68rq6k9c65Dc65Y5LGS2qXa5+ekt5wzv0uSc65384kPADvHTlyRDfeeKOmT5+uWrVqMTUKAH7kS3F72MdtuZWX9EuOx1uyt+VUXVJ1M/vczBZnT63+iZndbWbLzGzZzp07ffhoAIFw6NAhtW3bVrNnz9aIESPUu3dvryMBQFjLc42bmbWU1EpSeTN7LcdTxSVl5OPnV5PUUFIFSalm9hfn3N6cOznnRkoaKUl16tThxAggSHTu3Fnz58/X22+/re7du3sdBwDC3qlOTtgmaZmypkWX59h+QJIvF2XaKqlijscVsrfltEXSEudcuqSfzewHZRW5r3x4fwAe69u3r7p27apu3TinCAACIc/i5pxbJWmVmY3LLlZn6itJ1cysirIKWxdJuX+6T5PUVdJoMyulrKnTDWfxWQACZO/evVqwYIE6dOigxo0bex0HACKKL2vcKpvZZDNbY2YbTnyd7kXOuQxJvSXNkbRW0kTn3Hdm9oyZnTi5YY6k3Wa2RtInkgY453af5X8LAD/bs2ePmjRpoptvvlm//PLL6V8AAMhXvlzHbbSkJyW9LKmRpDvk483pnXOzJM3Kte2JHN87Sf2yv8LSuCWbNX1l7hniP1uzfb8S44sHIBFwdnbu3KkmTZpo3bp1+u9//6uKFSue/kUAgHzlSwEr4pxbIMmcc5ucc09Jau3fWOFj+sqtWrN9/2n3S4wvrnZX5D7pFggOO3bsUMOGDfXDDz9oxowZat2aHwEA4AVfRtyOmlmUpB/NrLey1qsV82+s8JIYX1wTel3tdQzgrM2cOVObNm3SrFmz1KhRI6/jAEDE8mXE7QFJRZV1q6vakm6RdLs/QwEIDpmZmZKku+66S99//z2lDQA8dsriln3bqs7OuTTn3Bbn3B3OuQ7OucUByheSxi3ZrM4jvlTnEV/6NE0KBKOff/5ZtWrV0ldfZV2dp0KFCh4nAgCcsrg5545Lui5AWcJGznVtrF1DKPrxxx9Vv359bd68WVFRPp2LBAAIAF/WuK0wsxmSJkk6eGKjc26K31KFAda1IVStXbtWjRs3Vnp6uj755BNdfvnlXkcCAGTzpbgVlrRbUnKObU4SxQ0IMxs2bFDDhg1lZlq4cKGSkpK8jgQAyOG0xc05d0cgggDwXsWKFdW+fXv169dPl1xyiddxAAC5+DLiBiDMrVixQuXLl1eZMmU0YsQIr+MAAPLAqmMgwn355Zdq2LChevbs6XUUAMBpMOKWD3Lf1orbVyFUfPrpp2rVqpXKlSunYcOGeR0HAHAapx1xM7OyZvYfM5ud/TjRzHr4P1royH1bKy4BglCQkpKiFi1aqEKFClq0aBH3HgWAEODLiNs7yrrR/KPZj3+QNEHSf/yUKSRx+Q+EkszMTPXv318XXXSR5s+fr7Jly3odCQDgA1+KWztVBh0AACAASURBVCnn3EQze1iSnHMZZnbcz7kA+FFUVJRmzpypQoUKqVSpUl7HAQD4yJeTEw6a2QXKunabzKyepH1+TQXAL6ZOnarbbrtNx48fV/ny5SltABBifClu/SXNkHSxmX0u6V1JffyaCkC+mzBhgjp16qT169fr0KFDXscBAJwFXy7Au9zMGki6RJJJWuecS/d7MgD5ZuzYsbr99tt17bXX6qOPPlJsbKzXkQAAZ8GXs0pXSxoo6Yhz7ltKGxBaxowZo9tuu00NGzbU7NmzKW0AEMJ8mSq9XlKGpIlm9pWZ/cPMEvycC0A+ueiii3TDDTdo5syZOu+887yOAwA4B6ctbs65Tc65F5xztSV1k3SZpJ/9ngzAOVm1apUk6W9/+5v++9//qkiRIh4nAgCcK59ueWVmlcxsoKTxkmooa+oUQJAaOnSorrjiCs2aNcvrKACAfHTakxPMbImkApImSerknNvg91QAztpzzz2nxx57TJ07d1bTpk29jgMAyEe+XID3NufcOr8nAXBOnHN66qmn9Mwzz+iWW27R6NGjFRPD7YgBIJzk+VPdzG5xzo2V1NrMWud+3jn3kl+TATgjixcv1jPPPKM77rhDo0aNUnR0tNeRAAD57FT/HD9x+tnJrh3g/JAFwDm4+uqrNW/ePCUnJysqyqflqwCAEJNncXPOjcj+dr5z7vOcz5nZtX5NBcAnmZmZeuihh9S+fXtde+21atKkideRAAB+5Ms/y1/3cRuAAMrMzFSvXr00dOhQzZkzx+s4AIAAONUat6slXSOptJn1y/FUcUksngE8dPz4cfXo0UNjxozRo48+qqefftrrSACAADjVGreCkopl75Nzndt+SR39GQpA3jIyMnTbbbfpgw8+0DPPPKPHH3/c60gAgAA51Rq3RZIWmdk7zrlNAcwE4DQyMzM1ePBgPfTQQ15HAQAE0KmmSl9xzvWVNMzM/nQWqXOurV+TAfiDo0ePat++fSpTpozGjRvHmaMAEIFONVX6XvavQwMRBEDeDh8+rA4dOmjjxo1asWKFChUq5HUkAIAHTjVVujz710UntpnZ+ZIqOudWByAbAEmHDh1Su3bttGDBAo0YMYLSBgAR7LRzLWa20MyKm1lJSV9LGmVm3DUBCIC0tDS1atVKKSkpGj16tHr27Ol1JACAh3xZJBPnnNsv6UZJ7zrnrpLEVT6BAOjbt68+++wzjR07VrfffrvXcQAAHvOluMWYWbykmyTN9HMeADk899xzmj59urp27ep1FABAEPCluD0jaY6kn5xzX5nZRZJ+9G8sIHLt3r1bgwYNUnp6usqWLavWrVt7HQkAECROdVapJMk5N0nSpByPN0jq4M9QQKT67bff1KRJE/3www/q2LGj6tSp43UkAEAQ8eXkhApmNtXMfsv++q+ZVQhEOCCSbN++XQ0bNtT69es1c+ZMShsA4E98mSodLWmGpAuzvz7M3gYgn2zZskUNGjTQ5s2bNXv2bDVpwvk/AIA/86W4lXbOjXbOZWR/vSOptJ9zARFlx44dOnz4sObMmaMGDRp4HQcAEKROu8ZN0m4zu0XSB9mPu0ra7b9IQOTYt2+f4uLiVKdOHa1fv56L6wIATsmXEbc7lXUpkB3ZXx0l3eHPUKFg3JLN6jziS3Ue8aXWbN/vdRyEoB9//FE1a9bUsGHDJInSBgA4LV/OKt0kiRvK5zJ95Vat2b5fifHFlRhfXO2uKO91JISQtWvXKjk5WcePH1f9+vW9jgMACBGnLW7Z1217VVI9SU7Sl5IezL4sSERLjC+uCb2u9joGQsw333yjxo0bKzo6WgsXLlRiYqLXkQAAIcKXqdJxkiZKilfWWaWT9P/XuwE4A3v37lVycrIKFiyoRYsWUdoAAGfEl+JW1Dn3Xo6zSsdKKuzvYEA4KlGihIYOHapFixapevXqXscBAIQYX84qnW1mgySNV9ZUaWdJs8yspCQ55/b4MR8QFr744gsdPXpUjRo14mbxAICz5ktxuyn71165tndRVpG7KF8TAWEmNTVVrVq1UrVq1bR8+XJFRfky0A0AwJ/5clZplUAECXbjlmzW9JVb//f4xBmlwKksWLBA119/vSpXrqxZs2ZR2gAA54S/RXx04vIfJ3AJEJzOxx9/rDZt2qhq1apauHCh4uPjvY4EAAhxvkyVIhuX/8CZmDJlimrUqKF58+apVKlSXscBAIQBihuQz44dO6aCBQvq3//+t9LS0hQXF+d1JABAmDjtVKllucXMnsh+nGBmdf0fDQg9EyZM0GWXXaZt27YpOjqa0gYAyFe+rHF7U9LVyrq5vCQdkPSG3xIBIeq9995Tt27dVLZsWcXGxnodBwAQhnwpblc55+6XdESSnHO/Syro11RAiHn77bd1++23q2HDhpo1axbFDQDgF74Ut3Qzi1bWNdtkZqUlZfo1FRBCJk6cqB49eqh58+aaOXOmzjvvPK8jAQDClC/F7TVJUyWVMbPnJH0m6Z9+TQWEkMaNG6tfv36aNm2aihQp4nUcAEAYO21xc869L2mgpH9J2i6pvXNukr+DAcFu0qRJOnr0qC644AK9+OKLKlSokNeRAABhzpezShMkHZL0oaQZkg5mbwMi1rPPPqubbrpJb775ptdRAAARxJep0o8kzcz+dYGkDZJm+/LmZtbCzNaZ2frsG9XntV8HM3NmVseX9wW84pzT448/rieeeEK33nqr/v73v3sdCQAQQXy5V+lfcj42s1qS7jvd67JPaHhDUlNJWyR9ZWYznHNrcu0XK+kBSUvOIDcQcM45PfTQQxoyZIh69OihESNGKDo62utYAIAIcsb3KnXOfS3pKh92rStpvXNug3PumKTxktqdZL9nJT2v7MuNAMFqy5Yteuutt3Tvvfdq5MiRlDYAQMCddsTNzPrleBglqZakbT68d3lJv+R4vEW5Cl/26F1F59xHZjbgFBnulnS3JCUksLwOgeWck5mpYsWKWrFihRISEmRmXscCAEQgX0bcYnN8FVLWWreTjZydETOLkvSSpP6n29c5N9I5V8c5V6d06dLn+tGAz44fP66ePXvq//7v/yRJlSpVorQBADxzyhG37HVqsc65f5zFe2+VVDHH4wrZ206IlVRT0sLsvwjLSZphZm2dc8vO4vOAfJWRkaE777xT7733nh577DGv4wAAkHdxM7MY51yGmV17lu/9laRqZlZFWYWti6RuJ550zu2TVCrH5y2U9A9KG4JBenq6br31Vk2YMEHPPvssxQ0AEBRONeK2VFnr2Vaa2QxJkyQdPPGkc27Kqd44u/T1ljRHUrSkt51z35nZM5KWOedmnHN6wA+cc+rWrZsmT56sF154QQMG5Ln8EgCAgDrtyQmSCkvaLSlZWfcrtexfT1ncJMk5N0vSrFzbnshj34Y+ZAH8zszUqlUrXXfddXrggQe8jgMAwP+cqriVyT6j9Fv9/8J2gvNrKsADhw8f1qpVq1SvXj3dcccdXscBAOBPTlXcoiUV0x8L2wlhW9zGLdms6Su3/mn7mu37lRhf3INECISDBw+qbdu2Wrx4sX766SeVK1fO60gAAPzJqYrbdufcMwFLEiSmr9x60pKWGF9c7a4o71Eq+NOBAwfUunVrff7553rnnXcobQCAoHWq4haxF6tKjC+uCb2u9joGAmDfvn1q2bKlli5dqvfff19dunTxOhIAAHk6VXFrHLAUgEdGjhypr776ShMmTFCHDh28jgMAwCnlWdycc3sCGQTwQv/+/dW4cWPVqlXL6ygAAJzWGd9kHgh1v/76q9q0aaNNmzYpKiqK0gYACBm+XMcNCBvbt29XcnKyNm/erI0bN6pSpUpeRwIAwGcRX9xyX/6Dy36Ery1btig5OVnbt2/X7NmzVb9+fa8jAQBwRiJ+qvTE5T9O4LIf4Wnz5s2qX7++fv31V82ZM4fSBgAISRE/4iZx+Y9IULx4cVWtWlXjx49X3bp1vY4DAMBZobghrG3YsEHlypVTiRIlNHfuXK/jAABwTiJ+qhTha82aNbrmmmt09913ex0FAIB8QXFDWFq9erUaNmwoM9Ojjz7qdRwAAPIFxQ1h5+uvv1ajRo1UsGBBLVq0SJdeeqnXkQAAyBcUN4SVjIwMde3aVbGxsUpNTVX16tW9jgQAQL7h5ASElZiYGE2aNElxcXFcXBcAEHYYcUNYWLRokZ555hk553TZZZdR2gAAYYnihpA3f/58tWzZUuPHj1daWprXcQAA8BuKG0La7Nmz1aZNG1WtWlULFy5UbGys15EAAPAbihtC1owZM9S+fXslJSXpk08+UZkyZbyOBACAX1HcELIOHjyo2rVra8GCBbrgggu8jgMAgN9R3BBytm/fLknq2rWrPv30U5UoUcLjRAAABAbFDSFlzJgxuuiii/TZZ59JkqKjoz1OBABA4FDcEDJGjRqlO+64Q9ddd51q1arldRwAAAKO4oaQ8MYbb+juu+9WixYt9OGHH6po0aJeRwIAIOAobgh6CxcuVO/evdWuXTtNnTpVhQsX9joSAACeoLgh6DVo0ED/+c9/NGnSJBUqVMjrOAAAeIbihqDknNPLL7+sH3/8UWamO++8UwUKFPA6FgAAnqK4Ieg45/T444+rX79+GjVqlNdxAAAIGjFeBwBycs5p4MCBGjp0qHr27KnBgwd7HQkAgKDBiBuChnNOffv21dChQ3X//fdr+PDhiorijygAACfwtyKCxpEjR7R8+XI9+OCDev311yltAADkwlQpPHf8+HEdPXpURYsW1bx581S4cGGZmdexAAAIOgxpwFMZGRnq3r27WrdurfT0dBUpUoTSBgBAHihu8Ex6erpuueUWjR07Vk2bNuVyHwAAnAZTpfDEsWPH1KVLF02dOlVDhgzRP/7xD68jAQAQ9Chu8MR9992nqVOn6tVXX9Xf//53r+MAABASKG7wRP/+/XXNNdfozjvv9DoKAAAhgzVuCJiDBw9q+PDhcs7p0ksvpbQBAHCGKG4IiAMHDqhly5a6//77tWLFCq/jAAAQkpgqhd/t27dPLVq00FdffaVx48apVq1aXkcCACAkUdzgV3v27FHz5s21atUqTZo0STfccIPXkQAACFkUN/jVsmXLtHbtWk2ZMkVt2rTxOg4AACGN4ga/yMjIUExMjJo1a6aff/5ZpUuX9joSAAAhj5MTkO+2bdumK6+8UlOmTJEkShsAAPmEETfkq19++UXJycnasWMHhQ0AgHxGcUO+2bhxoxo1aqQ9e/Zo3rx5qlevnteRAAAIKxQ35Itdu3apfv36SktL04IFC1SnTh2vIwEAEHZY44Z8ccEFF+jOO+9USkoKpQ0AAD9hxA3n5LvvvpOZKTExUU899ZTXcQAACGsUN5y1VatWqUmTJkpISNCyZctkZl5HAgAgrDFVirOyfPlyNWrUSIULF9b48eMpbQAABADFDWds8eLFaty4seLi4pSamqpq1ap5HQkAgIgQkVOl45Zs1vSVWyVJa7bvV2J8cY8ThZZ//etfKlWqlFJSUpSQkOB1HAAAIkZEFrfpK7f+r7AlxhdXuyvKex0pJDjnZGZ6//33deDAAcXHx3sdCQCAiBKRxU2SEuOLa0Kvq72OETLmzp2rF154QVOnTlVsbKyKFSvmdSQAACIOa9xwWrNmzVLbtm21a9cuHT161Os4AABELIobTmnatGlq3769atasqZSUFJUqVcrrSAAARCyKG/I0ffp0derUSbVq1dL8+fNVsmRJryMBABDR/FrczKyFma0zs/VmNugkz/czszVmttrMFphZJX/mwZmpWbOmbrzxRs2dO1clSpTwOg4AABHPb8XNzKIlvSGppaRESV3NLDHXbisk1XHOXSZpsqQX/JUHvvviiy/knNPFF1+sCRMmqHhxLpcCAEAw8OeIW11J651zG5xzxySNl9Qu5w7OuU+cc4eyHy6WVMGPeeCDkSNH6tprr9WIESO8jgIAAHLxZ3ErL+mXHI+3ZG/LSw9Js0/2hJndbWbLzGzZzp078zEicho2bJh69eqlVq1aqXv37l7HAQAAuQTFyQlmdoukOpKGnOx559xI51wd51yd0qVLBzZchHjxxRfVp08ftWvXTlOmTFHhwoW9jgQAAHLx5wV4t0qqmONxhextf2BmTSQ9KqmBc46LhHlgw4YNeuSRR9SpUye9//77KlCggNeRAADASfizuH0lqZqZVVFWYesiqVvOHczsSkkjJLVwzv3mxyw4hYsuukifffaZrrzySsXEROzNNAAACHp+myp1zmVI6i1pjqS1kiY6574zs2fMrG32bkMkFZM0ycxWmtkMf+XBHznn9Nhjj2ncuHGSpL/+9a+UNgAAgpxf/6Z2zs2SNCvXtidyfN/En5+Pk3POacCAAXrxxRd17733qlu3bqd/EQAA8BxDLBHGOacHHnhAr7/+unr37q3XXnvN60gAAMBHQXFWKQLDOad7771Xr7/+uvr376/XXntNZuZ1LAAA4COKW4QpVaqUHn74YQ0ZMoTSBgBAiGGqNAJkZGRo06ZNuvjii/Xss89KEqUNAIAQxIhbmEtPT1e3bt1Ur1497dq1S2ZGaQMAIEQx4hbGjh49qs6dO2v69Ol68cUXVapUKa8jAQCAc0BxC1NHjhxRhw4dNGvWrP+dQQoAAEIbxS1M/etf/9Ls2bM1YsQI3X333V7HAQAA+YDiFqYGDRqkq666Sq1atfI6CgAAyCecnBBG9u/fr3vvvVd79+5VkSJFKG0AAIQZiluY2Lt3r5o1a6a33npLS5cu9ToOAADwA6ZKw8CePXvUrFkzrV69WpMnT1azZs28jgQAAPyA4hbidu7cqaZNm+r777/XtGnTmB4FACCMUdxC3OHDh3Xs2DF9+OGHatq0qddxAACAH1HcQtSuXbtUsmRJJSQkaPXq1YqJ4bcSAIBwx8kJIWjz5s2qV6+e+vfvL0mUNgAAIgTFLcT8/PPPatCggXbt2qUuXbp4HQcAAAQQQzUh5Mcff1RycrIOHjyoBQsWqHbt2l5HAgAAAURxCxHp6elq0aKFjhw5ok8++USXX36515EAAECAUdxCRIECBTR8+HBdeOGFSkpK8joOAADwAGvcgtzKlSv13nvvSZKaNm1KaQMAIIIx4hbEli1bpmbNmql48eLq0KGDihYt6nUkAADgIUbcgtSXX36pxo0bKy4uTgsXLqS0AQAAilswSk1NVbNmzVSmTBmlpqaqcuXKXkcCAABBgOIWhJYsWaIKFSpo0aJFqlixotdxAABAkKC4BZFDhw5JkgYMGKBly5bpwgsv9DgRAAAIJhS3IDFz5kxdfPHFWr16tSTpvPPO8zgRAAAINhS3IDB16lTdeOONqlChgipUqOB1HAAAEKQobh6bMGGCOnXqpNq1a2v+/PkqWbKk15EAAECQorh5KCUlRd26ddM111yjuXPnKi4uzutIAAAgiFHcPHTttdfqscce0+zZsxUbG+t1HAAAEOQobh4YP368du3apUKFCunpp5/mRAQAAOATiluAvfbaa+ratasGDx7sdRQAABBiKG4BNHToUD3wwAO64YYb9M9//tPrOAAAIMRQ3ALkueee04ABA9S5c2dNmDBBBQsW9DoSAAAIMRS3ADhw4IBGjx6tW265RWPHjlWBAgW8jgQAAEJQjNcBwplzTpmZmYqNjdUXX3yhCy64QNHR0V7HAgAAIYoRNz9xzqlfv3664447dPz4cZUpU4bSBgAAzgnFzQ8yMzPVu3dvvfLKKypZsqSiojjMAADg3NEo8llmZqbuuecevfnmmxowYIBefvllmZnXsQAAQBiguOWzPn36aNSoUXr00Uf1/PPPU9oAAEC+4eSEfNapUyeVL19ejzzyiNdRAABAmGHELR8cO3ZMs2fPliQ1bNiQ0gYAAPyC4naOjh49qo4dO6p169b67rvvvI4DAADCGFOl5+Dw4cO68cYb9fHHH2vYsGFKSkryOhIAAAhjFLezdOjQIbVr104LFizQyJEj1bNnT68jAQCAMEdxO0szZ85USkqKRo8erdtvv93rOAAAIAJQ3M7STTfdpL/85S+69NJLvY4CAAAiBCcnnIG9e/eqWbNmWrJkiSRR2gAAQEAx4uaj3bt3q1mzZvrmm2/022+/eR0HAABEIIqbD3777Tc1bdpU69at0/Tp09WyZUuvIwEAgAhEcTuNXbt2qVGjRvr55581c+ZMNWnSxOtIAAAgQrHG7TTi4uJUu3ZtzZ49m9IGAAA8xYhbHjZv3qxChQqpbNmyevfdd72OAwAAwIjbyWzYsEF/+9vf1LFjRznnvI4DAAAgieL2Jz/88IPq16+vtLQ0vfrqqzIzryMBAABIYqr0D9asWaPGjRvr+PHj+uSTT3TZZZd5HQkAAOB/KG453HfffZKkhQsXKjEx0eM0AAAAf0Rxy+GDDz7QgQMHVL16da+jAAAA/EnEr3FbunSpevbsqYyMDMXHx1PaAABA0PJrcTOzFma2zszWm9mgkzxfyMwmZD+/xMwq+zNPbl988YWaNGmiBQsWaNeuXYH8aAAAgDPmt+JmZtGS3pDUUlKipK5mlnvhWA9Jvzvnqkp6WdLz/sqT2759WTeML1eunFJTU1WuXLlAfTQAAMBZ8eeIW11J651zG5xzxySNl9Qu1z7tJI3J/n6ypMYWgOtv7N37u1av/kYJCQlatGiRKlSo4O+PBAAAOGf+LG7lJf2S4/GW7G0n3cc5lyFpn6QL/JhJkhQVFa1ixYpp4cKFio+P9/fHAQAA5IuQOKvUzO6WdLckJSQknPP71atRQfUuqaAyZcqc83sBAAAEij+L21ZJFXM8rpC97WT7bDGzGElxknbnfiPn3EhJIyWpTp0653wPqievTzrXtwAAAAg4f06VfiWpmplVMbOCkrpImpFrnxmSbs/+vqOkFMfNQQEAAE7KbyNuzrkMM+staY6kaElvO+e+M7NnJC1zzs2Q9B9J75nZekl7lFXuAAAAcBJ+XePmnJslaVaubU/k+P6IpE7+zAAAABAuIv7OCQAAAKGC4gYAABAiKG4AAAAhguIGAAAQIihuAAAAIYLiBgAAECIobgAAACGC4gYAABAiKG4AAAAhguIGAAAQIihuAAAAIYLiBgAAECLMOed1hjNiZjslbcqHtyolaVc+vE844tjkjWOTN45N3jg2ecuvY1PJOVc6H94HCGohV9zyi5ktc87V8TpHMOLY5I1jkzeOTd44Nnnj2ABnhqlSAACAEEFxAwAACBGRXNxGeh0giHFs8saxyRvHJm8cm7xxbIAzELFr3AAAAEJNJI+4AQAAhBSKGwAAQIgI++JmZi3MbJ2ZrTezQSd5vpCZTch+fomZVQ58Sm/4cGz6mdkaM1ttZgvMrJIXOb1wumOTY78OZubMLGIuZ+DLsTGzm7L/7HxnZuMCndErPvw/lWBmn5jZiuz/r1p5kTPQzOxtM/vNzL7N43kzs9eyj9tqM6sV6IxAqAjr4mZm0ZLekNRSUqKkrmaWmGu3HpJ+d85VlfSypOcDm9IbPh6bFZLqOOcukzRZ0guBTekNH4+NzCxW0gOSlgQ2oXd8OTZmVk3Sw5Kudc4lSeob8KAe8PHPzWOSJjrnrpTURdKbgU3pmXcktTjF8y0lVcv+ulvSvwOQCQhJYV3cJNWVtN45t8E5d0zSeEntcu3TTtKY7O8nS2psZhbAjF457bFxzn3inDuU/XCxpAoBzugVX/7cSNKzyir6RwIZzmO+HJuekt5wzv0uSc653wKc0Su+HBsnqXj293GStgUwn2ecc6mS9pxil3aS3nVZFksqYWbxgUkHhJZwL27lJf2S4/GW7G0n3cc5lyFpn6QLApLOW74cm5x6SJrt10TB47THJnsqp6Jz7qNABgsCvvy5qS6pupl9bmaLzexUIy3hxJdj85SkW8xsi6RZkvoEJlrQO9OfR0DEivE6AIKfmd0iqY6kBl5nCQZmFiXpJUndPY4SrGKUNeXVUFmjtKlm9hfn3F5PUwWHrpLecc69aGZXS3rPzGo65zK9DgYgNIT7iNtWSRVzPK6Qve2k+5hZjLKmL3YHJJ23fDk2MrMmkh6V1NY5dzRA2bx2umMTK6mmpIVmtlFSPUkzIuQEBV/+3GyRNMM5l+6c+1nSD8oqcuHOl2PTQ9JESXLOfSmpsLJush7pfPp5BCD8i9tXkqqZWRUzK6isxcAzcu0zQ9Lt2d93lJTiIuOqxKc9NmZ2paQRyiptkbJOSTrNsXHO7XPOlXLOVXbOVVbW+r+2zrll3sQNKF/+n5qmrNE2mVkpZU2dbghkSI/4cmw2S2osSWZ2qbKK286ApgxOMyTdln12aT1J+5xz270OBQSjsJ4qdc5lmFlvSXMkRUt62zn3nZk9I2mZc26GpP8oa7pivbIWz3bxLnHg+HhshkgqJmlS9vkam51zbT0LHSA+HpuI5OOxmSOpmZmtkXRc0gDnXNiPYvt4bPpLGmVmDyrrRIXukfAPRTP7QFllvlT2+r4nJRWQJOfccGWt92slab2kQ5Lu8CYpEPy45RUAAECICPepUgAAgLBBcQMAAAgRFDcAAIAQQXEDAAAIERQ3AACAEEFxA7KZ2XEzW5njq/Ip9k0LXLK8mdmFZjY5+/srzKxVjufamtmgAGapbGbdAvV5ABCJuBwIkM3M0pxzxfJ730Axs+6S6jjnevvxM2Ky7+l7sucaSvqHc66Nvz4fACIdI25AHsysmJktMLOvzeyb/9fe/YVWXYdxHH9/kCVt6MKIkC4ULIkudGR/wKYrKbsoyChZJVl00R8iyCjyQsKCyggEQRZUiBSyRApZRa5ARTkoaE6nQdSFRUGZQWnaRuKeLr7P2uF0jlsSyKnPCwa/893339luHp7vl98j6a46faZL2pUZuiOSFmT7Ykl7cuwWSX8L8iTtlLSuauwN2T5N0lZJg1mkfU62d1VlAwckTcks15F8U/9LQHf+gwuP+AAAAzdJREFUvlvSw5LWS2qX9G3WWEVSm6TvJLVImiVpm6TPJe2WdHWdfa6W9K6kCuVl1TOz74H8mZ9d1wALcv0VkiZJel3Svvwuj/1L/xozs/+t/3TlBLN/6GJJB/P5KLAUuDsiTmbppr2S+mredP8A0B8RL0uaBLRm31XArRFxWtLzwDOUwKpWa0R0SFoIbKDUQH0RGIiIJZIWAe8AHcCzwJMRUclAcHh0koj4Q9ILVGXcMgNHRJzI79UF7ADuzD2fkfQm8HhEfC3pRqAHWFRnn9cAnRExJKkVuC0ihiVdBfQC1wErqcq4SXqUUrroekmTgYqkT7N+qZmZnQcHbmZjhiKiY/SDpBbglQyqRoArgMuBH6vG7AM2ZN+tEXFQUhcl0KlkqbCLgD0N1uwFiIhdkqZKugToBO7J9u2SLpU0FagAayVtAj6IiO9z/onYDHRTArf7gJ4M/uYzVtIMYHKD8X0RMZTPLcB6SR2UklazG4xZDMyRdG9+bqcUm3fgZmZ2nhy4mTW2DLgMmJfZqW8oRcH/kgHXQuAOYKOktcAvwGcRcf8E1qi9ZNrw0mlErJH0MaWmY0XS7VRl3cbRRwlCpwHzgO1AG/BrdbB6DqernlcAx4C5lOsWjfYg4KmI6J/gHs3MbBy+42bWWDvwUwZttwAzajtImgEci4i3gLeBa4G9wE2Srsw+bZIaZaW6s08n5VjxBLCbEjSOXvj/OY9rZ0XE4Yh4jZLpq72P9hswpd4iEXEqx6wDPoqIsxFxEjgqaWmuJUlzJ/h3+SEiRoAHKQXV663fDzyR2UgkzZbUNoH5zcysAWfczBrbBHwo6TCwH/iyTp+bgecknQFOAcsj4njeL+vNu11Q7rx9VWf8sKQByvHjI9m2mnL8Ogj8DjyU7U9nADkCfAF8AkyvmmsHsDLvs71aZ63NwJbc86hlwBuSVuUe3gMO1RlbrQd4X9JyYBtj2bhB4KykQ8BGSpA4EzigchZ7HFgyztxmZnYOfh2I2QUiaSflMv/+C70XMzNrDj4qNTMzM2sSzriZmZmZNQln3MzMzMyahAM3MzMzsybhwM3MzMysSThwMzMzM2sSDtzMzMzMmsSfD4jwlCBokpQAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 504x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6xiapb3I1z7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "2ab6e982-d486-473c-d8fb-9b2e789f074d"
      },
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "get_performance_metrics(y, pred, class_labes, acc=get_accuracy, prevalence=get_prevalence, \n",
        "                        sens=get_sensitivity, spec=get_specificity, ppv=get_ppv, npv=get_npv, auc=roc_auc_score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TP</th>\n",
              "      <th>TN</th>\n",
              "      <th>FP</th>\n",
              "      <th>FN</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Prevalence</th>\n",
              "      <th>Sensitivity</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>PPV</th>\n",
              "      <th>NPV</th>\n",
              "      <th>AUC</th>\n",
              "      <th>F1</th>\n",
              "      <th>Threshold</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Covid</th>\n",
              "      <td>76</td>\n",
              "      <td>81</td>\n",
              "      <td>24</td>\n",
              "      <td>22</td>\n",
              "      <td>0.764</td>\n",
              "      <td>0.483</td>\n",
              "      <td>0.694</td>\n",
              "      <td>0.829</td>\n",
              "      <td>0.791</td>\n",
              "      <td>0.744</td>\n",
              "      <td>0.848</td>\n",
              "      <td>Not Defined</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       TP  TN  FP  FN Accuracy  ...    PPV    NPV    AUC           F1 Threshold\n",
              "                                ...                                            \n",
              "Covid  76  81  24  22    0.764  ...  0.791  0.744  0.848  Not Defined       0.5\n",
              "\n",
              "[1 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5MXulupI5o_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def bootstrap_auc(y, pred, classes, bootstraps = 100, fold_size = 1000):\n",
        "    statistics = np.zeros((len(classes), bootstraps))\n",
        "\n",
        "    for c in range(len(classes)):\n",
        "        df = pd.DataFrame(columns=['y', 'pred'])\n",
        "        df.loc[:, 'y'] = y[:, c]\n",
        "        df.loc[:, 'pred'] = pred[:, c]\n",
        "        # get positive examples for stratified sampling\n",
        "        df_pos = df[df.y == 1]\n",
        "        df_neg = df[df.y == 0]\n",
        "        prevalence = len(df_pos) / len(df)\n",
        "        for i in range(bootstraps):\n",
        "            # stratified sampling of positive and negative examples\n",
        "            pos_sample = df_pos.sample(n = int(fold_size * prevalence), replace=True)\n",
        "            neg_sample = df_neg.sample(n = int(fold_size * (1-prevalence)), replace=True)\n",
        "\n",
        "            y_sample = np.concatenate([pos_sample.y.values, neg_sample.y.values])\n",
        "            pred_sample = np.concatenate([pos_sample.pred.values, neg_sample.pred.values])\n",
        "            score = roc_auc_score(y_sample, pred_sample)\n",
        "            statistics[c][i] = score\n",
        "    return statistics\n",
        "\n",
        "statistics = bootstrap_auc(y, pred, class_labes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGl5cSVZJBCa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        },
        "outputId": "3ae4b28a-b153-444f-dbc2-9cd181280bb6"
      },
      "source": [
        "print_confidence_intervals(class_labes, statistics)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Mean AUC (CI 5%-95%)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Covid</th>\n",
              "      <td>0.85 (0.83-0.87)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Mean AUC (CI 5%-95%)\n",
              "Covid     0.85 (0.83-0.87)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bg2ASLc1JFBW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "afdbdfd6-266d-441c-9091-e0cc0f6fa74c"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "get_performance_metrics(y, pred, class_labes, acc=get_accuracy, prevalence=get_prevalence, \n",
        "                        sens=get_sensitivity, spec=get_specificity, ppv=get_ppv, npv=get_npv, auc=roc_auc_score,f1=f1_score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TP</th>\n",
              "      <th>TN</th>\n",
              "      <th>FP</th>\n",
              "      <th>FN</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Prevalence</th>\n",
              "      <th>Sensitivity</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>PPV</th>\n",
              "      <th>NPV</th>\n",
              "      <th>AUC</th>\n",
              "      <th>F1</th>\n",
              "      <th>Threshold</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Covid</th>\n",
              "      <td>76</td>\n",
              "      <td>81</td>\n",
              "      <td>24</td>\n",
              "      <td>22</td>\n",
              "      <td>0.764</td>\n",
              "      <td>0.483</td>\n",
              "      <td>0.694</td>\n",
              "      <td>0.829</td>\n",
              "      <td>0.791</td>\n",
              "      <td>0.744</td>\n",
              "      <td>0.848</td>\n",
              "      <td>0.739</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       TP  TN  FP  FN Accuracy  ...    PPV    NPV    AUC     F1 Threshold\n",
              "                                ...                                      \n",
              "Covid  76  81  24  22    0.764  ...  0.791  0.744  0.848  0.739       0.5\n",
              "\n",
              "[1 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QgXuTnmbJIsQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.calibration import calibration_curve\n",
        "def plot_calibration_curve(y, pred):\n",
        "    plt.figure(figsize=(20, 20))\n",
        "    for i in range(len(class_labes)):\n",
        "        plt.subplot(4, 4, i + 1)\n",
        "        fraction_of_positives, mean_predicted_value = calibration_curve(y[:,i], pred[:,i], n_bins=20)\n",
        "        plt.plot([0, 1], [0, 1], linestyle='--')\n",
        "        plt.plot(mean_predicted_value, fraction_of_positives, marker='.')\n",
        "        plt.xlabel(\"Predicted Value\")\n",
        "        plt.ylabel(\"Fraction of Positives\")\n",
        "        plt.title(class_labes[i])\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rI1VwZ1vJQGq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "outputId": "d40c03ee-60d6-4694-9b86-d7e5c80bd7a5"
      },
      "source": [
        "plot_calibration_curve(y, pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x1440 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mwa8MRzsJS9W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}