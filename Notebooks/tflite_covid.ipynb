{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tflite-covid.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vg8MPwIaV-13",
        "colab_type": "text"
      },
      "source": [
        "# **IMPORTS AND HELPER FUNCTIONS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KZUS_StVzuV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "8828651a-7c41-47b7-9c83-4bb849bf90ce"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.layers import Dense, Flatten, MaxPooling2D, GlobalAveragePooling2D, AveragePooling2D, Dropout, BatchNormalization, Input\n",
        "from tensorflow.keras.models import load_model, Sequential, Model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from tensorflow.keras.applications import VGG16, VGG19, ResNet50, ResNet101\n",
        "from sklearn.model_selection import KFold\n",
        "from tensorflow.keras.metrics import AUC, BinaryAccuracy\n",
        "from tensorflow.keras.regularizers import l2, l1, l1_l2\n",
        "from tensorflow.keras.activations import sigmoid, relu\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import Callback, LambdaCallback\n",
        "import math"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZoOH3esWV8V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CyclicLR(Callback):\n",
        "    \"\"\"This callback implements a cyclical learning rate policy (CLR).\n",
        "    The method cycles the learning rate between two boundaries with\n",
        "    some constant frequency.\n",
        "    # Arguments\n",
        "        base_lr: initial learning rate which is the\n",
        "            lower boundary in the cycle.\n",
        "        max_lr: upper boundary in the cycle. Functionally,\n",
        "            it defines the cycle amplitude (max_lr - base_lr).\n",
        "            The lr at any cycle is the sum of base_lr\n",
        "            and some scaling of the amplitude; therefore\n",
        "            max_lr may not actually be reached depending on\n",
        "            scaling function.\n",
        "        step_size: number of training iterations per\n",
        "            half cycle. Authors suggest setting step_size\n",
        "            2-8 x training iterations in epoch.\n",
        "        mode: one of {triangular, triangular2, exp_range}.\n",
        "            Default 'triangular'.\n",
        "            Values correspond to policies detailed above.\n",
        "            If scale_fn is not None, this argument is ignored.\n",
        "        gamma: constant in 'exp_range' scaling function:\n",
        "            gamma**(cycle iterations)\n",
        "        scale_fn: Custom scaling policy defined by a single\n",
        "            argument lambda function, where\n",
        "            0 <= scale_fn(x) <= 1 for all x >= 0.\n",
        "            mode paramater is ignored\n",
        "        scale_mode: {'cycle', 'iterations'}.\n",
        "            Defines whether scale_fn is evaluated on\n",
        "            cycle number or cycle iterations (training\n",
        "            iterations since start of cycle). Default is 'cycle'.\n",
        "\n",
        "    The amplitude of the cycle can be scaled on a per-iteration or\n",
        "    per-cycle basis.\n",
        "    This class has three built-in policies, as put forth in the paper.\n",
        "    \"triangular\":\n",
        "        A basic triangular cycle w/ no amplitude scaling.\n",
        "    \"triangular2\":\n",
        "        A basic triangular cycle that scales initial amplitude by half each cycle.\n",
        "    \"exp_range\":\n",
        "        A cycle that scales initial amplitude by gamma**(cycle iterations) at each\n",
        "        cycle iteration.\n",
        "    For more detail, please see paper.\n",
        "\n",
        "    # Example for CIFAR-10 w/ batch size 100:\n",
        "        ```python\n",
        "            clr = CyclicLR(base_lr=0.001, max_lr=0.006,\n",
        "                                step_size=2000., mode='triangular')\n",
        "            model.fit(X_train, Y_train, callbacks=[clr])\n",
        "        ```\n",
        "\n",
        "    Class also supports custom scaling functions:\n",
        "        ```python\n",
        "            clr_fn = lambda x: 0.5*(1+np.sin(x*np.pi/2.))\n",
        "            clr = CyclicLR(base_lr=0.001, max_lr=0.006,\n",
        "                                step_size=2000., scale_fn=clr_fn,\n",
        "                                scale_mode='cycle')\n",
        "            model.fit(X_train, Y_train, callbacks=[clr])\n",
        "        ```\n",
        "\n",
        "    # References\n",
        "\n",
        "      - [Cyclical Learning Rates for Training Neural Networks](\n",
        "      https://arxiv.org/abs/1506.01186)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "            self,\n",
        "            base_lr=0.001,\n",
        "            max_lr=0.006,\n",
        "            step_size=2000.,\n",
        "            mode='triangular',\n",
        "            gamma=1.,\n",
        "            scale_fn=None,\n",
        "            scale_mode='cycle'):\n",
        "        super(CyclicLR, self).__init__()\n",
        "\n",
        "        if mode not in ['triangular', 'triangular2',\n",
        "                        'exp_range']:\n",
        "            raise KeyError(\"mode must be one of 'triangular', \"\n",
        "                           \"'triangular2', or 'exp_range'\")\n",
        "        self.base_lr = base_lr\n",
        "        self.max_lr = max_lr\n",
        "        self.step_size = step_size\n",
        "        self.mode = mode\n",
        "        self.gamma = gamma\n",
        "        if scale_fn is None:\n",
        "            if self.mode == 'triangular':\n",
        "                self.scale_fn = lambda x: 1.\n",
        "                self.scale_mode = 'cycle'\n",
        "            elif self.mode == 'triangular2':\n",
        "                self.scale_fn = lambda x: 1 / (2.**(x - 1))\n",
        "                self.scale_mode = 'cycle'\n",
        "            elif self.mode == 'exp_range':\n",
        "                self.scale_fn = lambda x: gamma ** x\n",
        "                self.scale_mode = 'iterations'\n",
        "        else:\n",
        "            self.scale_fn = scale_fn\n",
        "            self.scale_mode = scale_mode\n",
        "        self.clr_iterations = 0.\n",
        "        self.trn_iterations = 0.\n",
        "        self.history = {}\n",
        "\n",
        "        self._reset()\n",
        "\n",
        "    def _reset(self, new_base_lr=None, new_max_lr=None,\n",
        "               new_step_size=None):\n",
        "        \"\"\"Resets cycle iterations.\n",
        "        Optional boundary/step size adjustment.\n",
        "        \"\"\"\n",
        "        if new_base_lr is not None:\n",
        "            self.base_lr = new_base_lr\n",
        "        if new_max_lr is not None:\n",
        "            self.max_lr = new_max_lr\n",
        "        if new_step_size is not None:\n",
        "            self.step_size = new_step_size\n",
        "        self.clr_iterations = 0.\n",
        "\n",
        "    def clr(self):\n",
        "        cycle = np.floor(1 + self.clr_iterations / (2 * self.step_size))\n",
        "        x = np.abs(self.clr_iterations / self.step_size - 2 * cycle + 1)\n",
        "        if self.scale_mode == 'cycle':\n",
        "            return self.base_lr + (self.max_lr - self.base_lr) * \\\n",
        "                np.maximum(0, (1 - x)) * self.scale_fn(cycle)\n",
        "        else:\n",
        "            return self.base_lr + (self.max_lr - self.base_lr) * \\\n",
        "                np.maximum(0, (1 - x)) * self.scale_fn(self.clr_iterations)\n",
        "\n",
        "    def on_train_begin(self, logs={}):\n",
        "        logs = logs or {}\n",
        "\n",
        "        if self.clr_iterations == 0:\n",
        "            K.set_value(self.model.optimizer.lr, self.base_lr)\n",
        "        else:\n",
        "            K.set_value(self.model.optimizer.lr, self.clr())\n",
        "\n",
        "    def on_batch_end(self, epoch, logs=None):\n",
        "\n",
        "        logs = logs or {}\n",
        "        self.trn_iterations += 1\n",
        "        self.clr_iterations += 1\n",
        "        K.set_value(self.model.optimizer.lr, self.clr())\n",
        "\n",
        "        self.history.setdefault(\n",
        "            'lr', []).append(\n",
        "            K.get_value(\n",
        "                self.model.optimizer.lr))\n",
        "        self.history.setdefault('iterations', []).append(self.trn_iterations)\n",
        "\n",
        "        for k, v in logs.items():\n",
        "            self.history.setdefault(k, []).append(v)\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        logs = logs or {}\n",
        "        logs['lr'] = K.get_value(self.model.optimizer.lr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oqaq-voYY8zZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_train_generator(df, image_dir, x_col, y_cols, shuffle=True, batch_size=8, seed=1, target_w = 200, target_h =200):\n",
        "    \"\"\"\n",
        "    Return generator for training set, normalizing using batch\n",
        "    statistics.\n",
        "\n",
        "    Args:\n",
        "      train_df (dataframe): dataframe specifying training data.\n",
        "      image_dir (str): directory where image files are held.\n",
        "      x_col (str): name of column in df that holds filenames.\n",
        "      y_cols (list): list of strings that hold y labels for images.\n",
        "      sample_size (int): size of sample to use for normalization statistics.\n",
        "      batch_size (int): images per batch to be fed into model during training.\n",
        "      seed (int): random seed.\n",
        "      target_w (int): final width of input images.\n",
        "      target_h (int): final height of input images.\n",
        "    \n",
        "    Returns:\n",
        "        train_generator (DataFrameIterator): iterator over training set\n",
        "    \"\"\"        \n",
        "    print(\"getting train generator...\") \n",
        "    # normalize images\n",
        "    image_generator = ImageDataGenerator(\n",
        "        samplewise_center=True,\n",
        "        samplewise_std_normalization= True)\n",
        "    \n",
        "    # flow from directory with specified batch size\n",
        "    # and target image size\n",
        "    generator = image_generator.flow_from_dataframe(\n",
        "            dataframe=df,\n",
        "            directory=image_dir,\n",
        "            x_col=x_col,\n",
        "            y_col=y_cols,\n",
        "            class_mode=\"raw\",\n",
        "            batch_size=batch_size,\n",
        "            shuffle=shuffle,\n",
        "            seed=seed,\n",
        "            target_size=(target_w,target_h))\n",
        "    \n",
        "    return generator\n",
        "\n",
        "def get_test_and_valid_generator(valid_df, test_df, train_df, image_dir, x_col, y_cols, sample_size=100, batch_size=8, seed=1, target_w = 200, target_h = 200):\n",
        "    \"\"\"\n",
        "    Return generator for validation set and test test set using \n",
        "    normalization statistics from training set.\n",
        "\n",
        "    Args:\n",
        "      valid_df (dataframe): dataframe specifying validation data.\n",
        "      test_df (dataframe): dataframe specifying test data.\n",
        "      train_df (dataframe): dataframe specifying training data.\n",
        "      image_dir (str): directory where image files are held.\n",
        "      x_col (str): name of column in df that holds filenames.\n",
        "      y_cols (list): list of strings that hold y labels for images.\n",
        "      sample_size (int): size of sample to use for normalization statistics.\n",
        "      batch_size (int): images per batch to be fed into model during training.\n",
        "      seed (int): random seed.\n",
        "      target_w (int): final width of input images.\n",
        "      target_h (int): final height of input images.\n",
        "    \n",
        "    Returns:\n",
        "        test_generator (DataFrameIterator) and valid_generator: iterators over test set and validation set respectively\n",
        "    \"\"\"\n",
        "    print(\"getting train and valid generators...\")\n",
        "    # get generator to sample dataset\n",
        "    raw_train_generator = ImageDataGenerator().flow_from_dataframe(\n",
        "        dataframe=train_df, \n",
        "        directory=IMG_DIR, \n",
        "        x_col=\"Source\", \n",
        "        y_col=labels, \n",
        "        class_mode=\"raw\", \n",
        "        batch_size=sample_size, \n",
        "        shuffle=True, \n",
        "        target_size=(target_w, target_h))\n",
        "    \n",
        "    # get data sample\n",
        "    batch = raw_train_generator.next()\n",
        "    data_sample = batch[0]\n",
        "\n",
        "    # use sample to fit mean and std for test set generator\n",
        "    image_generator = ImageDataGenerator(\n",
        "        featurewise_center=True,\n",
        "        featurewise_std_normalization= True)\n",
        "    \n",
        "    # fit generator to sample from training data\n",
        "    image_generator.fit(data_sample)\n",
        "\n",
        "    # get test generator\n",
        "    valid_generator = image_generator.flow_from_dataframe(\n",
        "            dataframe=valid_df,\n",
        "            directory=image_dir,\n",
        "            x_col=x_col,\n",
        "            y_col=y_cols,\n",
        "            class_mode=\"raw\",\n",
        "            batch_size=batch_size,\n",
        "            shuffle=False,\n",
        "            seed=seed,\n",
        "            target_size=(target_w,target_h))\n",
        "\n",
        "    test_generator = image_generator.flow_from_dataframe(\n",
        "            dataframe=test_df,\n",
        "            directory=image_dir,\n",
        "            x_col=x_col,\n",
        "            y_col=y_cols,\n",
        "            class_mode=\"raw\",\n",
        "            batch_size=batch_size,\n",
        "            shuffle=False,\n",
        "            seed=seed,\n",
        "            target_size=(target_w,target_h))\n",
        "    return valid_generator, test_generator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DbCG_JwZJSd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_weighted_loss(pos_weights, neg_weights, epsilon=1e-7):\n",
        "    \"\"\"\n",
        "    Return weighted loss function given negative weights and positive weights.\n",
        "\n",
        "    Args:\n",
        "      pos_weights (np.array): array of positive weights for each class, size (num_classes)\n",
        "      neg_weights (np.array): array of negative weights for each class, size (num_classes)\n",
        "    \n",
        "    Returns:\n",
        "      weighted_loss (function): weighted loss function\n",
        "    \"\"\"\n",
        "    def weighted_loss(y_true, y_pred):\n",
        "        \"\"\"\n",
        "        Return weighted loss value. \n",
        "\n",
        "        Args:\n",
        "            y_true (Tensor): Tensor of true labels, size is (num_examples, num_classes)\n",
        "            y_pred (Tensor): Tensor of predicted labels, size is (num_examples, num_classes)\n",
        "        Returns:\n",
        "            loss (Tensor): overall scalar loss summed across all classes\n",
        "        \"\"\"\n",
        "        # initialize loss to zero\n",
        "        loss = 0.0\n",
        "        \n",
        "\n",
        "        for i in range(len(pos_weights)):\n",
        "            # for each class, add average weighted loss for that class \n",
        "            loss += -K.mean(pos_weights[i]*y_true[:,i]*K.log(y_pred[:,i]+epsilon) + neg_weights[i]*(1-y_true[:,i])*K.log(1-y_pred[:,i]+epsilon)) \n",
        "        return loss\n",
        "    return weighted_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmB--NUoZ_Jj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_class_freqs(labels):\n",
        "    \"\"\"\n",
        "    Compute positive and negative frequences for each class.\n",
        "\n",
        "    Args:\n",
        "        labels (np.array): matrix of labels, size (num_examples, num_classes)\n",
        "    Returns:\n",
        "        positive_frequencies (np.array): array of positive frequences for each\n",
        "                                         class, size (num_classes)\n",
        "        negative_frequencies (np.array): array of negative frequences for each\n",
        "                                         class, size (num_classes)\n",
        "    \"\"\"\n",
        "    ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\n",
        "    \n",
        "    # total number of patients (rows)\n",
        "    N = labels.shape[0]\n",
        "    \n",
        "    positive_frequencies = np.sum(labels,axis=0)/N\n",
        "    negative_frequencies = np.ones_like(positive_frequencies) - positive_frequencies\n",
        "\n",
        "    ### END CODE HERE ###\n",
        "    return positive_frequencies, negative_frequencies"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5gQeeYEaBGH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LRFinder:\n",
        "    \"\"\"\n",
        "    Plots the change of the loss function of a Keras model when the learning rate is exponentially increasing.\n",
        "    See for details:\n",
        "    https://towardsdatascience.com/estimating-optimal-learning-rate-for-a-deep-neural-network-ce32f2556ce0\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "        self.losses = []\n",
        "        self.lrs = []\n",
        "        self.best_loss = 1e9\n",
        "\n",
        "    def on_batch_end(self, batch, logs):\n",
        "        # Log the learning rate\n",
        "        lr = K.get_value(self.model.optimizer.learning_rate)\n",
        "        self.lrs.append(lr)\n",
        "\n",
        "        # Log the loss\n",
        "        loss = logs['loss']\n",
        "        self.losses.append(loss)\n",
        "\n",
        "        # Check whether the loss got too large or NaN\n",
        "        if batch > 5 and (math.isnan(loss) or loss > self.best_loss * 4):\n",
        "            self.model.stop_training = True\n",
        "            return\n",
        "\n",
        "        if loss < self.best_loss:\n",
        "            self.best_loss = loss\n",
        "\n",
        "        # Increase the learning rate for the next batch\n",
        "        lr *= self.lr_mult\n",
        "        K.set_value(self.model.optimizer.learning_rate, lr)\n",
        "\n",
        "    def find(self, x_train, y_train, start_lr, end_lr, batch_size=64, epochs=1):\n",
        "        # If x_train contains data for multiple inputs, use length of the first input.\n",
        "        # Assumption: the first element in the list is single input; NOT a list of inputs.\n",
        "        N = x_train[0].shape[0] if isinstance(x_train, list) else x_train.shape[0]\n",
        "\n",
        "        # Compute number of batches and LR multiplier\n",
        "        num_batches = epochs * N / batch_size\n",
        "        self.lr_mult = (float(end_lr) / float(start_lr)) ** (float(1) / float(num_batches))\n",
        "        # Save weights into a file\n",
        "        self.model.save_weights('tmp.h5')\n",
        "\n",
        "        # Remember the original learning rate\n",
        "        original_lr = K.get_value(self.model.optimizer.learning_rate)\n",
        "\n",
        "        # Set the initial learning rate\n",
        "        K.set_value(self.model.optimizer.learning_rate, start_lr)\n",
        "\n",
        "        self.model.fit(x_train, y_train,\n",
        "                       batch_size=batch_size, epochs=epochs,\n",
        "                       callbacks=[LambdaCallback(on_batch_end=lambda batch, logs: self.on_batch_end(batch, logs))])\n",
        "\n",
        "        # Restore the weights to the state before model fitting\n",
        "        self.model.load_weights('tmp.h5')\n",
        "\n",
        "        # Restore the original learning rate\n",
        "        K.set_value(self.model.optimizer.learning_rate, original_lr)\n",
        "\n",
        "    def find_generator(self, generator, start_lr, end_lr, epochs=1, steps_per_epoch=None, **kw_fit):\n",
        "        if steps_per_epoch is None:\n",
        "            try:\n",
        "                steps_per_epoch = len(generator)\n",
        "            except (ValueError, NotImplementedError) as e:\n",
        "                raise e('`steps_per_epoch=None` is only valid for a'\n",
        "                        ' generator based on the '\n",
        "                        '`keras.utils.Sequence`'\n",
        "                        ' class. Please specify `steps_per_epoch` '\n",
        "                        'or use the `keras.utils.Sequence` class.')\n",
        "        self.lr_mult = (float(end_lr) / float(start_lr)) ** (float(1) / float(epochs * steps_per_epoch))\n",
        "\n",
        "        # Save weights into a file\n",
        "        self.model.save_weights('tmp.h5')\n",
        "\n",
        "        # Remember the original learning rate\n",
        "        original_lr = K.get_value(self.model.optimizer.learning_rate)\n",
        "\n",
        "        # Set the initial learning rate\n",
        "        K.set_value(self.model.optimizer.learning_rate, start_lr)\n",
        "\n",
        "\n",
        "        self.model.fit_generator(generator=generator,\n",
        "                                 epochs=epochs,\n",
        "                                 steps_per_epoch=steps_per_epoch,\n",
        "                                 callbacks=[ LambdaCallback(on_batch_end=lambda batch,\n",
        "                                                      logs: self.on_batch_end(batch, logs))],\n",
        "                                 **kw_fit)\n",
        "\n",
        "        # Restore the weights to the state before model fitting\n",
        "        self.model.load_weights('tmp.h5')\n",
        "\n",
        "        # Restore the original learning rate\n",
        "        K.set_value(self.model.optimizer.learning_rate, original_lr)\n",
        "\n",
        "    def plot_loss(self, n_skip_beginning=10, n_skip_end=5, x_scale='log'):\n",
        "        \"\"\"\n",
        "        Plots the loss.\n",
        "        Parameters:\n",
        "            n_skip_beginning - number of batches to skip on the left.\n",
        "            n_skip_end - number of batches to skip on the right.\n",
        "        \"\"\"\n",
        "        plt.ylabel(\"loss\")\n",
        "        plt.xlabel(\"learning rate (log scale)\")\n",
        "        plt.plot(self.lrs[n_skip_beginning:-n_skip_end], self.losses[n_skip_beginning:-n_skip_end])\n",
        "        plt.xscale(x_scale)\n",
        "        plt.show()\n",
        "\n",
        "    def plot_loss_change(self, sma=1, n_skip_beginning=10, n_skip_end=5, y_lim=(-0.01, 0.01)):\n",
        "        \"\"\"\n",
        "        Plots rate of change of the loss function.\n",
        "        Parameters:\n",
        "            sma - number of batches for simple moving average to smooth out the curve.\n",
        "            n_skip_beginning - number of batches to skip on the left.\n",
        "            n_skip_end - number of batches to skip on the right.\n",
        "            y_lim - limits for the y axis.\n",
        "        \"\"\"\n",
        "        derivatives = self.get_derivatives(sma)[n_skip_beginning:-n_skip_end]\n",
        "        lrs = self.lrs[n_skip_beginning:-n_skip_end]\n",
        "        plt.ylabel(\"rate of loss change\")\n",
        "        plt.xlabel(\"learning rate (log scale)\")\n",
        "        plt.plot(lrs, derivatives)\n",
        "        plt.xscale('log')\n",
        "        plt.ylim(y_lim)\n",
        "        plt.show()\n",
        "\n",
        "    def get_derivatives(self, sma):\n",
        "        assert sma >= 1\n",
        "        derivatives = [0] * sma\n",
        "        for i in range(sma, len(self.lrs)):\n",
        "            derivatives.append((self.losses[i] - self.losses[i - sma]) / sma)\n",
        "        return derivatives\n",
        "\n",
        "    def get_best_lr(self, sma, n_skip_beginning=10, n_skip_end=5):\n",
        "        derivatives = self.get_derivatives(sma)\n",
        "        best_der_idx = np.argmax(derivatives[n_skip_beginning:-n_skip_end])[0]\n",
        "        return self.lrs[n_skip_beginning:-n_skip_end][best_der_idx]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2LE5mY4bzhb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def find_lr(model_parm, data,epochs):\n",
        "  X_batch, y_batch = next(data)\n",
        "  X_idxs_resampled, _ = RandomUnderSampler().fit_resample(\n",
        "      np.asarray(range(len(X_batch)))[:, np.newaxis], \n",
        "      y_batch)\n",
        "  X_batch, y_batch = X_batch[X_idxs_resampled[:, 0]], y_batch[X_idxs_resampled[:, 0]]\n",
        "  print(X_batch.shape)\n",
        "  lr_finder = LRFinder(model_parm)\n",
        "  lr_finder.find(X_batch, y_batch, start_lr=1e-20, end_lr=1e+5, batch_size=16, epochs=epochs)\n",
        "  return lr_finder.plot_loss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUs7frUFmsNo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_model_name(k):\n",
        "    return 'model_{}.h5'.format(k)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QdrRCDlaZSW",
        "colab_type": "text"
      },
      "source": [
        "# **DATA HANDLING**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fF9MiQbkacuk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df = pd.read_excel('/content/drive/My Drive/Files-Covid/train.xlsx')\n",
        "test_df = pd.read_excel('/content/drive/My Drive/Files-Covid/test.xlsx')\n",
        "valid_df = pd.read_excel('/content/drive/My Drive/Files-Covid/valid.xlsx')\n",
        "labels = ['Covid']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orXIBD17alq8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "9236f9a9-374f-47bd-e500-32e44dc0b6bc"
      },
      "source": [
        "IMG_DIR = \"/content/drive/My Drive/Files-Covid/IMG_DIR/\"\n",
        "train_generator_96 = get_train_generator(train_df, IMG_DIR, \"Source\", labels,target_w = 96, target_h = 96)\n",
        "valid_generator_96, test_generator_96= get_test_and_valid_generator(valid_df, test_df, train_df, IMG_DIR, \"Source\", labels, target_w = 96, target_h = 96)\n",
        "\n",
        "train_generator_192 = get_train_generator(train_df, IMG_DIR, \"Source\", labels,target_w = 192, target_h = 192)\n",
        "valid_generator_192, test_generator_192= get_test_and_valid_generator(valid_df, test_df, train_df, IMG_DIR, \"Source\", labels, target_w = 192, target_h = 192)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "getting train generator...\n",
            "Found 425 validated image filenames.\n",
            "getting train and valid generators...\n",
            "Found 425 validated image filenames.\n",
            "Found 118 validated image filenames.\n",
            "Found 203 validated image filenames.\n",
            "getting train generator...\n",
            "Found 425 validated image filenames.\n",
            "getting train and valid generators...\n",
            "Found 425 validated image filenames.\n",
            "Found 118 validated image filenames.\n",
            "Found 203 validated image filenames.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hq9koOztanmn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "eadf7864-81e2-4efe-d746-05f465dd377f"
      },
      "source": [
        "freq_pos_96, freq_neg_96 = compute_class_freqs(train_generator_96.labels)\n",
        "freq_pos_192, freq_neg_192 = compute_class_freqs(train_generator_192.labels)\n",
        "print(freq_pos_96)\n",
        "print(freq_neg_96)\n",
        "print(freq_pos_192)\n",
        "print(freq_neg_192)\n",
        "pos_weights_96 = freq_neg_96\n",
        "neg_weights_96 = freq_pos_96\n",
        "pos_contribution = freq_pos_96 * pos_weights_96 \n",
        "neg_contribution = freq_neg_96 * neg_weights_96"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.44941176]\n",
            "[0.55058824]\n",
            "[0.44941176]\n",
            "[0.55058824]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tBaJie6a2x6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "main_df = [train_df,valid_df]\n",
        "main_df = pd.concat(main_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aa3ewqVza71M",
        "colab_type": "text"
      },
      "source": [
        "# **MODEL AND TUNING**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YfdSucUDa-_b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 840
        },
        "outputId": "146fdfd0-0bea-468f-9509-9db88d306d77"
      },
      "source": [
        "learn_96 = VGG16(include_top=False, weights = 'imagenet', input_tensor=Input(shape=(96, 96, 3)))\n",
        "print(learn_96.summary())\n",
        "model = Sequential()\n",
        "model.add(learn_96)\n",
        "model.add(AveragePooling2D())\n",
        "model.add(BatchNormalization())\n",
        "model.add(Flatten())\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(512,activation=relu,kernel_regularizer=l2(0.00001)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(1,activation=sigmoid))\n",
        "\n",
        "for cnn_block_layer in learn_96.layers:\n",
        "    cnn_block_layer.trainable = False\n",
        "\n",
        "model.compile(optimizer=Adam(),\n",
        "              loss=get_weighted_loss(pos_weights_96,neg_weights_96),\n",
        "              metrics=['accuracy',AUC()])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 1s 0us/step\n",
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 96, 96, 3)]       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 96, 96, 64)        1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 96, 96, 64)        36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 48, 48, 64)        0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 48, 48, 128)       73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 48, 48, 128)       147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 24, 24, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 24, 24, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 24, 24, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 24, 24, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 12, 12, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 12, 12, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 12, 12, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 12, 12, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 6, 6, 512)         0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 3, 3, 512)         0         \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bEa1tc9cupC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clr = CyclicLR(base_lr=1e-4, max_lr=1e-2,\n",
        "                    step_size=1000., mode='triangular')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bt-ODivkdHkH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_indexes = list(main_df['Source'])\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1. / 255,\n",
        ")\n",
        "valid_datagen = ImageDataGenerator(\n",
        "    rescale=1. / 255\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btaXejcadKhN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "75961e38-32e2-44e5-8c5b-2cd898db4088"
      },
      "source": [
        "VALIDATION_ACCURACY = []\n",
        "VALIDAITON_LOSS = []\n",
        "kfold = KFold(n_splits=10, shuffle=True)\n",
        "save_model = '/content/drive/My Drive/Files-Covid/'\n",
        "fold_var = 1\n",
        "for train_index,val_index in kfold.split(img_indexes):\n",
        "  traindf = main_df.iloc[train_index, :].reset_index()\n",
        "  validdf = main_df.iloc[val_index, :].reset_index()\n",
        "  train_generator = train_datagen.flow_from_dataframe(dataframe=traindf,\n",
        "                                                    directory=IMG_DIR,\n",
        "                                                    x_col=\"Source\",\n",
        "                                                    y_col=\"Covid\",\n",
        "                                                    class_mode=\"raw\",\n",
        "                                                    target_size=(96, 96),\n",
        "                                                    batch_size=16)\n",
        "\n",
        "  valid_generator = valid_datagen.flow_from_dataframe(dataframe=validdf,\n",
        "                                                    directory=IMG_DIR,\n",
        "                                                    x_col=\"Source\",\n",
        "                                                    y_col=\"Covid\",\n",
        "                                                    class_mode=\"raw\",\n",
        "                                                    target_size=(96, 96),\n",
        "                                                    batch_size=16)\n",
        "  history = model.fit_generator(train_generator, \n",
        "                              validation_data=valid_generator,\n",
        "                              steps_per_epoch=len(train_df.index)/16, \n",
        "                              validation_steps=len(valid_df.index)/16, \n",
        "                              epochs = 20,\n",
        "                              verbose=1,\n",
        "                              callbacks = [EarlyStopping(monitor='val_loss',mode='min',patience=4,verbose=1,restore_best_weights = True),ModelCheckpoint(filepath='/content/drive/My Drive/Files-Covid/model_96_{}.h5'.format(fold_var), save_best_only=True, monitor='val_accuracy', mode='max'),clr])\n",
        "  # model.load_weights('/content/drive/My Drive/Files-Covid/model_96_{}.h5'.format(fold_var))\n",
        "\n",
        "  # results = model.evaluate_generator(valid_generator)\n",
        "  # results = dict(zip(model.metrics_names,results))\n",
        "\n",
        "  # VALIDATION_ACCURACY.append(results['accuracy'])\n",
        "  # VALIDATION_LOSS.append(results['loss'])\n",
        "\n",
        "  fold_var += 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 488 validated image filenames.\n",
            "Found 55 validated image filenames.\n",
            "WARNING:tensorflow:From <ipython-input-16-e9e0ab4b46d6>:30: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            "Epoch 1/20\n",
            "27/26 [==============================] - 147s 5s/step - loss: 0.4622 - accuracy: 0.5579 - auc: 0.5587 - val_loss: 0.3333 - val_accuracy: 0.6182 - val_auc: 0.7812 - lr: 3.6730e-04\n",
            "Epoch 2/20\n",
            "27/26 [==============================] - 17s 616ms/step - loss: 0.3256 - accuracy: 0.6840 - auc: 0.7570 - val_loss: 0.3100 - val_accuracy: 0.6818 - val_auc: 0.7900 - lr: 6.3460e-04\n",
            "Epoch 3/20\n",
            "27/26 [==============================] - 5s 168ms/step - loss: 0.2641 - accuracy: 0.7547 - auc: 0.8376 - val_loss: 0.2948 - val_accuracy: 0.7273 - val_auc: 0.7838 - lr: 9.0190e-04\n",
            "Epoch 4/20\n",
            "27/26 [==============================] - 4s 152ms/step - loss: 0.2166 - accuracy: 0.8113 - auc: 0.8920 - val_loss: 0.2791 - val_accuracy: 0.7909 - val_auc: 0.8232 - lr: 0.0012\n",
            "Epoch 5/20\n",
            "27/26 [==============================] - 4s 141ms/step - loss: 0.2377 - accuracy: 0.8042 - auc: 0.8792 - val_loss: 0.2560 - val_accuracy: 0.7636 - val_auc: 0.8720 - lr: 0.0014\n",
            "Epoch 6/20\n",
            "27/26 [==============================] - 5s 175ms/step - loss: 0.2237 - accuracy: 0.7925 - auc: 0.8885 - val_loss: 0.2164 - val_accuracy: 0.8818 - val_auc: 0.9134 - lr: 0.0017\n",
            "Epoch 7/20\n",
            "27/26 [==============================] - 4s 142ms/step - loss: 0.2228 - accuracy: 0.8066 - auc: 0.8974 - val_loss: 0.2676 - val_accuracy: 0.7909 - val_auc: 0.8362 - lr: 0.0020\n",
            "Epoch 8/20\n",
            "27/26 [==============================] - 4s 150ms/step - loss: 0.1851 - accuracy: 0.8657 - auc: 0.9248 - val_loss: 0.2399 - val_accuracy: 0.8000 - val_auc: 0.8724 - lr: 0.0022\n",
            "Epoch 9/20\n",
            "27/26 [==============================] - 4s 161ms/step - loss: 0.1506 - accuracy: 0.8986 - auc: 0.9496 - val_loss: 0.2093 - val_accuracy: 0.8364 - val_auc: 0.9038 - lr: 0.0025\n",
            "Epoch 10/20\n",
            "27/26 [==============================] - 4s 151ms/step - loss: 0.1766 - accuracy: 0.8420 - auc: 0.9309 - val_loss: 0.2156 - val_accuracy: 0.8182 - val_auc: 0.8915 - lr: 0.0028\n",
            "Epoch 11/20\n",
            "27/26 [==============================] - 4s 144ms/step - loss: 0.1737 - accuracy: 0.8561 - auc: 0.9357 - val_loss: 0.2371 - val_accuracy: 0.7909 - val_auc: 0.8702 - lr: 0.0030\n",
            "Epoch 12/20\n",
            "27/26 [==============================] - 4s 141ms/step - loss: 0.1984 - accuracy: 0.8278 - auc: 0.9192 - val_loss: 0.2678 - val_accuracy: 0.8000 - val_auc: 0.8375 - lr: 0.0033\n",
            "Epoch 13/20\n",
            "27/26 [==============================] - ETA: 0s - loss: 0.1614 - accuracy: 0.8750 - auc: 0.9420Restoring model weights from the end of the best epoch.\n",
            "27/26 [==============================] - 4s 153ms/step - loss: 0.1614 - accuracy: 0.8750 - auc: 0.9420 - val_loss: 0.2619 - val_accuracy: 0.7636 - val_auc: 0.8594 - lr: 0.0036\n",
            "Epoch 00013: early stopping\n",
            "Found 488 validated image filenames.\n",
            "Found 55 validated image filenames.\n",
            "Epoch 1/20\n",
            "27/26 [==============================] - 8s 286ms/step - loss: 0.1995 - accuracy: 0.8310 - auc: 0.9216 - val_loss: 0.1649 - val_accuracy: 0.9091 - val_auc: 0.9676 - lr: 0.0038\n",
            "Epoch 2/20\n",
            "27/26 [==============================] - 4s 151ms/step - loss: 0.1970 - accuracy: 0.8373 - auc: 0.9196 - val_loss: 0.2383 - val_accuracy: 0.7818 - val_auc: 0.8480 - lr: 0.0041\n",
            "Epoch 3/20\n",
            "27/26 [==============================] - 4s 139ms/step - loss: 0.2100 - accuracy: 0.8255 - auc: 0.9127 - val_loss: 0.3000 - val_accuracy: 0.6909 - val_auc: 0.8263 - lr: 0.0044\n",
            "Epoch 4/20\n",
            "27/26 [==============================] - 4s 159ms/step - loss: 0.1668 - accuracy: 0.8608 - auc: 0.9385 - val_loss: 0.2291 - val_accuracy: 0.7545 - val_auc: 0.8702 - lr: 0.0046\n",
            "Epoch 5/20\n",
            "27/26 [==============================] - ETA: 0s - loss: 0.2055 - accuracy: 0.8538 - auc: 0.9170Restoring model weights from the end of the best epoch.\n",
            "27/26 [==============================] - 4s 139ms/step - loss: 0.2055 - accuracy: 0.8538 - auc: 0.9170 - val_loss: 0.1907 - val_accuracy: 0.7818 - val_auc: 0.9187 - lr: 0.0049\n",
            "Epoch 00005: early stopping\n",
            "Found 488 validated image filenames.\n",
            "Found 55 validated image filenames.\n",
            "Epoch 1/20\n",
            "27/26 [==============================] - 8s 292ms/step - loss: 0.2358 - accuracy: 0.8241 - auc: 0.8930 - val_loss: 0.1339 - val_accuracy: 0.9455 - val_auc: 0.9715 - lr: 0.0052\n",
            "Epoch 2/20\n",
            "27/26 [==============================] - 4s 143ms/step - loss: 0.2126 - accuracy: 0.8443 - auc: 0.9056 - val_loss: 0.2208 - val_accuracy: 0.8182 - val_auc: 0.8964 - lr: 0.0054\n",
            "Epoch 3/20\n",
            "27/26 [==============================] - 4s 140ms/step - loss: 0.2197 - accuracy: 0.8208 - auc: 0.9038 - val_loss: 0.1192 - val_accuracy: 0.9455 - val_auc: 0.9897 - lr: 0.0057\n",
            "Epoch 4/20\n",
            "27/26 [==============================] - 4s 149ms/step - loss: 0.1761 - accuracy: 0.8538 - auc: 0.9362 - val_loss: 0.1421 - val_accuracy: 0.8727 - val_auc: 0.9711 - lr: 0.0060\n",
            "Epoch 5/20\n",
            "27/26 [==============================] - 4s 141ms/step - loss: 0.1901 - accuracy: 0.8420 - auc: 0.9271 - val_loss: 0.1566 - val_accuracy: 0.8364 - val_auc: 0.9389 - lr: 0.0062\n",
            "Epoch 6/20\n",
            "27/26 [==============================] - 4s 140ms/step - loss: 0.1678 - accuracy: 0.8679 - auc: 0.9441 - val_loss: 0.1410 - val_accuracy: 0.9000 - val_auc: 0.9617 - lr: 0.0065\n",
            "Epoch 7/20\n",
            "27/26 [==============================] - ETA: 0s - loss: 0.1906 - accuracy: 0.8467 - auc: 0.9337Restoring model weights from the end of the best epoch.\n",
            "27/26 [==============================] - 4s 141ms/step - loss: 0.1906 - accuracy: 0.8467 - auc: 0.9337 - val_loss: 0.1848 - val_accuracy: 0.8455 - val_auc: 0.9253 - lr: 0.0068\n",
            "Epoch 00007: early stopping\n",
            "Found 489 validated image filenames.\n",
            "Found 54 validated image filenames.\n",
            "Epoch 1/20\n",
            "27/26 [==============================] - 7s 243ms/step - loss: 0.1939 - accuracy: 0.8403 - auc: 0.9226 - val_loss: 0.1645 - val_accuracy: 0.8333 - val_auc: 0.9462 - lr: 0.0070\n",
            "Epoch 2/20\n",
            "27/26 [==============================] - 4s 155ms/step - loss: 0.1947 - accuracy: 0.8518 - auc: 0.9235 - val_loss: 0.1900 - val_accuracy: 0.8241 - val_auc: 0.9260 - lr: 0.0073\n",
            "Epoch 3/20\n",
            "27/26 [==============================] - 4s 158ms/step - loss: 0.1959 - accuracy: 0.8729 - auc: 0.9292 - val_loss: 0.1632 - val_accuracy: 0.8889 - val_auc: 0.9478 - lr: 0.0076\n",
            "Epoch 4/20\n",
            "27/26 [==============================] - 4s 146ms/step - loss: 0.1999 - accuracy: 0.8376 - auc: 0.9230 - val_loss: 0.2460 - val_accuracy: 0.6944 - val_auc: 0.8490 - lr: 0.0079\n",
            "Epoch 5/20\n",
            "27/26 [==============================] - 4s 148ms/step - loss: 0.1659 - accuracy: 0.8824 - auc: 0.9469 - val_loss: 0.2657 - val_accuracy: 0.7963 - val_auc: 0.9076 - lr: 0.0081\n",
            "Epoch 6/20\n",
            "27/26 [==============================] - 4s 142ms/step - loss: 0.1942 - accuracy: 0.8518 - auc: 0.9369 - val_loss: 0.2261 - val_accuracy: 0.8426 - val_auc: 0.9180 - lr: 0.0084\n",
            "Epoch 7/20\n",
            "27/26 [==============================] - ETA: 0s - loss: 0.1835 - accuracy: 0.8706 - auc: 0.9419Restoring model weights from the end of the best epoch.\n",
            "27/26 [==============================] - 4s 139ms/step - loss: 0.1835 - accuracy: 0.8706 - auc: 0.9419 - val_loss: 0.3732 - val_accuracy: 0.6574 - val_auc: 0.8331 - lr: 0.0087\n",
            "Epoch 00007: early stopping\n",
            "Found 489 validated image filenames.\n",
            "Found 54 validated image filenames.\n",
            "Epoch 1/20\n",
            "27/26 [==============================] - 6s 238ms/step - loss: 0.1970 - accuracy: 0.8634 - auc: 0.9257 - val_loss: 0.1519 - val_accuracy: 0.8889 - val_auc: 0.9505 - lr: 0.0089\n",
            "Epoch 2/20\n",
            "27/26 [==============================] - 4s 141ms/step - loss: 0.2027 - accuracy: 0.8471 - auc: 0.9258 - val_loss: 0.1778 - val_accuracy: 0.8889 - val_auc: 0.9454 - lr: 0.0092\n",
            "Epoch 3/20\n",
            "27/26 [==============================] - 4s 147ms/step - loss: 0.2042 - accuracy: 0.8706 - auc: 0.9342 - val_loss: 0.2080 - val_accuracy: 0.8704 - val_auc: 0.9269 - lr: 0.0095\n",
            "Epoch 4/20\n",
            "27/26 [==============================] - 4s 145ms/step - loss: 0.2079 - accuracy: 0.8329 - auc: 0.9237 - val_loss: 0.2340 - val_accuracy: 0.8426 - val_auc: 0.9141 - lr: 0.0097\n",
            "Epoch 5/20\n",
            "27/26 [==============================] - 4s 146ms/step - loss: 0.1886 - accuracy: 0.8824 - auc: 0.9426 - val_loss: 0.1508 - val_accuracy: 0.8889 - val_auc: 0.9560 - lr: 0.0100\n",
            "Epoch 6/20\n",
            "27/26 [==============================] - 4s 142ms/step - loss: 0.1721 - accuracy: 0.8776 - auc: 0.9502 - val_loss: 0.2387 - val_accuracy: 0.8148 - val_auc: 0.9111 - lr: 0.0097\n",
            "Epoch 7/20\n",
            "27/26 [==============================] - 4s 145ms/step - loss: 0.2038 - accuracy: 0.8588 - auc: 0.9366 - val_loss: 0.2471 - val_accuracy: 0.7222 - val_auc: 0.8949 - lr: 0.0095\n",
            "Epoch 8/20\n",
            "27/26 [==============================] - 4s 143ms/step - loss: 0.1748 - accuracy: 0.8681 - auc: 0.9504 - val_loss: 0.2047 - val_accuracy: 0.8241 - val_auc: 0.9348 - lr: 0.0092\n",
            "Epoch 9/20\n",
            "27/26 [==============================] - ETA: 0s - loss: 0.1785 - accuracy: 0.8824 - auc: 0.9537Restoring model weights from the end of the best epoch.\n",
            "27/26 [==============================] - 4s 155ms/step - loss: 0.1785 - accuracy: 0.8824 - auc: 0.9537 - val_loss: 0.3608 - val_accuracy: 0.7778 - val_auc: 0.8468 - lr: 0.0089\n",
            "Epoch 00009: early stopping\n",
            "Found 489 validated image filenames.\n",
            "Found 54 validated image filenames.\n",
            "Epoch 1/20\n",
            "27/26 [==============================] - 8s 309ms/step - loss: 0.2178 - accuracy: 0.8449 - auc: 0.9229 - val_loss: 0.0969 - val_accuracy: 0.9444 - val_auc: 0.9945 - lr: 0.0087\n",
            "Epoch 2/20\n",
            "27/26 [==============================] - 4s 156ms/step - loss: 0.1880 - accuracy: 0.8588 - auc: 0.9418 - val_loss: 0.0948 - val_accuracy: 0.9444 - val_auc: 0.9966 - lr: 0.0084\n",
            "Epoch 3/20\n",
            "27/26 [==============================] - 6s 220ms/step - loss: 0.1648 - accuracy: 0.8918 - auc: 0.9552 - val_loss: 0.0934 - val_accuracy: 0.9722 - val_auc: 0.9993 - lr: 0.0081\n",
            "Epoch 4/20\n",
            "27/26 [==============================] - 4s 153ms/step - loss: 0.1807 - accuracy: 0.8847 - auc: 0.9460 - val_loss: 0.1443 - val_accuracy: 0.9167 - val_auc: 0.9759 - lr: 0.0079\n",
            "Epoch 5/20\n",
            "27/26 [==============================] - 4s 145ms/step - loss: 0.1501 - accuracy: 0.9059 - auc: 0.9663 - val_loss: 0.1376 - val_accuracy: 0.8889 - val_auc: 0.9834 - lr: 0.0076\n",
            "Epoch 6/20\n",
            "27/26 [==============================] - 4s 153ms/step - loss: 0.1525 - accuracy: 0.9106 - auc: 0.9639 - val_loss: 0.1252 - val_accuracy: 0.9630 - val_auc: 0.9818 - lr: 0.0073\n",
            "Epoch 7/20\n",
            "27/26 [==============================] - 4s 150ms/step - loss: 0.1498 - accuracy: 0.9012 - auc: 0.9654 - val_loss: 0.0932 - val_accuracy: 0.9444 - val_auc: 0.9937 - lr: 0.0071\n",
            "Epoch 8/20\n",
            "27/26 [==============================] - 4s 147ms/step - loss: 0.1376 - accuracy: 0.9120 - auc: 0.9730 - val_loss: 0.1192 - val_accuracy: 0.9259 - val_auc: 0.9845 - lr: 0.0068\n",
            "Epoch 9/20\n",
            "27/26 [==============================] - 4s 147ms/step - loss: 0.1648 - accuracy: 0.9106 - auc: 0.9598 - val_loss: 0.1367 - val_accuracy: 0.9074 - val_auc: 0.9834 - lr: 0.0065\n",
            "Epoch 10/20\n",
            "27/26 [==============================] - 4s 147ms/step - loss: 0.1041 - accuracy: 0.9459 - auc: 0.9888 - val_loss: 0.1169 - val_accuracy: 0.9167 - val_auc: 0.9884 - lr: 0.0063\n",
            "Epoch 11/20\n",
            "27/26 [==============================] - ETA: 0s - loss: 0.1108 - accuracy: 0.9435 - auc: 0.9850Restoring model weights from the end of the best epoch.\n",
            "27/26 [==============================] - 4s 149ms/step - loss: 0.1108 - accuracy: 0.9435 - auc: 0.9850 - val_loss: 0.1760 - val_accuracy: 0.9074 - val_auc: 0.9794 - lr: 0.0060\n",
            "Epoch 00011: early stopping\n",
            "Found 489 validated image filenames.\n",
            "Found 54 validated image filenames.\n",
            "Epoch 1/20\n",
            "27/26 [==============================] - 7s 244ms/step - loss: 0.1296 - accuracy: 0.9213 - auc: 0.9765 - val_loss: 0.0690 - val_accuracy: 0.9815 - val_auc: 0.9985 - lr: 0.0057\n",
            "Epoch 2/20\n",
            "27/26 [==============================] - 4s 152ms/step - loss: 0.1403 - accuracy: 0.9059 - auc: 0.9734 - val_loss: 0.0715 - val_accuracy: 0.9630 - val_auc: 0.9971 - lr: 0.0055\n",
            "Epoch 3/20\n",
            "27/26 [==============================] - 4s 151ms/step - loss: 0.1476 - accuracy: 0.9106 - auc: 0.9685 - val_loss: 0.0888 - val_accuracy: 0.9167 - val_auc: 0.9945 - lr: 0.0052\n",
            "Epoch 4/20\n",
            "27/26 [==============================] - 4s 153ms/step - loss: 0.1266 - accuracy: 0.9247 - auc: 0.9791 - val_loss: 0.1168 - val_accuracy: 0.9444 - val_auc: 0.9875 - lr: 0.0049\n",
            "Epoch 5/20\n",
            "27/26 [==============================] - ETA: 0s - loss: 0.1203 - accuracy: 0.9341 - auc: 0.9815Restoring model weights from the end of the best epoch.\n",
            "27/26 [==============================] - 4s 150ms/step - loss: 0.1203 - accuracy: 0.9341 - auc: 0.9815 - val_loss: 0.1057 - val_accuracy: 0.9444 - val_auc: 0.9877 - lr: 0.0047\n",
            "Epoch 00005: early stopping\n",
            "Found 489 validated image filenames.\n",
            "Found 54 validated image filenames.\n",
            "Epoch 1/20\n",
            "27/26 [==============================] - 7s 256ms/step - loss: 0.1299 - accuracy: 0.9120 - auc: 0.9781 - val_loss: 0.0882 - val_accuracy: 0.9444 - val_auc: 0.9938 - lr: 0.0044\n",
            "Epoch 2/20\n",
            "27/26 [==============================] - 4s 158ms/step - loss: 0.1391 - accuracy: 0.9176 - auc: 0.9724 - val_loss: 0.1424 - val_accuracy: 0.9537 - val_auc: 0.9571 - lr: 0.0041\n",
            "Epoch 3/20\n",
            "27/26 [==============================] - 4s 167ms/step - loss: 0.1533 - accuracy: 0.9012 - auc: 0.9669 - val_loss: 0.1001 - val_accuracy: 0.9907 - val_auc: 0.9735 - lr: 0.0039\n",
            "Epoch 4/20\n",
            "27/26 [==============================] - 4s 147ms/step - loss: 0.1267 - accuracy: 0.9247 - auc: 0.9778 - val_loss: 0.1015 - val_accuracy: 0.9815 - val_auc: 0.9780 - lr: 0.0036\n",
            "Epoch 5/20\n",
            "27/26 [==============================] - ETA: 0s - loss: 0.1231 - accuracy: 0.9271 - auc: 0.9807Restoring model weights from the end of the best epoch.\n",
            "27/26 [==============================] - 4s 153ms/step - loss: 0.1231 - accuracy: 0.9271 - auc: 0.9807 - val_loss: 0.1221 - val_accuracy: 0.9444 - val_auc: 0.9776 - lr: 0.0033\n",
            "Epoch 00005: early stopping\n",
            "Found 489 validated image filenames.\n",
            "Found 54 validated image filenames.\n",
            "Epoch 1/20\n",
            "27/26 [==============================] - 7s 273ms/step - loss: 0.1347 - accuracy: 0.9282 - auc: 0.9749 - val_loss: 0.0537 - val_accuracy: 1.0000 - val_auc: 1.0000 - lr: 0.0031\n",
            "Epoch 2/20\n",
            "27/26 [==============================] - 4s 148ms/step - loss: 0.1142 - accuracy: 0.9224 - auc: 0.9838 - val_loss: 0.0585 - val_accuracy: 1.0000 - val_auc: 1.0000 - lr: 0.0028\n",
            "Epoch 3/20\n",
            "27/26 [==============================] - 4s 152ms/step - loss: 0.1085 - accuracy: 0.9318 - auc: 0.9862 - val_loss: 0.0586 - val_accuracy: 0.9815 - val_auc: 1.0000 - lr: 0.0025\n",
            "Epoch 4/20\n",
            "27/26 [==============================] - 4s 144ms/step - loss: 0.1222 - accuracy: 0.9294 - auc: 0.9806 - val_loss: 0.0569 - val_accuracy: 1.0000 - val_auc: 1.0000 - lr: 0.0023\n",
            "Epoch 5/20\n",
            "27/26 [==============================] - ETA: 0s - loss: 0.1134 - accuracy: 0.9459 - auc: 0.9829Restoring model weights from the end of the best epoch.\n",
            "27/26 [==============================] - 4s 158ms/step - loss: 0.1134 - accuracy: 0.9459 - auc: 0.9829 - val_loss: 0.0645 - val_accuracy: 0.9815 - val_auc: 1.0000 - lr: 0.0020\n",
            "Epoch 00005: early stopping\n",
            "Found 489 validated image filenames.\n",
            "Found 54 validated image filenames.\n",
            "Epoch 1/20\n",
            "27/26 [==============================] - 7s 265ms/step - loss: 0.1318 - accuracy: 0.9213 - auc: 0.9762 - val_loss: 0.0489 - val_accuracy: 1.0000 - val_auc: 1.0000 - lr: 0.0017\n",
            "Epoch 2/20\n",
            "27/26 [==============================] - 4s 165ms/step - loss: 0.1440 - accuracy: 0.9247 - auc: 0.9697 - val_loss: 0.0485 - val_accuracy: 1.0000 - val_auc: 1.0000 - lr: 0.0015\n",
            "Epoch 3/20\n",
            "27/26 [==============================] - 4s 151ms/step - loss: 0.1122 - accuracy: 0.9271 - auc: 0.9844 - val_loss: 0.0487 - val_accuracy: 1.0000 - val_auc: 1.0000 - lr: 0.0012\n",
            "Epoch 4/20\n",
            "27/26 [==============================] - 4s 163ms/step - loss: 0.1231 - accuracy: 0.9341 - auc: 0.9786 - val_loss: 0.0474 - val_accuracy: 1.0000 - val_auc: 1.0000 - lr: 9.2170e-04\n",
            "Epoch 5/20\n",
            "27/26 [==============================] - 4s 158ms/step - loss: 0.1238 - accuracy: 0.9200 - auc: 0.9798 - val_loss: 0.0476 - val_accuracy: 1.0000 - val_auc: 1.0000 - lr: 6.5440e-04\n",
            "Epoch 6/20\n",
            "27/26 [==============================] - 4s 158ms/step - loss: 0.1001 - accuracy: 0.9506 - auc: 0.9889 - val_loss: 0.0453 - val_accuracy: 1.0000 - val_auc: 1.0000 - lr: 3.8710e-04\n",
            "Epoch 7/20\n",
            "27/26 [==============================] - 4s 156ms/step - loss: 0.0978 - accuracy: 0.9529 - auc: 0.9883 - val_loss: 0.0451 - val_accuracy: 1.0000 - val_auc: 1.0000 - lr: 1.1980e-04\n",
            "Epoch 8/20\n",
            "27/26 [==============================] - 4s 160ms/step - loss: 0.1373 - accuracy: 0.9120 - auc: 0.9722 - val_loss: 0.0449 - val_accuracy: 1.0000 - val_auc: 1.0000 - lr: 3.4750e-04\n",
            "Epoch 9/20\n",
            "27/26 [==============================] - 4s 157ms/step - loss: 0.1220 - accuracy: 0.9341 - auc: 0.9816 - val_loss: 0.0463 - val_accuracy: 1.0000 - val_auc: 1.0000 - lr: 6.1480e-04\n",
            "Epoch 10/20\n",
            "27/26 [==============================] - 4s 156ms/step - loss: 0.1065 - accuracy: 0.9435 - auc: 0.9861 - val_loss: 0.0471 - val_accuracy: 1.0000 - val_auc: 1.0000 - lr: 8.8210e-04\n",
            "Epoch 11/20\n",
            "27/26 [==============================] - 4s 163ms/step - loss: 0.1038 - accuracy: 0.9459 - auc: 0.9875 - val_loss: 0.0469 - val_accuracy: 1.0000 - val_auc: 1.0000 - lr: 0.0011\n",
            "Epoch 12/20\n",
            "27/26 [==============================] - ETA: 0s - loss: 0.0889 - accuracy: 0.9529 - auc: 0.9928Restoring model weights from the end of the best epoch.\n",
            "27/26 [==============================] - 4s 150ms/step - loss: 0.0889 - accuracy: 0.9529 - auc: 0.9928 - val_loss: 0.0459 - val_accuracy: 1.0000 - val_auc: 1.0000 - lr: 0.0014\n",
            "Epoch 00012: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYBf-pmNXFLw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ad8fff5f-ede2-4ea9-b7e2-73876b00d2d7"
      },
      "source": [
        "learn_96.trainable = True\n",
        "len(learn_96.layers)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSorW-kjm4Z4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for layer in learn_96.layers[:13]:\n",
        "  layer.trainable =  False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hjd9YMq4m7kF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer=Adam(),\n",
        "              loss=get_weighted_loss(pos_weights_96,neg_weights_96),\n",
        "              metrics=['accuracy',AUC()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDOJyAWdnBo3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a6198172-73c4-472f-f1c6-2a7b2b4f2cf4"
      },
      "source": [
        "\n",
        "kfold = KFold(n_splits=10, shuffle=True)\n",
        "save_model = '/content/drive/My Drive/Files-Covid/'\n",
        "fold_var = 1\n",
        "for train_index,val_index in kfold.split(img_indexes):\n",
        "  traindf = main_df.iloc[train_index, :].reset_index()\n",
        "  validdf = main_df.iloc[val_index, :].reset_index()\n",
        "  train_generator = train_datagen.flow_from_dataframe(dataframe=traindf,\n",
        "                                                    directory=IMG_DIR,\n",
        "                                                    x_col=\"Source\",\n",
        "                                                    y_col=\"Covid\",\n",
        "                                                    class_mode=\"raw\",\n",
        "                                                    target_size=(96, 96),\n",
        "                                                    batch_size=16)\n",
        "\n",
        "  valid_generator = valid_datagen.flow_from_dataframe(dataframe=validdf,\n",
        "                                                    directory=IMG_DIR,\n",
        "                                                    x_col=\"Source\",\n",
        "                                                    y_col=\"Covid\",\n",
        "                                                    class_mode=\"raw\",\n",
        "                                                    target_size=(96, 96),\n",
        "                                                    batch_size=16)\n",
        "  history = model.fit_generator(train_generator, \n",
        "                              validation_data=valid_generator,\n",
        "                              steps_per_epoch=len(train_df.index)/16, \n",
        "                              validation_steps=len(valid_df.index)/16, \n",
        "                              epochs = 20,\n",
        "                              verbose=1,\n",
        "                              callbacks = [EarlyStopping(monitor='val_loss',mode='min',patience=4,verbose=1,restore_best_weights = True),ModelCheckpoint(filepath='/content/drive/My Drive/Files-Covid/model_96_fine_tune_{}.h5'.format(fold_var), save_best_only=True, monitor='val_accuracy', mode='max'),clr])\n",
        "  # model.load_weights('/content/drive/My Drive/Files-Covid/model_96_{}.h5'.format(fold_var))\n",
        "\n",
        "  # results = model.evaluate_generator(valid_generator)\n",
        "  # results = dict(zip(model.metrics_names,results))\n",
        "\n",
        "  # VALIDATION_ACCURACY.append(results['accuracy'])\n",
        "  # VALIDATION_LOSS.append(results['loss'])\n",
        "\n",
        "  fold_var += 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 488 validated image filenames.\n",
            "Found 55 validated image filenames.\n",
            "Epoch 1/20\n",
            "27/26 [==============================] - 5s 194ms/step - loss: 0.4493 - accuracy: 0.6667 - auc_1: 0.7102 - val_loss: 1.0395 - val_accuracy: 0.5818 - val_auc_1: 0.6386 - lr: 0.0017\n",
            "Epoch 2/20\n",
            "27/26 [==============================] - 4s 159ms/step - loss: 0.4594 - accuracy: 0.6297 - auc_1: 0.6713 - val_loss: 3.7844 - val_accuracy: 0.4727 - val_auc_1: 0.5000 - lr: 0.0020\n",
            "Epoch 3/20\n",
            "27/26 [==============================] - 5s 177ms/step - loss: 0.3899 - accuracy: 0.6840 - auc_1: 0.7511 - val_loss: 3.6781 - val_accuracy: 0.4909 - val_auc_1: 0.5000 - lr: 0.0022\n",
            "Epoch 4/20\n",
            "27/26 [==============================] - 6s 215ms/step - loss: 0.3309 - accuracy: 0.7382 - auc_1: 0.8117 - val_loss: 0.8964 - val_accuracy: 0.6364 - val_auc_1: 0.7315 - lr: 0.0025\n",
            "Epoch 5/20\n",
            "27/26 [==============================] - 4s 159ms/step - loss: 0.3131 - accuracy: 0.7665 - auc_1: 0.8291 - val_loss: 1.5641 - val_accuracy: 0.4909 - val_auc_1: 0.6936 - lr: 0.0028\n",
            "Epoch 6/20\n",
            "27/26 [==============================] - 5s 177ms/step - loss: 0.2477 - accuracy: 0.8349 - auc_1: 0.8961 - val_loss: 0.3469 - val_accuracy: 0.7364 - val_auc_1: 0.8548 - lr: 0.0030\n",
            "Epoch 7/20\n",
            "27/26 [==============================] - 5s 182ms/step - loss: 0.2072 - accuracy: 0.8373 - auc_1: 0.9198 - val_loss: 0.4428 - val_accuracy: 0.8545 - val_auc_1: 0.8830 - lr: 0.0033\n",
            "Epoch 8/20\n",
            "27/26 [==============================] - 4s 155ms/step - loss: 0.1825 - accuracy: 0.8657 - auc_1: 0.9429 - val_loss: 2.7254 - val_accuracy: 0.4818 - val_auc_1: 0.5902 - lr: 0.0036\n",
            "Epoch 9/20\n",
            "27/26 [==============================] - 5s 178ms/step - loss: 0.1583 - accuracy: 0.9057 - auc_1: 0.9590 - val_loss: 1.4385 - val_accuracy: 0.7091 - val_auc_1: 0.7672 - lr: 0.0038\n",
            "Epoch 10/20\n",
            "27/26 [==============================] - ETA: 0s - loss: 0.1856 - accuracy: 0.8679 - auc_1: 0.9423Restoring model weights from the end of the best epoch.\n",
            "27/26 [==============================] - 4s 153ms/step - loss: 0.1856 - accuracy: 0.8679 - auc_1: 0.9423 - val_loss: 1.4470 - val_accuracy: 0.5727 - val_auc_1: 0.7249 - lr: 0.0041\n",
            "Epoch 00010: early stopping\n",
            "Found 488 validated image filenames.\n",
            "Found 55 validated image filenames.\n",
            "Epoch 1/20\n",
            "27/26 [==============================] - 5s 177ms/step - loss: 0.2160 - accuracy: 0.8333 - auc_1: 0.9145 - val_loss: 3.8068 - val_accuracy: 0.4727 - val_auc_1: 0.5000 - lr: 0.0044\n",
            "Epoch 2/20\n",
            "27/26 [==============================] - 5s 178ms/step - loss: 0.1699 - accuracy: 0.8750 - auc_1: 0.9514 - val_loss: 2.2755 - val_accuracy: 0.5636 - val_auc_1: 0.6250 - lr: 0.0046\n",
            "Epoch 3/20\n",
            "27/26 [==============================] - 5s 180ms/step - loss: 0.1510 - accuracy: 0.9198 - auc_1: 0.9679 - val_loss: 1.2833 - val_accuracy: 0.7000 - val_auc_1: 0.7778 - lr: 0.0049\n",
            "Epoch 4/20\n",
            "27/26 [==============================] - 4s 150ms/step - loss: 0.1589 - accuracy: 0.8892 - auc_1: 0.9579 - val_loss: 3.7697 - val_accuracy: 0.5273 - val_auc_1: 0.5000 - lr: 0.0052\n",
            "Epoch 5/20\n",
            "27/26 [==============================] - 4s 161ms/step - loss: 0.1377 - accuracy: 0.9222 - auc_1: 0.9692 - val_loss: 4.2215 - val_accuracy: 0.4364 - val_auc_1: 0.4556 - lr: 0.0054\n",
            "Epoch 6/20\n",
            "27/26 [==============================] - 4s 165ms/step - loss: 0.1253 - accuracy: 0.9222 - auc_1: 0.9763 - val_loss: 3.6665 - val_accuracy: 0.4909 - val_auc_1: 0.5000 - lr: 0.0057\n",
            "Epoch 7/20\n",
            "27/26 [==============================] - ETA: 0s - loss: 0.1104 - accuracy: 0.9245 - auc_1: 0.9839Restoring model weights from the end of the best epoch.\n",
            "27/26 [==============================] - 4s 154ms/step - loss: 0.1104 - accuracy: 0.9245 - auc_1: 0.9839 - val_loss: 4.0002 - val_accuracy: 0.4364 - val_auc_1: 0.5000 - lr: 0.0060\n",
            "Epoch 00007: early stopping\n",
            "Found 488 validated image filenames.\n",
            "Found 55 validated image filenames.\n",
            "Epoch 1/20\n",
            "27/26 [==============================] - 5s 175ms/step - loss: 0.2003 - accuracy: 0.8519 - auc_1: 0.9335 - val_loss: 3.6756 - val_accuracy: 0.4909 - val_auc_1: 0.5000 - lr: 0.0062\n",
            "Epoch 2/20\n",
            "27/26 [==============================] - 5s 176ms/step - loss: 0.1680 - accuracy: 0.8774 - auc_1: 0.9538 - val_loss: 3.5458 - val_accuracy: 0.5091 - val_auc_1: 0.5000 - lr: 0.0065\n",
            "Epoch 3/20\n",
            "27/26 [==============================] - 4s 152ms/step - loss: 0.1129 - accuracy: 0.9387 - auc_1: 0.9818 - val_loss: 3.7514 - val_accuracy: 0.4727 - val_auc_1: 0.5000 - lr: 0.0068\n",
            "Epoch 4/20\n",
            "27/26 [==============================] - 4s 153ms/step - loss: 0.1122 - accuracy: 0.9245 - auc_1: 0.9837 - val_loss: 3.3534 - val_accuracy: 0.4909 - val_auc_1: 0.5357 - lr: 0.0070\n",
            "Epoch 5/20\n",
            "27/26 [==============================] - 4s 165ms/step - loss: 0.1885 - accuracy: 0.8844 - auc_1: 0.9483 - val_loss: 4.2918 - val_accuracy: 0.5091 - val_auc_1: 0.4861 - lr: 0.0073\n",
            "Epoch 6/20\n",
            "27/26 [==============================] - 4s 161ms/step - loss: 0.1156 - accuracy: 0.9363 - auc_1: 0.9810 - val_loss: 3.1367 - val_accuracy: 0.5000 - val_auc_1: 0.5000 - lr: 0.0076\n",
            "Epoch 7/20\n",
            "27/26 [==============================] - 4s 153ms/step - loss: 0.0868 - accuracy: 0.9552 - auc_1: 0.9913 - val_loss: 3.2351 - val_accuracy: 0.5000 - val_auc_1: 0.5182 - lr: 0.0078\n",
            "Epoch 8/20\n",
            "27/26 [==============================] - 4s 142ms/step - loss: 0.1210 - accuracy: 0.9306 - auc_1: 0.9777 - val_loss: 3.8057 - val_accuracy: 0.4727 - val_auc_1: 0.5000 - lr: 0.0081\n",
            "Epoch 9/20\n",
            "27/26 [==============================] - 4s 155ms/step - loss: 0.1045 - accuracy: 0.9434 - auc_1: 0.9823 - val_loss: 3.6754 - val_accuracy: 0.4909 - val_auc_1: 0.5000 - lr: 0.0084\n",
            "Epoch 10/20\n",
            "27/26 [==============================] - ETA: 0s - loss: 0.0703 - accuracy: 0.9575 - auc_1: 0.9959Restoring model weights from the end of the best epoch.\n",
            "27/26 [==============================] - 4s 162ms/step - loss: 0.0703 - accuracy: 0.9575 - auc_1: 0.9959 - val_loss: 3.5191 - val_accuracy: 0.5091 - val_auc_1: 0.5000 - lr: 0.0086\n",
            "Epoch 00010: early stopping\n",
            "Found 489 validated image filenames.\n",
            "Found 54 validated image filenames.\n",
            "Epoch 1/20\n",
            "27/26 [==============================] - 5s 185ms/step - loss: 0.1486 - accuracy: 0.9028 - auc_1: 0.9661 - val_loss: 4.5396 - val_accuracy: 0.3704 - val_auc_1: 0.5000 - lr: 0.0089\n",
            "Epoch 2/20\n",
            "27/26 [==============================] - 5s 176ms/step - loss: 0.1333 - accuracy: 0.9224 - auc_1: 0.9736 - val_loss: 0.8650 - val_accuracy: 0.6944 - val_auc_1: 0.8676 - lr: 0.0092\n",
            "Epoch 3/20\n",
            "27/26 [==============================] - 4s 150ms/step - loss: 0.1277 - accuracy: 0.9129 - auc_1: 0.9789 - val_loss: 4.9381 - val_accuracy: 0.3148 - val_auc_1: 0.5000 - lr: 0.0094\n",
            "Epoch 4/20\n",
            "27/26 [==============================] - 4s 144ms/step - loss: 0.1095 - accuracy: 0.9482 - auc_1: 0.9856 - val_loss: 4.4735 - val_accuracy: 0.3796 - val_auc_1: 0.5000 - lr: 0.0097\n",
            "Epoch 5/20\n",
            "27/26 [==============================] - 5s 175ms/step - loss: 0.1109 - accuracy: 0.9459 - auc_1: 0.9840 - val_loss: 4.5397 - val_accuracy: 0.3704 - val_auc_1: 0.5000 - lr: 0.0100\n",
            "Epoch 6/20\n",
            "27/26 [==============================] - ETA: 0s - loss: 0.0862 - accuracy: 0.9576 - auc_1: 0.9922Restoring model weights from the end of the best epoch.\n",
            "27/26 [==============================] - 4s 146ms/step - loss: 0.0862 - accuracy: 0.9576 - auc_1: 0.9922 - val_loss: 4.6677 - val_accuracy: 0.3426 - val_auc_1: 0.5000 - lr: 0.0098\n",
            "Epoch 00006: early stopping\n",
            "Found 489 validated image filenames.\n",
            "Found 54 validated image filenames.\n",
            "Epoch 1/20\n",
            "27/26 [==============================] - 5s 177ms/step - loss: 0.1043 - accuracy: 0.9306 - auc_1: 0.9869 - val_loss: 3.4778 - val_accuracy: 0.5185 - val_auc_1: 0.5000 - lr: 0.0095\n",
            "Epoch 2/20\n",
            "27/26 [==============================] - 5s 178ms/step - loss: 0.1044 - accuracy: 0.9412 - auc_1: 0.9855 - val_loss: 3.2125 - val_accuracy: 0.5556 - val_auc_1: 0.5000 - lr: 0.0092\n",
            "Epoch 3/20\n",
            "27/26 [==============================] - 4s 152ms/step - loss: 0.0698 - accuracy: 0.9624 - auc_1: 0.9939 - val_loss: 3.6927 - val_accuracy: 0.4722 - val_auc_1: 0.5000 - lr: 0.0090\n",
            "Epoch 4/20\n",
            "27/26 [==============================] - 5s 181ms/step - loss: 0.0602 - accuracy: 0.9694 - auc_1: 0.9975 - val_loss: 0.3071 - val_accuracy: 0.8889 - val_auc_1: 0.9314 - lr: 0.0087\n",
            "Epoch 5/20\n",
            "27/26 [==============================] - 4s 161ms/step - loss: 0.0567 - accuracy: 0.9788 - auc_1: 0.9977 - val_loss: 0.8549 - val_accuracy: 0.7407 - val_auc_1: 0.8462 - lr: 0.0084\n",
            "Epoch 6/20\n",
            "27/26 [==============================] - 4s 159ms/step - loss: 0.1370 - accuracy: 0.9271 - auc_1: 0.9727 - val_loss: 0.8241 - val_accuracy: 0.7130 - val_auc_1: 0.8173 - lr: 0.0082\n",
            "Epoch 7/20\n",
            "27/26 [==============================] - 4s 156ms/step - loss: 0.0782 - accuracy: 0.9600 - auc_1: 0.9934 - val_loss: 0.5958 - val_accuracy: 0.8333 - val_auc_1: 0.9215 - lr: 0.0079\n",
            "Epoch 8/20\n",
            "27/26 [==============================] - 6s 212ms/step - loss: 0.0935 - accuracy: 0.9560 - auc_1: 0.9866 - val_loss: 0.0866 - val_accuracy: 0.9444 - val_auc_1: 1.0000 - lr: 0.0076\n",
            "Epoch 9/20\n",
            "27/26 [==============================] - 4s 154ms/step - loss: 0.0445 - accuracy: 0.9906 - auc_1: 0.9983 - val_loss: 2.8533 - val_accuracy: 0.5370 - val_auc_1: 0.6250 - lr: 0.0074\n",
            "Epoch 10/20\n",
            "27/26 [==============================] - 4s 157ms/step - loss: 0.0348 - accuracy: 0.9929 - auc_1: 0.9999 - val_loss: 1.3162 - val_accuracy: 0.6852 - val_auc_1: 0.8190 - lr: 0.0071\n",
            "Epoch 11/20\n",
            "27/26 [==============================] - 6s 224ms/step - loss: 0.0333 - accuracy: 0.9953 - auc_1: 1.0000 - val_loss: 0.1301 - val_accuracy: 0.9630 - val_auc_1: 0.9791 - lr: 0.0068\n",
            "Epoch 12/20\n",
            "27/26 [==============================] - ETA: 0s - loss: 0.0533 - accuracy: 0.9859 - auc_1: 0.9964Restoring model weights from the end of the best epoch.\n",
            "27/26 [==============================] - 4s 156ms/step - loss: 0.0533 - accuracy: 0.9859 - auc_1: 0.9964 - val_loss: 1.0168 - val_accuracy: 0.7685 - val_auc_1: 0.8772 - lr: 0.0066\n",
            "Epoch 00012: early stopping\n",
            "Found 489 validated image filenames.\n",
            "Found 54 validated image filenames.\n",
            "Epoch 1/20\n",
            "27/26 [==============================] - 5s 179ms/step - loss: 0.0779 - accuracy: 0.9514 - auc_1: 0.9916 - val_loss: 0.0365 - val_accuracy: 0.9815 - val_auc_1: 1.0000 - lr: 0.0063\n",
            "Epoch 2/20\n",
            "27/26 [==============================] - 5s 198ms/step - loss: 0.0458 - accuracy: 0.9859 - auc_1: 0.9994 - val_loss: 0.0260 - val_accuracy: 1.0000 - val_auc_1: 1.0000 - lr: 0.0060\n",
            "Epoch 3/20\n",
            "27/26 [==============================] - 4s 154ms/step - loss: 0.0331 - accuracy: 0.9953 - auc_1: 0.9999 - val_loss: 0.2744 - val_accuracy: 0.8981 - val_auc_1: 0.9286 - lr: 0.0058\n",
            "Epoch 4/20\n",
            "27/26 [==============================] - 4s 147ms/step - loss: 0.0287 - accuracy: 0.9976 - auc_1: 1.0000 - val_loss: 1.0339 - val_accuracy: 0.7593 - val_auc_1: 0.8243 - lr: 0.0055\n",
            "Epoch 5/20\n",
            "27/26 [==============================] - 5s 173ms/step - loss: 0.0547 - accuracy: 0.9859 - auc_1: 0.9934 - val_loss: 0.5858 - val_accuracy: 0.8519 - val_auc_1: 0.9167 - lr: 0.0052\n",
            "Epoch 6/20\n",
            "27/26 [==============================] - 4s 158ms/step - loss: 0.0332 - accuracy: 0.9953 - auc_1: 0.9999 - val_loss: 0.0231 - val_accuracy: 1.0000 - val_auc_1: 1.0000 - lr: 0.0050\n",
            "Epoch 7/20\n",
            "27/26 [==============================] - 4s 148ms/step - loss: 0.0285 - accuracy: 0.9976 - auc_1: 0.9999 - val_loss: 0.7334 - val_accuracy: 0.8148 - val_auc_1: 0.8598 - lr: 0.0047\n",
            "Epoch 8/20\n",
            "27/26 [==============================] - 4s 151ms/step - loss: 0.0355 - accuracy: 0.9884 - auc_1: 0.9997 - val_loss: 1.6948 - val_accuracy: 0.6667 - val_auc_1: 0.6211 - lr: 0.0044\n",
            "Epoch 9/20\n",
            "27/26 [==============================] - 4s 159ms/step - loss: 0.0279 - accuracy: 0.9953 - auc_1: 1.0000 - val_loss: 2.7941 - val_accuracy: 0.6481 - val_auc_1: 0.4861 - lr: 0.0041\n",
            "Epoch 10/20\n",
            "27/26 [==============================] - ETA: 0s - loss: 0.0252 - accuracy: 1.0000 - auc_1: 1.0000Restoring model weights from the end of the best epoch.\n",
            "27/26 [==============================] - 4s 166ms/step - loss: 0.0252 - accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 2.7922 - val_accuracy: 0.6204 - val_auc_1: 0.4855 - lr: 0.0039\n",
            "Epoch 00010: early stopping\n",
            "Found 489 validated image filenames.\n",
            "Found 54 validated image filenames.\n",
            "Epoch 1/20\n",
            "27/26 [==============================] - 5s 192ms/step - loss: 0.0347 - accuracy: 0.9907 - auc_1: 0.9997 - val_loss: 0.2836 - val_accuracy: 0.9074 - val_auc_1: 0.9583 - lr: 0.0036\n",
            "Epoch 2/20\n",
            "27/26 [==============================] - 4s 160ms/step - loss: 0.0295 - accuracy: 0.9976 - auc_1: 0.9999 - val_loss: 1.0210 - val_accuracy: 0.6574 - val_auc_1: 0.8300 - lr: 0.0033\n",
            "Epoch 3/20\n",
            "27/26 [==============================] - 4s 151ms/step - loss: 0.0247 - accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 1.1170 - val_accuracy: 0.7130 - val_auc_1: 0.7717 - lr: 0.0031\n",
            "Epoch 4/20\n",
            "27/26 [==============================] - 4s 164ms/step - loss: 0.0259 - accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 1.1978 - val_accuracy: 0.6759 - val_auc_1: 0.8021 - lr: 0.0028\n",
            "Epoch 5/20\n",
            "27/26 [==============================] - ETA: 0s - loss: 0.0239 - accuracy: 1.0000 - auc_1: 1.0000Restoring model weights from the end of the best epoch.\n",
            "27/26 [==============================] - 4s 155ms/step - loss: 0.0239 - accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 1.1432 - val_accuracy: 0.6667 - val_auc_1: 0.7917 - lr: 0.0025\n",
            "Epoch 00005: early stopping\n",
            "Found 489 validated image filenames.\n",
            "Found 54 validated image filenames.\n",
            "Epoch 1/20\n",
            "27/26 [==============================] - 5s 175ms/step - loss: 0.0469 - accuracy: 0.9838 - auc_1: 0.9984 - val_loss: 0.0384 - val_accuracy: 0.9815 - val_auc_1: 1.0000 - lr: 0.0023\n",
            "Epoch 2/20\n",
            "27/26 [==============================] - 4s 151ms/step - loss: 0.0431 - accuracy: 0.9812 - auc_1: 0.9992 - val_loss: 2.8506 - val_accuracy: 0.5556 - val_auc_1: 0.5729 - lr: 0.0020\n",
            "Epoch 3/20\n",
            "27/26 [==============================] - 4s 149ms/step - loss: 0.0357 - accuracy: 0.9906 - auc_1: 0.9997 - val_loss: 3.0509 - val_accuracy: 0.5185 - val_auc_1: 0.5192 - lr: 0.0017\n",
            "Epoch 4/20\n",
            "27/26 [==============================] - 5s 169ms/step - loss: 0.0268 - accuracy: 0.9976 - auc_1: 1.0000 - val_loss: 1.2648 - val_accuracy: 0.6019 - val_auc_1: 0.7340 - lr: 0.0015\n",
            "Epoch 5/20\n",
            "27/26 [==============================] - ETA: 0s - loss: 0.0267 - accuracy: 0.9976 - auc_1: 1.0000Restoring model weights from the end of the best epoch.\n",
            "27/26 [==============================] - 4s 151ms/step - loss: 0.0267 - accuracy: 0.9976 - auc_1: 1.0000 - val_loss: 1.9686 - val_accuracy: 0.5370 - val_auc_1: 0.5800 - lr: 0.0012\n",
            "Epoch 00005: early stopping\n",
            "Found 489 validated image filenames.\n",
            "Found 54 validated image filenames.\n",
            "Epoch 1/20\n",
            "27/26 [==============================] - 5s 184ms/step - loss: 0.0267 - accuracy: 0.9977 - auc_1: 1.0000 - val_loss: 0.0630 - val_accuracy: 0.9630 - val_auc_1: 1.0000 - lr: 9.4150e-04\n",
            "Epoch 2/20\n",
            "27/26 [==============================] - 4s 151ms/step - loss: 0.0240 - accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 0.1841 - val_accuracy: 0.8704 - val_auc_1: 1.0000 - lr: 6.7420e-04\n",
            "Epoch 3/20\n",
            "27/26 [==============================] - 4s 159ms/step - loss: 0.0255 - accuracy: 0.9976 - auc_1: 1.0000 - val_loss: 0.5202 - val_accuracy: 0.7315 - val_auc_1: 0.9608 - lr: 4.0690e-04\n",
            "Epoch 4/20\n",
            "27/26 [==============================] - 4s 158ms/step - loss: 0.0268 - accuracy: 0.9953 - auc_1: 1.0000 - val_loss: 1.3867 - val_accuracy: 0.5556 - val_auc_1: 0.7895 - lr: 1.3960e-04\n",
            "Epoch 5/20\n",
            "27/26 [==============================] - ETA: 0s - loss: 0.0256 - accuracy: 0.9953 - auc_1: 1.0000Restoring model weights from the end of the best epoch.\n",
            "27/26 [==============================] - 4s 149ms/step - loss: 0.0256 - accuracy: 0.9953 - auc_1: 1.0000 - val_loss: 1.8661 - val_accuracy: 0.5556 - val_auc_1: 0.7037 - lr: 3.2770e-04\n",
            "Epoch 00005: early stopping\n",
            "Found 489 validated image filenames.\n",
            "Found 54 validated image filenames.\n",
            "Epoch 1/20\n",
            "27/26 [==============================] - 5s 172ms/step - loss: 0.0269 - accuracy: 0.9977 - auc_1: 1.0000 - val_loss: 0.4466 - val_accuracy: 0.7963 - val_auc_1: 0.9667 - lr: 5.9500e-04\n",
            "Epoch 2/20\n",
            "27/26 [==============================] - 4s 155ms/step - loss: 0.0320 - accuracy: 0.9929 - auc_1: 0.9999 - val_loss: 0.5095 - val_accuracy: 0.7315 - val_auc_1: 0.9194 - lr: 8.6230e-04\n",
            "Epoch 3/20\n",
            "27/26 [==============================] - 4s 149ms/step - loss: 0.0275 - accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 1.4392 - val_accuracy: 0.5926 - val_auc_1: 0.7719 - lr: 0.0011\n",
            "Epoch 4/20\n",
            "27/26 [==============================] - 4s 157ms/step - loss: 0.0237 - accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 2.5698 - val_accuracy: 0.4722 - val_auc_1: 0.6525 - lr: 0.0014\n",
            "Epoch 5/20\n",
            "27/26 [==============================] - ETA: 0s - loss: 0.0222 - accuracy: 1.0000 - auc_1: 1.0000Restoring model weights from the end of the best epoch.\n",
            "27/26 [==============================] - 4s 150ms/step - loss: 0.0222 - accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 2.9575 - val_accuracy: 0.4630 - val_auc_1: 0.6333 - lr: 0.0017\n",
            "Epoch 00005: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAOlE1vVlDfn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# history = model.fit_generator(train_generator_96, \n",
        "#                               validation_data=valid_generator_96,\n",
        "#                               steps_per_epoch=25, \n",
        "#                               validation_steps=12, \n",
        "#                               epochs = 50,\n",
        "#                               verbose=1,\n",
        "#                               callbacks = [EarlyStopping(monitor='val_loss',mode='min',patience=10,verbose=1,restore_best_weights = True),ModelCheckpoint(filepath='/content/drive/My Drive/Files-Covid/model_96_test1.h5', save_best_only=True, monitor='val_accuracy', mode='max'),clr])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BL5eTnKsFno4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "5f99e0f4-8a90-418d-84a6-b64347f7b808"
      },
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.ylabel(\"loss\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.title(\"Training- Val loss Curve\")\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5lZN8nzzpO-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model1 = load_model('/content/drive/My Drive/Files-Covid/model_96_1.h5',custom_objects={'weighted_loss':get_weighted_loss(pos_weights_96,neg_weights_96)})\n",
        "# model2 = load_model('/content/drive/My Drive/Files-Covid/model_96_2.h5',custom_objects={'weighted_loss':get_weighted_loss(pos_weights_96,neg_weights_96)})\n",
        "# model3 = load_model('/content/drive/My Drive/Files-Covid/model_96_3.h5',custom_objects={'weighted_loss':get_weighted_loss(pos_weights_96,neg_weights_96)})\n",
        "# model4 = load_model('/content/drive/My Drive/Files-Covid/model_96_4.h5',custom_objects={'weighted_loss':get_weighted_loss(pos_weights_96,neg_weights_96)})\n",
        "# model5 = load_model('/content/drive/My Drive/Files-Covid/model_96_5.h5',custom_objects={'weighted_loss':get_weighted_loss(pos_weights_96,neg_weights_96)})\n",
        "# model6 = load_model('/content/drive/My Drive/Files-Covid/model_96_6.h5',custom_objects={'weighted_loss':get_weighted_loss(pos_weights_96,neg_weights_96)})\n",
        "# model7 = load_model('/content/drive/My Drive/Files-Covid/model_96_7.h5',custom_objects={'weighted_loss':get_weighted_loss(pos_weights_96,neg_weights_96)})\n",
        "# model8 = load_model('/content/drive/My Drive/Files-Covid/model_96_8.h5',custom_objects={'weighted_loss':get_weighted_loss(pos_weights_96,neg_weights_96)})\n",
        "# model9 = load_model('/content/drive/My Drive/Files-Covid/model_96_9.h5',custom_objects={'weighted_loss':get_weighted_loss(pos_weights_96,neg_weights_96)})\n",
        "# model10 = load_model('/content/drive/My Drive/Files-Covid/model_96_10.h5',custom_objects={'weighted_loss':get_weighted_loss(pos_weights_96,neg_weights_96)})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gI5-IWlejaxm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_xab4sliQ3o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "9ce8c689-a7d5-4043-b14e-b13f54655639"
      },
      "source": [
        "predicted_vals1 = model.predict_generator(test_generator_96, steps = len(test_generator_96))\n",
        "# predicted_vals2 = model2.predict_generator(test_generator_96, steps = len(test_generator_96))\n",
        "# predicted_vals3 = model3.predict_generator(test_generator_96, steps = len(test_generator_96))\n",
        "# predicted_vals4 = model4.predict_generator(test_generator_96, steps = len(test_generator_96))\n",
        "# predicted_vals5 = model5.predict_generator(test_generator_96, steps = len(test_generator_96))\n",
        "# predicted_vals6 = model6.predict_generator(test_generator_96, steps = len(test_generator_96))\n",
        "# predicted_vals7 = model7.predict_generator(test_generator_96, steps = len(test_generator_96))\n",
        "# predicted_vals8 = model8.predict_generator(test_generator_96, steps = len(test_generator_96))\n",
        "# predicted_vals9 = model9.predict_generator(test_generator_96, steps = len(test_generator_96))\n",
        "# predicted_vals10 = model10.predict_generator(test_generator_96, steps = len(test_generator_96))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-29-83cb47b6c6e5>:1: Model.predict_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.predict, which supports generators.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYrnOBX6mHzn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRyMD9v30ByY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import roc_auc_score, roc_curve"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GE_zI7WL0E6q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_roc_curve(labels, predicted_vals, generator):\n",
        "    auc_roc_vals = []\n",
        "    for i in range(len(labels)):\n",
        "        try:\n",
        "            gt = generator.labels[:, i]\n",
        "            pred = predicted_vals[:, i]\n",
        "            auc_roc = roc_auc_score(gt, pred)\n",
        "            auc_roc_vals.append(auc_roc)\n",
        "            fpr_rf, tpr_rf, _ = roc_curve(gt, pred)\n",
        "            plt.figure(1, figsize=(10, 10))\n",
        "            plt.plot([0, 1], [0, 1], 'k--')\n",
        "            plt.plot(fpr_rf, tpr_rf,\n",
        "                     label=labels[i] + \" (\" + str(round(auc_roc, 3)) + \")\")\n",
        "            plt.xlabel('False positive rate')\n",
        "            plt.ylabel('True positive rate')\n",
        "            plt.title('ROC curve')\n",
        "            plt.legend(loc='best')\n",
        "        except:\n",
        "            print(\n",
        "                f\"Error in generating ROC curve for {labels[i]}. \"\n",
        "                f\"Dataset lacks enough examples.\"\n",
        "            )\n",
        "    plt.show()\n",
        "    return auc_roc_vals"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3yHhi_m0Hd_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 621
        },
        "outputId": "5a5e9cb3-319b-410f-838c-fc418d5da730"
      },
      "source": [
        "auc_rocs = get_roc_curve(labels, predicted_vals1, test_generator_96)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNRb2uaH0K0B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d55fb773-7a23-4e13-b921-46d4c911a5e7"
      },
      "source": [
        "len(test_df.index)/16"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12.6875"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VC9YPyoIs5KE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "c0b313a4-afcc-447e-c500-c0c3668b0d02"
      },
      "source": [
        "model.evaluate(test_generator_96,batch_size=16, verbose=1, steps=12)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12/12 [==============================] - 1s 61ms/step - loss: 0.6480 - accuracy: 0.8646 - auc_1: 0.7713\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6480233073234558, 0.8645833134651184, 0.7712963223457336]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "goVZiuWftOo7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "a3777f48-5957-4bf8-d5fe-1e05b1991bbd"
      },
      "source": [
        "export_dir = '/content/drive/My Drive/Files-Covid/saved_model/1'\n",
        "\n",
        "tf.saved_model.save(model,export_dir)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Files-Covid/saved_model/1/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYwsIXmytsvl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Select mode of optimization\n",
        "mode = \"Speed\" \n",
        "\n",
        "if mode == 'Storage':\n",
        "    optimization = tf.lite.Optimize.OPTIMIZE_FOR_SIZE\n",
        "elif mode == 'Speed':\n",
        "    optimization = tf.lite.Optimize.OPTIMIZE_FOR_LATENCY\n",
        "else:\n",
        "    optimization = tf.lite.Optimize.DEFAULT"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhBBYGhsuTeF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# EXERCISE: Use the TFLiteConverter SavedModel API to initialize the converter\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(export_dir)\n",
        "\n",
        "# Set the optimzations\n",
        "converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_LATENCY]\n",
        "\n",
        "# Invoke the converter to finally generate the TFLite model\n",
        "tflite_model = converter.convert()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rJmcfqzuWTX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "65a3218b-29b5-46f1-9377-bc489e03694d"
      },
      "source": [
        "import pathlib\n",
        "tflite_model_file = pathlib.Path('/content/drive/My Drive/Files-Covid/init_model.tflite')\n",
        "tflite_model_file.write_bytes(tflite_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15011080"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqV-U7BCusYr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load TFLite model and allocate tensors.\n",
        "interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "input_index = interpreter.get_input_details()[0][\"index\"]\n",
        "output_index = interpreter.get_output_details()[0][\"index\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xu62LCdZvRx7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZTJglCjx3We",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}